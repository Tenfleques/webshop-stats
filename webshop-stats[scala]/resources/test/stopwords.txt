Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
18/04/01 20:14:35 WARN Utils: Your hostname, blackhawk resolves to a loopback address: 127.0.0.1; using 192.168.1.3 instead (on interface wlan0)
18/04/01 20:14:35 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
18/04/01 20:14:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/04/01 20:14:43 WARN Checkpoint: Checkpoint directory /tmp/refs-xyzabb does not exist
18/04/01 20:14:43 INFO SparkContext: Running Spark version 2.3.0
18/04/01 20:14:44 INFO SparkContext: Submitted application: webshop-referee-stats-xyzab
18/04/01 20:14:45 INFO SecurityManager: Changing view acls to: blackjack
18/04/01 20:14:45 INFO SecurityManager: Changing modify acls to: blackjack
18/04/01 20:14:45 INFO SecurityManager: Changing view acls groups to: 
18/04/01 20:14:45 INFO SecurityManager: Changing modify acls groups to: 
18/04/01 20:14:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(blackjack); groups with view permissions: Set(); users  with modify permissions: Set(blackjack); groups with modify permissions: Set()
18/04/01 20:14:48 INFO Utils: Successfully started service 'sparkDriver' on port 37987.
18/04/01 20:14:48 INFO SparkEnv: Registering MapOutputTracker
18/04/01 20:14:48 INFO SparkEnv: Registering BlockManagerMaster
18/04/01 20:14:48 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/04/01 20:14:48 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/04/01 20:14:48 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9756b001-707f-46c2-949f-c2bb2853609e
18/04/01 20:14:48 INFO MemoryStore: MemoryStore started with capacity 477.3 MB
18/04/01 20:14:48 INFO SparkEnv: Registering OutputCommitCoordinator
18/04/01 20:14:49 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/04/01 20:14:49 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.1.3:4040
18/04/01 20:14:50 INFO Executor: Starting executor ID driver on host localhost
18/04/01 20:14:50 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35449.
18/04/01 20:14:50 INFO NettyBlockTransferService: Server created on 192.168.1.3:35449
18/04/01 20:14:50 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/04/01 20:14:50 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.1.3, 35449, None)
18/04/01 20:14:51 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.1.3:35449 with 477.3 MB RAM, BlockManagerId(driver, 192.168.1.3, 35449, None)
18/04/01 20:14:51 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.1.3, 35449, None)
18/04/01 20:14:51 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.1.3, 35449, None)
18/04/01 20:14:52 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 96.0 B, free 477.3 MB)
18/04/01 20:14:52 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 63.0 B, free 477.3 MB)
18/04/01 20:14:52 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.1.3:35449 (size: 63.0 B, free: 477.3 MB)
18/04/01 20:14:52 INFO SparkContext: Created broadcast 0 from broadcast at RefereeStats.scala:30
18/04/01 20:14:53 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 192.168.1.3:35449 in memory (size: 63.0 B, free: 477.3 MB)
18/04/01 20:14:53 WARN KafkaUtils: overriding enable.auto.commit to false for executor
18/04/01 20:14:53 WARN KafkaUtils: overriding auto.offset.reset to none for executor
18/04/01 20:14:53 WARN KafkaUtils: overriding executor group.id to spark-executor-streamer-xxx-xyzab
18/04/01 20:14:53 WARN KafkaUtils: overriding receive.buffer.bytes to 65536 see KAFKA-3135
18/04/01 20:14:54 INFO DirectKafkaInputDStream: Slide time = 5000 ms
18/04/01 20:14:54 INFO DirectKafkaInputDStream: Storage level = Serialized 1x Replicated
18/04/01 20:14:54 INFO DirectKafkaInputDStream: Checkpoint interval = null
18/04/01 20:14:54 INFO DirectKafkaInputDStream: Remember interval = 5000 ms
18/04/01 20:14:54 INFO DirectKafkaInputDStream: Initialized and validated org.apache.spark.streaming.kafka010.DirectKafkaInputDStream@4315e9af
18/04/01 20:14:54 INFO MappedDStream: Slide time = 5000 ms
18/04/01 20:14:54 INFO MappedDStream: Storage level = Serialized 1x Replicated
18/04/01 20:14:54 INFO MappedDStream: Checkpoint interval = null
18/04/01 20:14:54 INFO MappedDStream: Remember interval = 5000 ms
18/04/01 20:14:54 INFO MappedDStream: Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@117bcfdc
18/04/01 20:14:54 INFO ForEachDStream: Slide time = 5000 ms
18/04/01 20:14:54 INFO ForEachDStream: Storage level = Serialized 1x Replicated
18/04/01 20:14:54 INFO ForEachDStream: Checkpoint interval = null
18/04/01 20:14:54 INFO ForEachDStream: Remember interval = 5000 ms
18/04/01 20:14:54 INFO ForEachDStream: Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@6b00ad9
18/04/01 20:14:54 INFO DirectKafkaInputDStream: Slide time = 5000 ms
18/04/01 20:14:54 INFO DirectKafkaInputDStream: Storage level = Serialized 1x Replicated
18/04/01 20:14:54 INFO DirectKafkaInputDStream: Checkpoint interval = null
18/04/01 20:14:54 INFO DirectKafkaInputDStream: Remember interval = 5000 ms
18/04/01 20:14:54 INFO DirectKafkaInputDStream: Initialized and validated org.apache.spark.streaming.kafka010.DirectKafkaInputDStream@4315e9af
18/04/01 20:14:54 INFO MappedDStream: Slide time = 5000 ms
18/04/01 20:14:54 INFO MappedDStream: Storage level = Serialized 1x Replicated
18/04/01 20:14:54 INFO MappedDStream: Checkpoint interval = null
18/04/01 20:14:54 INFO MappedDStream: Remember interval = 5000 ms
18/04/01 20:14:54 INFO MappedDStream: Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@117bcfdc
18/04/01 20:14:54 INFO ShuffledDStream: Slide time = 5000 ms
18/04/01 20:14:54 INFO ShuffledDStream: Storage level = Serialized 1x Replicated
18/04/01 20:14:54 INFO ShuffledDStream: Checkpoint interval = null
18/04/01 20:14:54 INFO ShuffledDStream: Remember interval = 5000 ms
18/04/01 20:14:54 INFO ShuffledDStream: Initialized and validated org.apache.spark.streaming.dstream.ShuffledDStream@6fa69af7
18/04/01 20:14:54 INFO ForEachDStream: Slide time = 5000 ms
18/04/01 20:14:54 INFO ForEachDStream: Storage level = Serialized 1x Replicated
18/04/01 20:14:54 INFO ForEachDStream: Checkpoint interval = null
18/04/01 20:14:54 INFO ForEachDStream: Remember interval = 5000 ms
18/04/01 20:14:54 INFO ForEachDStream: Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@451882b2
18/04/01 20:14:54 INFO DirectKafkaInputDStream: Slide time = 5000 ms
18/04/01 20:14:54 INFO DirectKafkaInputDStream: Storage level = Serialized 1x Replicated
18/04/01 20:14:54 INFO DirectKafkaInputDStream: Checkpoint interval = null
18/04/01 20:14:54 INFO DirectKafkaInputDStream: Remember interval = 5000 ms
18/04/01 20:14:54 INFO DirectKafkaInputDStream: Initialized and validated org.apache.spark.streaming.kafka010.DirectKafkaInputDStream@4315e9af
18/04/01 20:14:54 INFO MappedDStream: Slide time = 5000 ms
18/04/01 20:14:54 INFO MappedDStream: Storage level = Serialized 1x Replicated
18/04/01 20:14:54 INFO MappedDStream: Checkpoint interval = null
18/04/01 20:14:54 INFO MappedDStream: Remember interval = 5000 ms
18/04/01 20:14:54 INFO MappedDStream: Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@51ce6f85
18/04/01 20:14:54 INFO ShuffledDStream: Slide time = 5000 ms
18/04/01 20:14:54 INFO ShuffledDStream: Storage level = Serialized 1x Replicated
18/04/01 20:14:54 INFO ShuffledDStream: Checkpoint interval = null
18/04/01 20:14:54 INFO ShuffledDStream: Remember interval = 5000 ms
18/04/01 20:14:54 INFO ShuffledDStream: Initialized and validated org.apache.spark.streaming.dstream.ShuffledDStream@5b84f14
18/04/01 20:14:54 INFO ForEachDStream: Slide time = 5000 ms
18/04/01 20:14:54 INFO ForEachDStream: Storage level = Serialized 1x Replicated
18/04/01 20:14:54 INFO ForEachDStream: Checkpoint interval = null
18/04/01 20:14:54 INFO ForEachDStream: Remember interval = 5000 ms
18/04/01 20:14:54 INFO ForEachDStream: Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@96a75da
18/04/01 20:14:54 INFO DirectKafkaInputDStream: Slide time = 5000 ms
18/04/01 20:14:54 INFO DirectKafkaInputDStream: Storage level = Serialized 1x Replicated
18/04/01 20:14:54 INFO DirectKafkaInputDStream: Checkpoint interval = null
18/04/01 20:14:54 INFO DirectKafkaInputDStream: Remember interval = 5000 ms
18/04/01 20:14:54 INFO DirectKafkaInputDStream: Initialized and validated org.apache.spark.streaming.kafka010.DirectKafkaInputDStream@4315e9af
18/04/01 20:14:54 INFO MappedDStream: Slide time = 5000 ms
18/04/01 20:14:54 INFO MappedDStream: Storage level = Serialized 1x Replicated
18/04/01 20:14:54 INFO MappedDStream: Checkpoint interval = null
18/04/01 20:14:54 INFO MappedDStream: Remember interval = 5000 ms
18/04/01 20:14:54 INFO MappedDStream: Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@351f2244
18/04/01 20:14:54 INFO ShuffledDStream: Slide time = 5000 ms
18/04/01 20:14:54 INFO ShuffledDStream: Storage level = Serialized 1x Replicated
18/04/01 20:14:54 INFO ShuffledDStream: Checkpoint interval = null
18/04/01 20:14:54 INFO ShuffledDStream: Remember interval = 5000 ms
18/04/01 20:14:54 INFO ShuffledDStream: Initialized and validated org.apache.spark.streaming.dstream.ShuffledDStream@736309a9
18/04/01 20:14:54 INFO ForEachDStream: Slide time = 5000 ms
18/04/01 20:14:54 INFO ForEachDStream: Storage level = Serialized 1x Replicated
18/04/01 20:14:54 INFO ForEachDStream: Checkpoint interval = null
18/04/01 20:14:54 INFO ForEachDStream: Remember interval = 5000 ms
18/04/01 20:14:54 INFO ForEachDStream: Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@244e619a
18/04/01 20:14:54 INFO ConsumerConfig: ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = streamer-xxx-xyzab
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

18/04/01 20:14:55 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:14:55 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:14:55 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:14:55 INFO AbstractCoordinator: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null)
18/04/01 20:14:55 INFO ConsumerCoordinator: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Revoking previously assigned partitions []
18/04/01 20:14:55 INFO AbstractCoordinator: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] (Re-)joining group
18/04/01 20:14:55 INFO AbstractCoordinator: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Successfully joined group with generation 1
18/04/01 20:14:55 INFO ConsumerCoordinator: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Setting newly assigned partitions [clients-purchases-src-xxx-0, clients-purchases-src-xxx-3, clients-purchases-src-xxx-4, clients-purchases-src-xxx-1, clients-purchases-src-xxx-2]
18/04/01 20:14:55 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-0 to offset 0.
18/04/01 20:14:55 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-3 to offset 0.
18/04/01 20:14:55 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-4 to offset 0.
18/04/01 20:14:55 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-1 to offset 0.
18/04/01 20:14:55 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-2 to offset 0.
18/04/01 20:14:55 INFO RecurringTimer: Started timer for JobGenerator at time 1522602895000
18/04/01 20:14:55 INFO JobGenerator: Started JobGenerator at 1522602895000 ms
18/04/01 20:14:55 INFO JobScheduler: Started JobScheduler
18/04/01 20:14:55 INFO StreamingContext: StreamingContext started
18/04/01 20:14:55 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-0 to offset 701.
18/04/01 20:14:55 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-3 to offset 0.
18/04/01 20:14:55 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-4 to offset 0.
18/04/01 20:14:55 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-1 to offset 0.
18/04/01 20:14:55 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-2 to offset 0.
18/04/01 20:14:56 INFO JobScheduler: Added jobs for time 1522602895000 ms
18/04/01 20:14:56 INFO JobGenerator: Checkpointing graph for time 1522602895000 ms
18/04/01 20:14:56 INFO DStreamGraph: Updating checkpoint data for time 1522602895000 ms
18/04/01 20:14:56 INFO JobScheduler: Starting job streaming job 1522602895000 ms.0 from job set of time 1522602895000 ms
18/04/01 20:14:56 INFO DStreamGraph: Updated checkpoint data for time 1522602895000 ms
18/04/01 20:14:56 INFO CheckpointWriter: Submitted checkpoint of time 1522602895000 ms to writer queue
18/04/01 20:14:56 INFO CheckpointWriter: Saving checkpoint for time 1522602895000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602895000'
18/04/01 20:14:56 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:14:56 INFO CheckpointWriter: Checkpoint for time 1522602895000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602895000', took 5532 bytes and 118 ms
18/04/01 20:14:56 INFO DAGScheduler: Got job 0 (print at RefereeStats.scala:67) with 1 output partitions
18/04/01 20:14:56 INFO DAGScheduler: Final stage: ResultStage 0 (print at RefereeStats.scala:67)
18/04/01 20:14:56 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:14:56 INFO DAGScheduler: Missing parents: List()
18/04/01 20:14:56 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:14:56 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 3.0 KB, free 477.3 MB)
18/04/01 20:14:56 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 1976.0 B, free 477.3 MB)
18/04/01 20:14:56 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.1.3:35449 (size: 1976.0 B, free: 477.3 MB)
18/04/01 20:14:56 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1039
18/04/01 20:14:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0))
18/04/01 20:14:56 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
18/04/01 20:14:56 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:14:56 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
18/04/01 20:14:56 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:14:56 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 704 bytes result sent to driver
18/04/01 20:14:56 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 238 ms on localhost (executor driver) (1/1)
18/04/01 20:14:56 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/04/01 20:14:56 INFO DAGScheduler: ResultStage 0 (print at RefereeStats.scala:67) finished in 0.495 s
18/04/01 20:14:56 INFO DAGScheduler: Job 0 finished: print at RefereeStats.scala:67, took 0.780004 s
18/04/01 20:14:57 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:14:57 INFO DAGScheduler: Got job 1 (print at RefereeStats.scala:67) with 4 output partitions
18/04/01 20:14:57 INFO DAGScheduler: Final stage: ResultStage 1 (print at RefereeStats.scala:67)
18/04/01 20:14:57 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:14:57 INFO DAGScheduler: Missing parents: List()
18/04/01 20:14:57 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[1] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:14:57 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 3.0 KB, free 477.3 MB)
18/04/01 20:14:57 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 1976.0 B, free 477.3 MB)
18/04/01 20:14:57 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.1.3:35449 (size: 1976.0 B, free: 477.3 MB)
18/04/01 20:14:57 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1039
18/04/01 20:14:57 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 1 (MapPartitionsRDD[1] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
18/04/01 20:14:57 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks
18/04/01 20:14:57 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:14:57 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:14:57 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
18/04/01 20:14:57 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
18/04/01 20:14:57 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:14:57 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:14:57 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 704 bytes result sent to driver
18/04/01 20:14:57 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 704 bytes result sent to driver
18/04/01 20:14:57 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:14:57 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
18/04/01 20:14:57 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 4, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:14:57 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
18/04/01 20:14:57 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 70 ms on localhost (executor driver) (1/4)
18/04/01 20:14:57 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 82 ms on localhost (executor driver) (2/4)
18/04/01 20:14:57 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:14:57 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 704 bytes result sent to driver
18/04/01 20:14:57 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 0 -> 701
18/04/01 20:14:57 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 55 ms on localhost (executor driver) (3/4)
18/04/01 20:14:57 INFO CachedKafkaConsumer: Initializing cache 16 64 0.75
18/04/01 20:14:57 INFO CachedKafkaConsumer: Cache miss for CacheKey(spark-executor-streamer-xxx-xyzab,clients-purchases-src-xxx,0)
18/04/01 20:14:57 INFO ConsumerConfig: ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = spark-executor-streamer-xxx-xyzab
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

18/04/01 20:14:57 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:14:57 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:14:57 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 0
18/04/01 20:14:57 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:14:57 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 1191 bytes result sent to driver
18/04/01 20:14:57 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 402 ms on localhost (executor driver) (4/4)
18/04/01 20:14:57 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/04/01 20:14:57 INFO DAGScheduler: ResultStage 1 (print at RefereeStats.scala:67) finished in 0.487 s
18/04/01 20:14:57 INFO DAGScheduler: Job 1 finished: print at RefereeStats.scala:67, took 0.502887 s
-------------------------------------------
Time: 1522602895000 ms
-------------------------------------------
(quora.com,0)
(vk.com,32000)
(instagram.*,40000)
(quora.com,0)
(twitter.*,49000)
(nextanalytics.com,53000)
(yandex.*,0)
(google.*,60000)
(twitter.*,0)
(twitter.*,3000)
...

18/04/01 20:14:57 INFO JobScheduler: Finished job streaming job 1522602895000 ms.0 from job set of time 1522602895000 ms
18/04/01 20:14:57 INFO JobScheduler: Starting job streaming job 1522602895000 ms.1 from job set of time 1522602895000 ms
18/04/01 20:14:57 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:71
18/04/01 20:14:57 INFO DAGScheduler: Registering RDD 1 (map at RefereeStats.scala:53)
18/04/01 20:14:57 INFO DAGScheduler: Got job 2 (foreachPartition at RefereeStats.scala:71) with 2 output partitions
18/04/01 20:14:57 INFO DAGScheduler: Final stage: ResultStage 3 (foreachPartition at RefereeStats.scala:71)
18/04/01 20:14:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
18/04/01 20:14:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
18/04/01 20:14:57 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[1] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:14:57 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 3.9 KB, free 477.3 MB)
18/04/01 20:14:57 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.3 MB)
18/04/01 20:14:57 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:14:57 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1039
18/04/01 20:14:57 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[1] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:14:57 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
18/04/01 20:14:57 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:14:57 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 6, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:14:57 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
18/04/01 20:14:57 INFO Executor: Running task 1.0 in stage 2.0 (TID 6)
18/04/01 20:14:57 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:14:57 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:14:57 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 981 bytes result sent to driver
18/04/01 20:14:57 INFO Executor: Finished task 1.0 in stage 2.0 (TID 6). 981 bytes result sent to driver
18/04/01 20:14:57 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 7, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:14:57 INFO Executor: Running task 2.0 in stage 2.0 (TID 7)
18/04/01 20:14:57 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 8, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:14:57 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 146 ms on localhost (executor driver) (1/5)
18/04/01 20:14:57 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:14:57 INFO Executor: Running task 3.0 in stage 2.0 (TID 8)
18/04/01 20:14:57 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 6) in 147 ms on localhost (executor driver) (2/5)
18/04/01 20:14:57 INFO Executor: Finished task 2.0 in stage 2.0 (TID 7). 938 bytes result sent to driver
18/04/01 20:14:57 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 9, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:14:57 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 7) in 28 ms on localhost (executor driver) (3/5)
18/04/01 20:14:57 INFO Executor: Running task 4.0 in stage 2.0 (TID 9)
18/04/01 20:14:57 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:14:57 INFO Executor: Finished task 3.0 in stage 2.0 (TID 8). 981 bytes result sent to driver
18/04/01 20:14:57 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 0 -> 701
18/04/01 20:14:57 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 8) in 44 ms on localhost (executor driver) (4/5)
18/04/01 20:14:57 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 0
18/04/01 20:14:58 INFO Executor: Finished task 4.0 in stage 2.0 (TID 9). 1024 bytes result sent to driver
18/04/01 20:14:58 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 9) in 229 ms on localhost (executor driver) (5/5)
18/04/01 20:14:58 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/04/01 20:14:58 INFO DAGScheduler: ShuffleMapStage 2 (map at RefereeStats.scala:53) finished in 0.441 s
18/04/01 20:14:58 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:14:58 INFO DAGScheduler: running: Set()
18/04/01 20:14:58 INFO DAGScheduler: waiting: Set(ResultStage 3)
18/04/01 20:14:58 INFO DAGScheduler: failed: Set()
18/04/01 20:14:58 INFO DAGScheduler: Submitting ResultStage 3 (ShuffledRDD[2] at reduceByKey at RefereeStats.scala:60), which has no missing parents
18/04/01 20:14:58 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 2.8 KB, free 477.3 MB)
18/04/01 20:14:58 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 1719.0 B, free 477.3 MB)
18/04/01 20:14:58 INFO ContextCleaner: Cleaned accumulator 45
18/04/01 20:14:58 INFO ContextCleaner: Cleaned accumulator 34
18/04/01 20:14:58 INFO ContextCleaner: Cleaned accumulator 28
18/04/01 20:14:58 INFO ContextCleaner: Cleaned accumulator 42
18/04/01 20:14:58 INFO ContextCleaner: Cleaned accumulator 36
18/04/01 20:14:58 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.1.3:35449 (size: 1719.0 B, free: 477.3 MB)
18/04/01 20:14:58 INFO ContextCleaner: Cleaned accumulator 29
18/04/01 20:14:58 INFO ContextCleaner: Cleaned accumulator 25
18/04/01 20:14:58 INFO ContextCleaner: Cleaned accumulator 46
18/04/01 20:14:58 INFO ContextCleaner: Cleaned accumulator 44
18/04/01 20:14:58 INFO ContextCleaner: Cleaned accumulator 31
18/04/01 20:14:58 INFO ContextCleaner: Cleaned accumulator 27
18/04/01 20:14:58 INFO ContextCleaner: Cleaned accumulator 33
18/04/01 20:14:58 INFO ContextCleaner: Cleaned accumulator 48
18/04/01 20:14:58 INFO ContextCleaner: Cleaned accumulator 38
18/04/01 20:14:58 INFO ContextCleaner: Cleaned accumulator 40
18/04/01 20:14:58 INFO ContextCleaner: Cleaned accumulator 43
18/04/01 20:14:58 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1039
18/04/01 20:14:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 3 (ShuffledRDD[2] at reduceByKey at RefereeStats.scala:60) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:14:58 INFO TaskSchedulerImpl: Adding task set 3.0 with 2 tasks
18/04/01 20:14:58 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.1.3:35449 in memory (size: 1976.0 B, free: 477.3 MB)
18/04/01 20:14:58 INFO ContextCleaner: Cleaned accumulator 39
18/04/01 20:14:58 INFO ContextCleaner: Cleaned accumulator 47
18/04/01 20:14:58 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.1.3:35449 in memory (size: 1976.0 B, free: 477.3 MB)
18/04/01 20:14:58 INFO ContextCleaner: Cleaned accumulator 37
18/04/01 20:14:58 INFO ContextCleaner: Cleaned accumulator 32
18/04/01 20:14:58 INFO ContextCleaner: Cleaned accumulator 41
18/04/01 20:14:58 INFO ContextCleaner: Cleaned accumulator 49
18/04/01 20:14:58 INFO ContextCleaner: Cleaned accumulator 30
18/04/01 20:14:58 INFO ContextCleaner: Cleaned accumulator 35
18/04/01 20:14:58 INFO ContextCleaner: Cleaned accumulator 26
18/04/01 20:14:58 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 10, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:14:58 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 11, localhost, executor driver, partition 1, ANY, 7649 bytes)
18/04/01 20:14:58 INFO Executor: Running task 0.0 in stage 3.0 (TID 10)
18/04/01 20:14:58 INFO Executor: Running task 1.0 in stage 3.0 (TID 11)
18/04/01 20:14:58 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:14:58 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:14:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 28 ms
18/04/01 20:14:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 28 ms
18/04/01 20:14:58 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:14:58 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:14:58 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:14:58 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:14:58 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:14:58 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:14:58 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:14:58 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:14:58 INFO KafkaProducer: [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:14:58 INFO KafkaProducer: [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:14:58 INFO Executor: Finished task 1.0 in stage 3.0 (TID 11). 1181 bytes result sent to driver
18/04/01 20:14:58 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 11) in 365 ms on localhost (executor driver) (1/2)
18/04/01 20:14:58 INFO Executor: Finished task 0.0 in stage 3.0 (TID 10). 1138 bytes result sent to driver
18/04/01 20:14:58 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 10) in 386 ms on localhost (executor driver) (2/2)
18/04/01 20:14:58 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/04/01 20:14:58 INFO DAGScheduler: ResultStage 3 (foreachPartition at RefereeStats.scala:71) finished in 0.437 s
18/04/01 20:14:58 INFO DAGScheduler: Job 2 finished: foreachPartition at RefereeStats.scala:71, took 1.065634 s
18/04/01 20:14:58 INFO JobScheduler: Finished job streaming job 1522602895000 ms.1 from job set of time 1522602895000 ms
18/04/01 20:14:58 INFO JobScheduler: Starting job streaming job 1522602895000 ms.2 from job set of time 1522602895000 ms
18/04/01 20:14:58 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:89
18/04/01 20:14:58 INFO DAGScheduler: Registering RDD 3 (map at RefereeStats.scala:46)
18/04/01 20:14:58 INFO DAGScheduler: Got job 3 (foreachPartition at RefereeStats.scala:89) with 2 output partitions
18/04/01 20:14:58 INFO DAGScheduler: Final stage: ResultStage 5 (foreachPartition at RefereeStats.scala:89)
18/04/01 20:14:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
18/04/01 20:14:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
18/04/01 20:14:58 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[3] at map at RefereeStats.scala:46), which has no missing parents
18/04/01 20:14:58 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 3.9 KB, free 477.3 MB)
18/04/01 20:14:58 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.3 MB)
18/04/01 20:14:58 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:14:58 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1039
18/04/01 20:14:58 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[3] at map at RefereeStats.scala:46) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:14:58 INFO TaskSchedulerImpl: Adding task set 4.0 with 5 tasks
18/04/01 20:14:58 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:14:58 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 13, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:14:58 INFO Executor: Running task 1.0 in stage 4.0 (TID 13)
18/04/01 20:14:58 INFO Executor: Running task 0.0 in stage 4.0 (TID 12)
18/04/01 20:14:58 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:14:58 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:14:58 INFO Executor: Finished task 1.0 in stage 4.0 (TID 13). 938 bytes result sent to driver
18/04/01 20:14:58 INFO Executor: Finished task 0.0 in stage 4.0 (TID 12). 938 bytes result sent to driver
18/04/01 20:14:58 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 14, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:14:58 INFO Executor: Running task 2.0 in stage 4.0 (TID 14)
18/04/01 20:14:58 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 15, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:14:58 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 13) in 27 ms on localhost (executor driver) (1/5)
18/04/01 20:14:58 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 12) in 29 ms on localhost (executor driver) (2/5)
18/04/01 20:14:58 INFO Executor: Running task 3.0 in stage 4.0 (TID 15)
18/04/01 20:14:58 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:14:58 INFO Executor: Finished task 2.0 in stage 4.0 (TID 14). 938 bytes result sent to driver
18/04/01 20:14:58 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 16, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:14:58 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:14:58 INFO Executor: Running task 4.0 in stage 4.0 (TID 16)
18/04/01 20:14:58 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 14) in 30 ms on localhost (executor driver) (3/5)
18/04/01 20:14:58 INFO Executor: Finished task 3.0 in stage 4.0 (TID 15). 981 bytes result sent to driver
18/04/01 20:14:58 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 15) in 38 ms on localhost (executor driver) (4/5)
18/04/01 20:14:58 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 0 -> 701
18/04/01 20:14:58 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 0
18/04/01 20:14:58 INFO Executor: Finished task 4.0 in stage 4.0 (TID 16). 1024 bytes result sent to driver
18/04/01 20:14:58 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 16) in 112 ms on localhost (executor driver) (5/5)
18/04/01 20:14:58 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/04/01 20:14:58 INFO DAGScheduler: ShuffleMapStage 4 (map at RefereeStats.scala:46) finished in 0.194 s
18/04/01 20:14:58 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:14:58 INFO DAGScheduler: running: Set()
18/04/01 20:14:58 INFO DAGScheduler: waiting: Set(ResultStage 5)
18/04/01 20:14:58 INFO DAGScheduler: failed: Set()
18/04/01 20:14:58 INFO DAGScheduler: Submitting ResultStage 5 (ShuffledRDD[4] at reduceByKey at RefereeStats.scala:51), which has no missing parents
18/04/01 20:14:58 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.8 KB, free 477.3 MB)
18/04/01 20:14:58 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1707.0 B, free 477.3 MB)
18/04/01 20:14:58 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.1.3:35449 (size: 1707.0 B, free: 477.3 MB)
18/04/01 20:14:58 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1039
18/04/01 20:14:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 5 (ShuffledRDD[4] at reduceByKey at RefereeStats.scala:51) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:14:58 INFO TaskSchedulerImpl: Adding task set 5.0 with 2 tasks
18/04/01 20:14:58 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 17, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:14:58 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 18, localhost, executor driver, partition 1, ANY, 7649 bytes)
18/04/01 20:14:58 INFO Executor: Running task 0.0 in stage 5.0 (TID 17)
18/04/01 20:14:58 INFO Executor: Running task 1.0 in stage 5.0 (TID 18)
18/04/01 20:14:58 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:14:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:14:58 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:14:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:14:58 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:14:58 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:14:58 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:14:58 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:14:58 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:14:58 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:14:58 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:14:58 INFO KafkaProducer: [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:14:58 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:14:58 INFO KafkaProducer: [Producer clientId=producer-4] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:14:59 INFO Executor: Finished task 0.0 in stage 5.0 (TID 17). 1181 bytes result sent to driver
18/04/01 20:14:59 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 17) in 103 ms on localhost (executor driver) (1/2)
18/04/01 20:14:59 INFO Executor: Finished task 1.0 in stage 5.0 (TID 18). 1138 bytes result sent to driver
18/04/01 20:14:59 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 18) in 123 ms on localhost (executor driver) (2/2)
18/04/01 20:14:59 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
18/04/01 20:14:59 INFO DAGScheduler: ResultStage 5 (foreachPartition at RefereeStats.scala:89) finished in 0.151 s
18/04/01 20:14:59 INFO DAGScheduler: Job 3 finished: foreachPartition at RefereeStats.scala:89, took 0.373192 s
18/04/01 20:14:59 INFO JobScheduler: Finished job streaming job 1522602895000 ms.2 from job set of time 1522602895000 ms
18/04/01 20:14:59 INFO JobScheduler: Starting job streaming job 1522602895000 ms.3 from job set of time 1522602895000 ms
18/04/01 20:14:59 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:106
18/04/01 20:14:59 INFO DAGScheduler: Registering RDD 5 (map at RefereeStats.scala:39)
18/04/01 20:14:59 INFO DAGScheduler: Got job 4 (foreachPartition at RefereeStats.scala:106) with 2 output partitions
18/04/01 20:14:59 INFO DAGScheduler: Final stage: ResultStage 7 (foreachPartition at RefereeStats.scala:106)
18/04/01 20:14:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
18/04/01 20:14:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)
18/04/01 20:14:59 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[5] at map at RefereeStats.scala:39), which has no missing parents
18/04/01 20:14:59 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 3.9 KB, free 477.3 MB)
18/04/01 20:14:59 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.3 MB)
18/04/01 20:14:59 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:14:59 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1039
18/04/01 20:14:59 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[5] at map at RefereeStats.scala:39) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:14:59 INFO TaskSchedulerImpl: Adding task set 6.0 with 5 tasks
18/04/01 20:14:59 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:14:59 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 20, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:14:59 INFO Executor: Running task 1.0 in stage 6.0 (TID 20)
18/04/01 20:14:59 INFO Executor: Running task 0.0 in stage 6.0 (TID 19)
18/04/01 20:14:59 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:14:59 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:14:59 INFO Executor: Finished task 0.0 in stage 6.0 (TID 19). 938 bytes result sent to driver
18/04/01 20:14:59 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 21, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:14:59 INFO Executor: Finished task 1.0 in stage 6.0 (TID 20). 938 bytes result sent to driver
18/04/01 20:14:59 INFO Executor: Running task 2.0 in stage 6.0 (TID 21)
18/04/01 20:14:59 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 19) in 28 ms on localhost (executor driver) (1/5)
18/04/01 20:14:59 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 22, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:14:59 INFO Executor: Running task 3.0 in stage 6.0 (TID 22)
18/04/01 20:14:59 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 20) in 40 ms on localhost (executor driver) (2/5)
18/04/01 20:14:59 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:14:59 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:14:59 INFO Executor: Finished task 3.0 in stage 6.0 (TID 22). 938 bytes result sent to driver
18/04/01 20:14:59 INFO Executor: Finished task 2.0 in stage 6.0 (TID 21). 938 bytes result sent to driver
18/04/01 20:14:59 INFO TaskSetManager: Starting task 4.0 in stage 6.0 (TID 23, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:14:59 INFO Executor: Running task 4.0 in stage 6.0 (TID 23)
18/04/01 20:14:59 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 22) in 18 ms on localhost (executor driver) (3/5)
18/04/01 20:14:59 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 21) in 42 ms on localhost (executor driver) (4/5)
18/04/01 20:14:59 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 0 -> 701
18/04/01 20:14:59 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 0
18/04/01 20:14:59 INFO Executor: Finished task 4.0 in stage 6.0 (TID 23). 1024 bytes result sent to driver
18/04/01 20:14:59 INFO TaskSetManager: Finished task 4.0 in stage 6.0 (TID 23) in 274 ms on localhost (executor driver) (5/5)
18/04/01 20:14:59 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
18/04/01 20:14:59 INFO DAGScheduler: ShuffleMapStage 6 (map at RefereeStats.scala:39) finished in 0.357 s
18/04/01 20:14:59 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:14:59 INFO DAGScheduler: running: Set()
18/04/01 20:14:59 INFO DAGScheduler: waiting: Set(ResultStage 7)
18/04/01 20:14:59 INFO DAGScheduler: failed: Set()
18/04/01 20:14:59 INFO DAGScheduler: Submitting ResultStage 7 (ShuffledRDD[6] at reduceByKey at RefereeStats.scala:43), which has no missing parents
18/04/01 20:14:59 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 2.8 KB, free 477.3 MB)
18/04/01 20:14:59 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 1699.0 B, free 477.3 MB)
18/04/01 20:14:59 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 192.168.1.3:35449 (size: 1699.0 B, free: 477.3 MB)
18/04/01 20:14:59 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1039
18/04/01 20:14:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 7 (ShuffledRDD[6] at reduceByKey at RefereeStats.scala:43) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:14:59 INFO TaskSchedulerImpl: Adding task set 7.0 with 2 tasks
18/04/01 20:14:59 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 24, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:14:59 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 25, localhost, executor driver, partition 1, ANY, 7649 bytes)
18/04/01 20:14:59 INFO Executor: Running task 0.0 in stage 7.0 (TID 24)
18/04/01 20:14:59 INFO Executor: Running task 1.0 in stage 7.0 (TID 25)
18/04/01 20:14:59 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:14:59 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:14:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:14:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:14:59 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:14:59 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:14:59 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:14:59 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:14:59 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:14:59 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:14:59 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:14:59 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:14:59 INFO KafkaProducer: [Producer clientId=producer-5] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:14:59 INFO KafkaProducer: [Producer clientId=producer-6] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:14:59 INFO Executor: Finished task 1.0 in stage 7.0 (TID 25). 1181 bytes result sent to driver
18/04/01 20:14:59 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 25) in 97 ms on localhost (executor driver) (1/2)
18/04/01 20:14:59 INFO Executor: Finished task 0.0 in stage 7.0 (TID 24). 1138 bytes result sent to driver
18/04/01 20:14:59 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 24) in 113 ms on localhost (executor driver) (2/2)
18/04/01 20:14:59 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
18/04/01 20:14:59 INFO DAGScheduler: ResultStage 7 (foreachPartition at RefereeStats.scala:106) finished in 0.133 s
18/04/01 20:14:59 INFO DAGScheduler: Job 4 finished: foreachPartition at RefereeStats.scala:106, took 0.511005 s
18/04/01 20:14:59 INFO JobScheduler: Finished job streaming job 1522602895000 ms.3 from job set of time 1522602895000 ms
18/04/01 20:14:59 INFO JobScheduler: Total delay: 4.567 s for time 1522602895000 ms (execution: 3.541 s)
18/04/01 20:14:59 INFO JobGenerator: Checkpointing graph for time 1522602895000 ms
18/04/01 20:14:59 INFO DStreamGraph: Updating checkpoint data for time 1522602895000 ms
18/04/01 20:14:59 INFO DStreamGraph: Updated checkpoint data for time 1522602895000 ms
18/04/01 20:14:59 INFO CheckpointWriter: Submitted checkpoint of time 1522602895000 ms to writer queue
18/04/01 20:14:59 INFO CheckpointWriter: Saving checkpoint for time 1522602895000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602895000'
18/04/01 20:14:59 INFO CheckpointWriter: Checkpoint for time 1522602895000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602895000', took 5532 bytes and 24 ms
18/04/01 20:14:59 INFO DStreamGraph: Clearing checkpoint data for time 1522602895000 ms
18/04/01 20:14:59 INFO DStreamGraph: Cleared checkpoint data for time 1522602895000 ms
18/04/01 20:14:59 INFO ReceivedBlockTracker: Deleting batches: 
18/04/01 20:14:59 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/tmp/refs-xyzabb/receivedBlockMetadata older than 1522602890000: 
18/04/01 20:14:59 INFO InputInfoTracker: remove old batch metadata: 
18/04/01 20:15:00 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-0 to offset 703.
18/04/01 20:15:00 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-3 to offset 0.
18/04/01 20:15:00 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-4 to offset 0.
18/04/01 20:15:00 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-1 to offset 0.
18/04/01 20:15:00 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-2 to offset 0.
18/04/01 20:15:00 INFO JobScheduler: Added jobs for time 1522602900000 ms
18/04/01 20:15:00 INFO JobGenerator: Checkpointing graph for time 1522602900000 ms
18/04/01 20:15:00 INFO DStreamGraph: Updating checkpoint data for time 1522602900000 ms
18/04/01 20:15:00 INFO DStreamGraph: Updated checkpoint data for time 1522602900000 ms
18/04/01 20:15:00 INFO JobScheduler: Starting job streaming job 1522602900000 ms.0 from job set of time 1522602900000 ms
18/04/01 20:15:00 INFO CheckpointWriter: Saving checkpoint for time 1522602900000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602900000'
18/04/01 20:15:00 INFO CheckpointWriter: Submitted checkpoint of time 1522602900000 ms to writer queue
18/04/01 20:15:00 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:15:00 INFO DAGScheduler: Got job 5 (print at RefereeStats.scala:67) with 1 output partitions
18/04/01 20:15:00 INFO DAGScheduler: Final stage: ResultStage 8 (print at RefereeStats.scala:67)
18/04/01 20:15:00 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:15:00 INFO DAGScheduler: Missing parents: List()
18/04/01 20:15:00 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[8] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:00 INFO CheckpointWriter: Checkpoint for time 1522602900000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602900000', took 5592 bytes and 47 ms
18/04/01 20:15:00 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 3.0 KB, free 477.3 MB)
18/04/01 20:15:00 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 1985.0 B, free 477.3 MB)
18/04/01 20:15:00 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 192.168.1.3:35449 (size: 1985.0 B, free: 477.3 MB)
18/04/01 20:15:00 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[8] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0))
18/04/01 20:15:00 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
18/04/01 20:15:00 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:00 INFO Executor: Running task 0.0 in stage 8.0 (TID 26)
18/04/01 20:15:00 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:00 INFO Executor: Finished task 0.0 in stage 8.0 (TID 26). 704 bytes result sent to driver
18/04/01 20:15:00 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 26) in 10 ms on localhost (executor driver) (1/1)
18/04/01 20:15:00 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
18/04/01 20:15:00 INFO DAGScheduler: ResultStage 8 (print at RefereeStats.scala:67) finished in 0.038 s
18/04/01 20:15:00 INFO DAGScheduler: Job 5 finished: print at RefereeStats.scala:67, took 0.051512 s
18/04/01 20:15:00 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:15:00 INFO DAGScheduler: Got job 6 (print at RefereeStats.scala:67) with 4 output partitions
18/04/01 20:15:00 INFO DAGScheduler: Final stage: ResultStage 9 (print at RefereeStats.scala:67)
18/04/01 20:15:00 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:15:00 INFO DAGScheduler: Missing parents: List()
18/04/01 20:15:00 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[8] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:00 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 3.0 KB, free 477.3 MB)
18/04/01 20:15:00 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 1985.0 B, free 477.3 MB)
18/04/01 20:15:00 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 192.168.1.3:35449 (size: 1985.0 B, free: 477.3 MB)
18/04/01 20:15:00 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:00 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 9 (MapPartitionsRDD[8] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
18/04/01 20:15:00 INFO TaskSchedulerImpl: Adding task set 9.0 with 4 tasks
18/04/01 20:15:00 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 27, localhost, executor driver, partition 1, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:00 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 28, localhost, executor driver, partition 2, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:00 INFO Executor: Running task 1.0 in stage 9.0 (TID 28)
18/04/01 20:15:00 INFO Executor: Running task 0.0 in stage 9.0 (TID 27)
18/04/01 20:15:00 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:00 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:00 INFO Executor: Finished task 0.0 in stage 9.0 (TID 27). 704 bytes result sent to driver
18/04/01 20:15:00 INFO Executor: Finished task 1.0 in stage 9.0 (TID 28). 704 bytes result sent to driver
18/04/01 20:15:00 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 29, localhost, executor driver, partition 3, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:00 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 27) in 22 ms on localhost (executor driver) (1/4)
18/04/01 20:15:00 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 30, localhost, executor driver, partition 4, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:00 INFO Executor: Running task 3.0 in stage 9.0 (TID 30)
18/04/01 20:15:00 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 28) in 26 ms on localhost (executor driver) (2/4)
18/04/01 20:15:00 INFO Executor: Running task 2.0 in stage 9.0 (TID 29)
18/04/01 20:15:00 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 701 -> 703
18/04/01 20:15:00 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:00 INFO Executor: Finished task 2.0 in stage 9.0 (TID 29). 704 bytes result sent to driver
18/04/01 20:15:00 INFO Executor: Finished task 3.0 in stage 9.0 (TID 30). 896 bytes result sent to driver
18/04/01 20:15:00 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 29) in 41 ms on localhost (executor driver) (3/4)
18/04/01 20:15:00 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 30) in 36 ms on localhost (executor driver) (4/4)
18/04/01 20:15:00 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
18/04/01 20:15:00 INFO DAGScheduler: ResultStage 9 (print at RefereeStats.scala:67) finished in 0.108 s
-------------------------------------------
Time: 1522602900000 ms
-------------------------------------------
(nextanalytics.com,0)
(vk.com,5000)

18/04/01 20:15:00 INFO DAGScheduler: Job 6 finished: print at RefereeStats.scala:67, took 0.122263 s
18/04/01 20:15:00 INFO JobScheduler: Finished job streaming job 1522602900000 ms.0 from job set of time 1522602900000 ms
18/04/01 20:15:00 INFO JobScheduler: Starting job streaming job 1522602900000 ms.1 from job set of time 1522602900000 ms
18/04/01 20:15:00 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:71
18/04/01 20:15:00 INFO DAGScheduler: Registering RDD 8 (map at RefereeStats.scala:53)
18/04/01 20:15:00 INFO DAGScheduler: Got job 7 (foreachPartition at RefereeStats.scala:71) with 2 output partitions
18/04/01 20:15:00 INFO DAGScheduler: Final stage: ResultStage 11 (foreachPartition at RefereeStats.scala:71)
18/04/01 20:15:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
18/04/01 20:15:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
18/04/01 20:15:00 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[8] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:00 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 3.9 KB, free 477.3 MB)
18/04/01 20:15:00 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.3 MB)
18/04/01 20:15:00 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:00 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:00 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[8] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:00 INFO TaskSchedulerImpl: Adding task set 10.0 with 5 tasks
18/04/01 20:15:00 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:00 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 32, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:00 INFO Executor: Running task 1.0 in stage 10.0 (TID 32)
18/04/01 20:15:00 INFO Executor: Running task 0.0 in stage 10.0 (TID 31)
18/04/01 20:15:00 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:00 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:00 INFO Executor: Finished task 0.0 in stage 10.0 (TID 31). 938 bytes result sent to driver
18/04/01 20:15:00 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 33, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:00 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 31) in 21 ms on localhost (executor driver) (1/5)
18/04/01 20:15:00 INFO Executor: Running task 2.0 in stage 10.0 (TID 33)
18/04/01 20:15:00 INFO Executor: Finished task 1.0 in stage 10.0 (TID 32). 938 bytes result sent to driver
18/04/01 20:15:00 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 34, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:00 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 32) in 29 ms on localhost (executor driver) (2/5)
18/04/01 20:15:00 INFO Executor: Running task 3.0 in stage 10.0 (TID 34)
18/04/01 20:15:00 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:00 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:00 INFO Executor: Finished task 2.0 in stage 10.0 (TID 33). 981 bytes result sent to driver
18/04/01 20:15:00 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 35, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:00 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 33) in 27 ms on localhost (executor driver) (3/5)
18/04/01 20:15:00 INFO Executor: Running task 4.0 in stage 10.0 (TID 35)
18/04/01 20:15:00 INFO Executor: Finished task 3.0 in stage 10.0 (TID 34). 938 bytes result sent to driver
18/04/01 20:15:00 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 34) in 28 ms on localhost (executor driver) (4/5)
18/04/01 20:15:00 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 701 -> 703
18/04/01 20:15:00 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 701
18/04/01 20:15:00 INFO Executor: Finished task 4.0 in stage 10.0 (TID 35). 1024 bytes result sent to driver
18/04/01 20:15:00 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 35) in 397 ms on localhost (executor driver) (5/5)
18/04/01 20:15:00 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
18/04/01 20:15:00 INFO DAGScheduler: ShuffleMapStage 10 (map at RefereeStats.scala:53) finished in 0.469 s
18/04/01 20:15:00 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:00 INFO DAGScheduler: running: Set()
18/04/01 20:15:00 INFO DAGScheduler: waiting: Set(ResultStage 11)
18/04/01 20:15:00 INFO DAGScheduler: failed: Set()
18/04/01 20:15:00 INFO DAGScheduler: Submitting ResultStage 11 (ShuffledRDD[9] at reduceByKey at RefereeStats.scala:60), which has no missing parents
18/04/01 20:15:00 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 2.8 KB, free 477.3 MB)
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 198
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 208
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 124
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 220
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 200
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 132
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 123
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 207
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 101
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 214
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 145
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 112
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 121
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 209
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 216
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 111
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 110
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 144
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 133
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 247
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 166
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 181
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 164
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 175
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 180
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 125
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 114
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 194
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 115
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 240
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 106
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 154
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 108
18/04/01 20:15:00 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 192.168.1.3:35449 in memory (size: 1719.0 B, free: 477.3 MB)
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 197
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 169
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 229
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 141
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 167
18/04/01 20:15:00 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 192.168.1.3:35449 in memory (size: 1699.0 B, free: 477.3 MB)
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 178
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 217
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 131
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 248
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 150
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 117
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 138
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 224
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 242
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 100
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 128
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 244
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 103
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 153
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 189
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 187
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 142
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 182
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 184
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 139
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 202
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 176
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 241
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 232
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 119
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 206
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 186
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 193
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 156
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 126
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 137
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 152
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 243
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 120
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 161
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 168
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 249
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 162
18/04/01 20:15:00 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 1706.0 B, free 477.3 MB)
18/04/01 20:15:00 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 192.168.1.3:35449 (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:15:00 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 192.168.1.3:35449 in memory (size: 1707.0 B, free: 477.3 MB)
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 238
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 130
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 185
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 235
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 196
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 204
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 245
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 227
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 221
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 246
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 105
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 203
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 212
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 149
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 109
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 222
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 173
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 237
18/04/01 20:15:00 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 192.168.1.3:35449 in memory (size: 1985.0 B, free: 477.3 MB)
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 113
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 195
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 199
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 210
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 148
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 147
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 233
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 136
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 129
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 165
18/04/01 20:15:00 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 146
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 118
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 218
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 122
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 151
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 170
18/04/01 20:15:00 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 134
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 160
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 135
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 205
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 236
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 192
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 225
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 179
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 183
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 223
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 174
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 188
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 226
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 213
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 239
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 171
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 157
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 155
18/04/01 20:15:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 11 (ShuffledRDD[9] at reduceByKey at RefereeStats.scala:60) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:00 INFO TaskSchedulerImpl: Adding task set 11.0 with 2 tasks
18/04/01 20:15:00 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 192.168.1.3:35449 in memory (size: 1985.0 B, free: 477.3 MB)
18/04/01 20:15:00 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 36, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:15:00 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 37, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:15:00 INFO Executor: Running task 1.0 in stage 11.0 (TID 36)
18/04/01 20:15:00 INFO Executor: Running task 0.0 in stage 11.0 (TID 37)
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 219
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 230
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 163
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 140
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 201
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 211
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 159
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 228
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 215
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 116
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 191
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 158
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 234
18/04/01 20:15:00 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:15:00 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:15:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:15:00 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:00 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:00 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 190
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 102
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 172
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 127
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 143
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 104
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 107
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 177
18/04/01 20:15:00 INFO ContextCleaner: Cleaned accumulator 231
18/04/01 20:15:00 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:00 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:00 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:00 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:00 INFO KafkaProducer: [Producer clientId=producer-8] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:00 INFO Executor: Finished task 1.0 in stage 11.0 (TID 36). 1138 bytes result sent to driver
18/04/01 20:15:00 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 36) in 64 ms on localhost (executor driver) (1/2)
18/04/01 20:15:00 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:00 INFO KafkaProducer: [Producer clientId=producer-7] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:01 INFO Executor: Finished task 0.0 in stage 11.0 (TID 37). 1138 bytes result sent to driver
18/04/01 20:15:01 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 37) in 103 ms on localhost (executor driver) (2/2)
18/04/01 20:15:01 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
18/04/01 20:15:01 INFO DAGScheduler: ResultStage 11 (foreachPartition at RefereeStats.scala:71) finished in 0.193 s
18/04/01 20:15:01 INFO DAGScheduler: Job 7 finished: foreachPartition at RefereeStats.scala:71, took 0.689866 s
18/04/01 20:15:01 INFO JobScheduler: Finished job streaming job 1522602900000 ms.1 from job set of time 1522602900000 ms
18/04/01 20:15:01 INFO JobScheduler: Starting job streaming job 1522602900000 ms.2 from job set of time 1522602900000 ms
18/04/01 20:15:01 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:89
18/04/01 20:15:01 INFO DAGScheduler: Registering RDD 10 (map at RefereeStats.scala:46)
18/04/01 20:15:01 INFO DAGScheduler: Got job 8 (foreachPartition at RefereeStats.scala:89) with 2 output partitions
18/04/01 20:15:01 INFO DAGScheduler: Final stage: ResultStage 13 (foreachPartition at RefereeStats.scala:89)
18/04/01 20:15:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
18/04/01 20:15:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
18/04/01 20:15:01 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[10] at map at RefereeStats.scala:46), which has no missing parents
18/04/01 20:15:01 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 3.9 KB, free 477.3 MB)
18/04/01 20:15:01 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.3 MB)
18/04/01 20:15:01 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:01 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:01 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[10] at map at RefereeStats.scala:46) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:01 INFO TaskSchedulerImpl: Adding task set 12.0 with 5 tasks
18/04/01 20:15:01 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:01 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 39, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:01 INFO Executor: Running task 1.0 in stage 12.0 (TID 39)
18/04/01 20:15:01 INFO Executor: Running task 0.0 in stage 12.0 (TID 38)
18/04/01 20:15:01 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:01 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:01 INFO Executor: Finished task 1.0 in stage 12.0 (TID 39). 938 bytes result sent to driver
18/04/01 20:15:01 INFO Executor: Finished task 0.0 in stage 12.0 (TID 38). 938 bytes result sent to driver
18/04/01 20:15:01 INFO TaskSetManager: Starting task 2.0 in stage 12.0 (TID 40, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:01 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 39) in 29 ms on localhost (executor driver) (1/5)
18/04/01 20:15:01 INFO Executor: Running task 2.0 in stage 12.0 (TID 40)
18/04/01 20:15:01 INFO TaskSetManager: Starting task 3.0 in stage 12.0 (TID 41, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:01 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 38) in 41 ms on localhost (executor driver) (2/5)
18/04/01 20:15:01 INFO Executor: Running task 3.0 in stage 12.0 (TID 41)
18/04/01 20:15:01 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:01 INFO Executor: Finished task 2.0 in stage 12.0 (TID 40). 981 bytes result sent to driver
18/04/01 20:15:01 INFO TaskSetManager: Starting task 4.0 in stage 12.0 (TID 42, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:01 INFO Executor: Running task 4.0 in stage 12.0 (TID 42)
18/04/01 20:15:01 INFO TaskSetManager: Finished task 2.0 in stage 12.0 (TID 40) in 25 ms on localhost (executor driver) (3/5)
18/04/01 20:15:01 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:01 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 701 -> 703
18/04/01 20:15:01 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 701
18/04/01 20:15:01 INFO Executor: Finished task 3.0 in stage 12.0 (TID 41). 938 bytes result sent to driver
18/04/01 20:15:01 INFO TaskSetManager: Finished task 3.0 in stage 12.0 (TID 41) in 30 ms on localhost (executor driver) (4/5)
18/04/01 20:15:01 INFO Executor: Finished task 4.0 in stage 12.0 (TID 42). 1024 bytes result sent to driver
18/04/01 20:15:01 INFO TaskSetManager: Finished task 4.0 in stage 12.0 (TID 42) in 183 ms on localhost (executor driver) (5/5)
18/04/01 20:15:01 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
18/04/01 20:15:01 INFO DAGScheduler: ShuffleMapStage 12 (map at RefereeStats.scala:46) finished in 0.255 s
18/04/01 20:15:01 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:01 INFO DAGScheduler: running: Set()
18/04/01 20:15:01 INFO DAGScheduler: waiting: Set(ResultStage 13)
18/04/01 20:15:01 INFO DAGScheduler: failed: Set()
18/04/01 20:15:01 INFO DAGScheduler: Submitting ResultStage 13 (ShuffledRDD[11] at reduceByKey at RefereeStats.scala:51), which has no missing parents
18/04/01 20:15:01 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 2.8 KB, free 477.3 MB)
18/04/01 20:15:01 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 1709.0 B, free 477.3 MB)
18/04/01 20:15:01 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 192.168.1.3:35449 (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:15:01 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:01 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 13 (ShuffledRDD[11] at reduceByKey at RefereeStats.scala:51) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:01 INFO TaskSchedulerImpl: Adding task set 13.0 with 2 tasks
18/04/01 20:15:01 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 43, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:15:01 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 44, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:15:01 INFO Executor: Running task 1.0 in stage 13.0 (TID 43)
18/04/01 20:15:01 INFO Executor: Running task 0.0 in stage 13.0 (TID 44)
18/04/01 20:15:01 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:01 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:15:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:01 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:01 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:01 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:01 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:01 INFO KafkaProducer: [Producer clientId=producer-9] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:01 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:01 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:01 INFO Executor: Finished task 1.0 in stage 13.0 (TID 43). 1138 bytes result sent to driver
18/04/01 20:15:01 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 43) in 69 ms on localhost (executor driver) (1/2)
18/04/01 20:15:01 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:01 INFO KafkaProducer: [Producer clientId=producer-10] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:01 INFO Executor: Finished task 0.0 in stage 13.0 (TID 44). 1138 bytes result sent to driver
18/04/01 20:15:01 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 44) in 94 ms on localhost (executor driver) (2/2)
18/04/01 20:15:01 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
18/04/01 20:15:01 INFO DAGScheduler: ResultStage 13 (foreachPartition at RefereeStats.scala:89) finished in 0.116 s
18/04/01 20:15:01 INFO DAGScheduler: Job 8 finished: foreachPartition at RefereeStats.scala:89, took 0.406836 s
18/04/01 20:15:01 INFO JobScheduler: Finished job streaming job 1522602900000 ms.2 from job set of time 1522602900000 ms
18/04/01 20:15:01 INFO JobScheduler: Starting job streaming job 1522602900000 ms.3 from job set of time 1522602900000 ms
18/04/01 20:15:01 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:106
18/04/01 20:15:01 INFO DAGScheduler: Registering RDD 12 (map at RefereeStats.scala:39)
18/04/01 20:15:01 INFO DAGScheduler: Got job 9 (foreachPartition at RefereeStats.scala:106) with 2 output partitions
18/04/01 20:15:01 INFO DAGScheduler: Final stage: ResultStage 15 (foreachPartition at RefereeStats.scala:106)
18/04/01 20:15:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
18/04/01 20:15:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 14)
18/04/01 20:15:01 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[12] at map at RefereeStats.scala:39), which has no missing parents
18/04/01 20:15:01 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 3.9 KB, free 477.3 MB)
18/04/01 20:15:01 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.3 MB)
18/04/01 20:15:01 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:01 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:01 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[12] at map at RefereeStats.scala:39) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:01 INFO TaskSchedulerImpl: Adding task set 14.0 with 5 tasks
18/04/01 20:15:01 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 45, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:01 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 46, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:01 INFO Executor: Running task 1.0 in stage 14.0 (TID 46)
18/04/01 20:15:01 INFO Executor: Running task 0.0 in stage 14.0 (TID 45)
18/04/01 20:15:01 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:01 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:01 INFO Executor: Finished task 0.0 in stage 14.0 (TID 45). 938 bytes result sent to driver
18/04/01 20:15:01 INFO TaskSetManager: Starting task 2.0 in stage 14.0 (TID 47, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:01 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 45) in 15 ms on localhost (executor driver) (1/5)
18/04/01 20:15:01 INFO Executor: Running task 2.0 in stage 14.0 (TID 47)
18/04/01 20:15:01 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:01 INFO Executor: Finished task 2.0 in stage 14.0 (TID 47). 938 bytes result sent to driver
18/04/01 20:15:01 INFO TaskSetManager: Starting task 3.0 in stage 14.0 (TID 48, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:01 INFO TaskSetManager: Finished task 2.0 in stage 14.0 (TID 47) in 18 ms on localhost (executor driver) (2/5)
18/04/01 20:15:01 INFO Executor: Running task 3.0 in stage 14.0 (TID 48)
18/04/01 20:15:01 INFO Executor: Finished task 1.0 in stage 14.0 (TID 46). 938 bytes result sent to driver
18/04/01 20:15:01 INFO TaskSetManager: Starting task 4.0 in stage 14.0 (TID 49, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:01 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 46) in 35 ms on localhost (executor driver) (3/5)
18/04/01 20:15:01 INFO Executor: Running task 4.0 in stage 14.0 (TID 49)
18/04/01 20:15:01 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:01 INFO Executor: Finished task 3.0 in stage 14.0 (TID 48). 938 bytes result sent to driver
18/04/01 20:15:01 INFO TaskSetManager: Finished task 3.0 in stage 14.0 (TID 48) in 26 ms on localhost (executor driver) (4/5)
18/04/01 20:15:01 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 701 -> 703
18/04/01 20:15:01 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 701
18/04/01 20:15:01 INFO Executor: Finished task 4.0 in stage 14.0 (TID 49). 1024 bytes result sent to driver
18/04/01 20:15:01 INFO TaskSetManager: Finished task 4.0 in stage 14.0 (TID 49) in 278 ms on localhost (executor driver) (5/5)
18/04/01 20:15:01 INFO DAGScheduler: ShuffleMapStage 14 (map at RefereeStats.scala:39) finished in 0.329 s
18/04/01 20:15:01 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:01 INFO DAGScheduler: running: Set()
18/04/01 20:15:01 INFO DAGScheduler: waiting: Set(ResultStage 15)
18/04/01 20:15:01 INFO DAGScheduler: failed: Set()
18/04/01 20:15:01 INFO DAGScheduler: Submitting ResultStage 15 (ShuffledRDD[13] at reduceByKey at RefereeStats.scala:43), which has no missing parents
18/04/01 20:15:01 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
18/04/01 20:15:01 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 2.8 KB, free 477.3 MB)
18/04/01 20:15:01 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 1701.0 B, free 477.3 MB)
18/04/01 20:15:01 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 192.168.1.3:35449 (size: 1701.0 B, free: 477.3 MB)
18/04/01 20:15:01 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:01 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 15 (ShuffledRDD[13] at reduceByKey at RefereeStats.scala:43) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:01 INFO TaskSchedulerImpl: Adding task set 15.0 with 2 tasks
18/04/01 20:15:01 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 50, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:15:01 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 51, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:15:01 INFO Executor: Running task 0.0 in stage 15.0 (TID 51)
18/04/01 20:15:01 INFO Executor: Running task 1.0 in stage 15.0 (TID 50)
18/04/01 20:15:01 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:15:01 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:01 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:01 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:01 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:01 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:01 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:01 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:01 INFO KafkaProducer: [Producer clientId=producer-11] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:01 INFO Executor: Finished task 1.0 in stage 15.0 (TID 50). 1138 bytes result sent to driver
18/04/01 20:15:01 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 50) in 51 ms on localhost (executor driver) (1/2)
18/04/01 20:15:01 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:01 INFO KafkaProducer: [Producer clientId=producer-12] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:01 INFO Executor: Finished task 0.0 in stage 15.0 (TID 51). 1138 bytes result sent to driver
18/04/01 20:15:01 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 51) in 79 ms on localhost (executor driver) (2/2)
18/04/01 20:15:01 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
18/04/01 20:15:01 INFO DAGScheduler: ResultStage 15 (foreachPartition at RefereeStats.scala:106) finished in 0.102 s
18/04/01 20:15:01 INFO DAGScheduler: Job 9 finished: foreachPartition at RefereeStats.scala:106, took 0.456592 s
18/04/01 20:15:01 INFO JobScheduler: Finished job streaming job 1522602900000 ms.3 from job set of time 1522602900000 ms
18/04/01 20:15:01 INFO JobScheduler: Total delay: 1.920 s for time 1522602900000 ms (execution: 1.862 s)
18/04/01 20:15:01 INFO MapPartitionsRDD: Removing RDD 1 from persistence list
18/04/01 20:15:01 INFO BlockManager: Removing RDD 1
18/04/01 20:15:01 INFO KafkaRDD: Removing RDD 0 from persistence list
18/04/01 20:15:01 INFO BlockManager: Removing RDD 0
18/04/01 20:15:01 INFO ShuffledRDD: Removing RDD 2 from persistence list
18/04/01 20:15:01 INFO BlockManager: Removing RDD 2
18/04/01 20:15:01 INFO ShuffledRDD: Removing RDD 4 from persistence list
18/04/01 20:15:01 INFO BlockManager: Removing RDD 4
18/04/01 20:15:01 INFO MapPartitionsRDD: Removing RDD 3 from persistence list
18/04/01 20:15:01 INFO BlockManager: Removing RDD 3
18/04/01 20:15:01 INFO ShuffledRDD: Removing RDD 6 from persistence list
18/04/01 20:15:01 INFO BlockManager: Removing RDD 6
18/04/01 20:15:01 INFO MapPartitionsRDD: Removing RDD 5 from persistence list
18/04/01 20:15:01 INFO BlockManager: Removing RDD 5
18/04/01 20:15:01 INFO JobGenerator: Checkpointing graph for time 1522602900000 ms
18/04/01 20:15:01 INFO DStreamGraph: Updating checkpoint data for time 1522602900000 ms
18/04/01 20:15:01 INFO DStreamGraph: Updated checkpoint data for time 1522602900000 ms
18/04/01 20:15:01 INFO CheckpointWriter: Saving checkpoint for time 1522602900000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602900000'
18/04/01 20:15:01 INFO CheckpointWriter: Submitted checkpoint of time 1522602900000 ms to writer queue
18/04/01 20:15:02 INFO CheckpointWriter: Checkpoint for time 1522602900000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602900000', took 5536 bytes and 33 ms
18/04/01 20:15:02 INFO DStreamGraph: Clearing checkpoint data for time 1522602900000 ms
18/04/01 20:15:02 INFO DStreamGraph: Cleared checkpoint data for time 1522602900000 ms
18/04/01 20:15:02 INFO ReceivedBlockTracker: Deleting batches: 
18/04/01 20:15:02 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/tmp/refs-xyzabb/receivedBlockMetadata older than 1522602895000: 
18/04/01 20:15:02 INFO InputInfoTracker: remove old batch metadata: 
18/04/01 20:15:05 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-0 to offset 705.
18/04/01 20:15:05 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-3 to offset 0.
18/04/01 20:15:05 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-4 to offset 0.
18/04/01 20:15:05 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-1 to offset 0.
18/04/01 20:15:05 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-2 to offset 0.
18/04/01 20:15:05 INFO JobScheduler: Added jobs for time 1522602905000 ms
18/04/01 20:15:05 INFO JobGenerator: Checkpointing graph for time 1522602905000 ms
18/04/01 20:15:05 INFO DStreamGraph: Updating checkpoint data for time 1522602905000 ms
18/04/01 20:15:05 INFO JobScheduler: Starting job streaming job 1522602905000 ms.0 from job set of time 1522602905000 ms
18/04/01 20:15:05 INFO DStreamGraph: Updated checkpoint data for time 1522602905000 ms
18/04/01 20:15:05 INFO CheckpointWriter: Submitted checkpoint of time 1522602905000 ms to writer queue
18/04/01 20:15:05 INFO CheckpointWriter: Saving checkpoint for time 1522602905000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602905000'
18/04/01 20:15:05 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:15:05 INFO DAGScheduler: Got job 10 (print at RefereeStats.scala:67) with 1 output partitions
18/04/01 20:15:05 INFO DAGScheduler: Final stage: ResultStage 16 (print at RefereeStats.scala:67)
18/04/01 20:15:05 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:15:05 INFO DAGScheduler: Missing parents: List()
18/04/01 20:15:05 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[15] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:05 INFO CheckpointWriter: Checkpoint for time 1522602905000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602905000', took 5593 bytes and 35 ms
18/04/01 20:15:05 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 3.0 KB, free 477.3 MB)
18/04/01 20:15:05 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.3 MB)
18/04/01 20:15:05 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:05 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[15] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0))
18/04/01 20:15:05 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
18/04/01 20:15:05 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 52, localhost, executor driver, partition 0, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:05 INFO Executor: Running task 0.0 in stage 16.0 (TID 52)
18/04/01 20:15:05 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:05 INFO Executor: Finished task 0.0 in stage 16.0 (TID 52). 704 bytes result sent to driver
18/04/01 20:15:05 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 52) in 10 ms on localhost (executor driver) (1/1)
18/04/01 20:15:05 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
18/04/01 20:15:05 INFO DAGScheduler: ResultStage 16 (print at RefereeStats.scala:67) finished in 0.026 s
18/04/01 20:15:05 INFO DAGScheduler: Job 10 finished: print at RefereeStats.scala:67, took 0.041545 s
18/04/01 20:15:05 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:15:05 INFO DAGScheduler: Got job 11 (print at RefereeStats.scala:67) with 4 output partitions
18/04/01 20:15:05 INFO DAGScheduler: Final stage: ResultStage 17 (print at RefereeStats.scala:67)
18/04/01 20:15:05 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:15:05 INFO DAGScheduler: Missing parents: List()
18/04/01 20:15:05 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[15] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:05 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 3.0 KB, free 477.3 MB)
18/04/01 20:15:05 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.3 MB)
18/04/01 20:15:05 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:05 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:05 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 17 (MapPartitionsRDD[15] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
18/04/01 20:15:05 INFO TaskSchedulerImpl: Adding task set 17.0 with 4 tasks
18/04/01 20:15:05 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 53, localhost, executor driver, partition 1, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:05 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 54, localhost, executor driver, partition 2, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:05 INFO Executor: Running task 0.0 in stage 17.0 (TID 53)
18/04/01 20:15:05 INFO Executor: Running task 1.0 in stage 17.0 (TID 54)
18/04/01 20:15:05 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:05 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:05 INFO Executor: Finished task 0.0 in stage 17.0 (TID 53). 747 bytes result sent to driver
18/04/01 20:15:05 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 55, localhost, executor driver, partition 3, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:05 INFO Executor: Running task 2.0 in stage 17.0 (TID 55)
18/04/01 20:15:05 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 53) in 11 ms on localhost (executor driver) (1/4)
18/04/01 20:15:05 INFO Executor: Finished task 1.0 in stage 17.0 (TID 54). 704 bytes result sent to driver
18/04/01 20:15:05 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:05 INFO TaskSetManager: Starting task 3.0 in stage 17.0 (TID 56, localhost, executor driver, partition 4, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:05 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 54) in 19 ms on localhost (executor driver) (2/4)
18/04/01 20:15:05 INFO Executor: Running task 3.0 in stage 17.0 (TID 56)
18/04/01 20:15:05 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 703 -> 705
18/04/01 20:15:05 INFO Executor: Finished task 2.0 in stage 17.0 (TID 55). 704 bytes result sent to driver
18/04/01 20:15:05 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 55) in 33 ms on localhost (executor driver) (3/4)
18/04/01 20:15:05 INFO Executor: Finished task 3.0 in stage 17.0 (TID 56). 899 bytes result sent to driver
18/04/01 20:15:05 INFO TaskSetManager: Finished task 3.0 in stage 17.0 (TID 56) in 28 ms on localhost (executor driver) (4/4)
18/04/01 20:15:05 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
18/04/01 20:15:05 INFO DAGScheduler: ResultStage 17 (print at RefereeStats.scala:67) finished in 0.082 s
18/04/01 20:15:05 INFO DAGScheduler: Job 11 finished: print at RefereeStats.scala:67, took 0.093117 s
18/04/01 20:15:05 INFO JobScheduler: Finished job streaming job 1522602905000 ms.0 from job set of time 1522602905000 ms
-------------------------------------------
Time: 1522602905000 ms
-------------------------------------------
(nextanalytics.com,6000)
(quora.com,0)

18/04/01 20:15:05 INFO JobScheduler: Starting job streaming job 1522602905000 ms.1 from job set of time 1522602905000 ms
18/04/01 20:15:05 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:71
18/04/01 20:15:05 INFO DAGScheduler: Registering RDD 15 (map at RefereeStats.scala:53)
18/04/01 20:15:05 INFO DAGScheduler: Got job 12 (foreachPartition at RefereeStats.scala:71) with 2 output partitions
18/04/01 20:15:05 INFO DAGScheduler: Final stage: ResultStage 19 (foreachPartition at RefereeStats.scala:71)
18/04/01 20:15:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
18/04/01 20:15:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 18)
18/04/01 20:15:05 INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[15] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:05 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:15:05 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:15:05 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:05 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:05 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[15] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:05 INFO TaskSchedulerImpl: Adding task set 18.0 with 5 tasks
18/04/01 20:15:05 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 57, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:05 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 58, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:05 INFO Executor: Running task 0.0 in stage 18.0 (TID 57)
18/04/01 20:15:05 INFO Executor: Running task 1.0 in stage 18.0 (TID 58)
18/04/01 20:15:05 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:05 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:05 INFO Executor: Finished task 0.0 in stage 18.0 (TID 57). 938 bytes result sent to driver
18/04/01 20:15:05 INFO Executor: Finished task 1.0 in stage 18.0 (TID 58). 938 bytes result sent to driver
18/04/01 20:15:05 INFO TaskSetManager: Starting task 2.0 in stage 18.0 (TID 59, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:05 INFO Executor: Running task 2.0 in stage 18.0 (TID 59)
18/04/01 20:15:05 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 57) in 22 ms on localhost (executor driver) (1/5)
18/04/01 20:15:05 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:05 INFO TaskSetManager: Starting task 3.0 in stage 18.0 (TID 60, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:05 INFO Executor: Running task 3.0 in stage 18.0 (TID 60)
18/04/01 20:15:05 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 58) in 31 ms on localhost (executor driver) (2/5)
18/04/01 20:15:05 INFO Executor: Finished task 2.0 in stage 18.0 (TID 59). 938 bytes result sent to driver
18/04/01 20:15:05 INFO TaskSetManager: Starting task 4.0 in stage 18.0 (TID 61, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:05 INFO Executor: Running task 4.0 in stage 18.0 (TID 61)
18/04/01 20:15:05 INFO TaskSetManager: Finished task 2.0 in stage 18.0 (TID 59) in 24 ms on localhost (executor driver) (3/5)
18/04/01 20:15:05 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:05 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 703 -> 705
18/04/01 20:15:05 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 703
18/04/01 20:15:05 INFO Executor: Finished task 3.0 in stage 18.0 (TID 60). 938 bytes result sent to driver
18/04/01 20:15:05 INFO TaskSetManager: Finished task 3.0 in stage 18.0 (TID 60) in 25 ms on localhost (executor driver) (4/5)
18/04/01 20:15:05 INFO Executor: Finished task 4.0 in stage 18.0 (TID 61). 1024 bytes result sent to driver
18/04/01 20:15:05 INFO TaskSetManager: Finished task 4.0 in stage 18.0 (TID 61) in 385 ms on localhost (executor driver) (5/5)
18/04/01 20:15:05 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
18/04/01 20:15:05 INFO DAGScheduler: ShuffleMapStage 18 (map at RefereeStats.scala:53) finished in 0.455 s
18/04/01 20:15:05 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:05 INFO DAGScheduler: running: Set()
18/04/01 20:15:05 INFO DAGScheduler: waiting: Set(ResultStage 19)
18/04/01 20:15:05 INFO DAGScheduler: failed: Set()
18/04/01 20:15:05 INFO DAGScheduler: Submitting ResultStage 19 (ShuffledRDD[16] at reduceByKey at RefereeStats.scala:60), which has no missing parents
18/04/01 20:15:05 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:15:05 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 1706.0 B, free 477.2 MB)
18/04/01 20:15:05 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 192.168.1.3:35449 (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:15:05 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 19 (ShuffledRDD[16] at reduceByKey at RefereeStats.scala:60) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:05 INFO TaskSchedulerImpl: Adding task set 19.0 with 2 tasks
18/04/01 20:15:05 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 62, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:15:05 INFO TaskSetManager: Starting task 1.0 in stage 19.0 (TID 63, localhost, executor driver, partition 1, ANY, 7649 bytes)
18/04/01 20:15:05 INFO Executor: Running task 0.0 in stage 19.0 (TID 62)
18/04/01 20:15:05 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:05 INFO Executor: Running task 1.0 in stage 19.0 (TID 63)
18/04/01 20:15:05 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:15:05 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:05 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:05 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:05 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:05 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:05 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:05 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:05 INFO KafkaProducer: [Producer clientId=producer-13] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:05 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:05 INFO KafkaProducer: [Producer clientId=producer-14] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:05 INFO Executor: Finished task 1.0 in stage 19.0 (TID 63). 1138 bytes result sent to driver
18/04/01 20:15:05 INFO TaskSetManager: Finished task 1.0 in stage 19.0 (TID 63) in 88 ms on localhost (executor driver) (1/2)
18/04/01 20:15:05 INFO Executor: Finished task 0.0 in stage 19.0 (TID 62). 1138 bytes result sent to driver
18/04/01 20:15:05 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 62) in 100 ms on localhost (executor driver) (2/2)
18/04/01 20:15:05 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
18/04/01 20:15:05 INFO DAGScheduler: ResultStage 19 (foreachPartition at RefereeStats.scala:71) finished in 0.123 s
18/04/01 20:15:05 INFO DAGScheduler: Job 12 finished: foreachPartition at RefereeStats.scala:71, took 0.598774 s
18/04/01 20:15:05 INFO JobScheduler: Finished job streaming job 1522602905000 ms.1 from job set of time 1522602905000 ms
18/04/01 20:15:05 INFO JobScheduler: Starting job streaming job 1522602905000 ms.2 from job set of time 1522602905000 ms
18/04/01 20:15:05 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:89
18/04/01 20:15:05 INFO DAGScheduler: Registering RDD 17 (map at RefereeStats.scala:46)
18/04/01 20:15:05 INFO DAGScheduler: Got job 13 (foreachPartition at RefereeStats.scala:89) with 2 output partitions
18/04/01 20:15:05 INFO DAGScheduler: Final stage: ResultStage 21 (foreachPartition at RefereeStats.scala:89)
18/04/01 20:15:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
18/04/01 20:15:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
18/04/01 20:15:05 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[17] at map at RefereeStats.scala:46), which has no missing parents
18/04/01 20:15:05 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:15:05 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:15:05 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:05 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:05 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[17] at map at RefereeStats.scala:46) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:05 INFO TaskSchedulerImpl: Adding task set 20.0 with 5 tasks
18/04/01 20:15:05 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:05 INFO TaskSetManager: Starting task 1.0 in stage 20.0 (TID 65, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:05 INFO Executor: Running task 0.0 in stage 20.0 (TID 64)
18/04/01 20:15:05 INFO Executor: Running task 1.0 in stage 20.0 (TID 65)
18/04/01 20:15:05 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:05 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:05 INFO Executor: Finished task 1.0 in stage 20.0 (TID 65). 938 bytes result sent to driver
18/04/01 20:15:05 INFO Executor: Finished task 0.0 in stage 20.0 (TID 64). 938 bytes result sent to driver
18/04/01 20:15:05 INFO TaskSetManager: Starting task 2.0 in stage 20.0 (TID 66, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:05 INFO Executor: Running task 2.0 in stage 20.0 (TID 66)
18/04/01 20:15:05 INFO TaskSetManager: Finished task 1.0 in stage 20.0 (TID 65) in 22 ms on localhost (executor driver) (1/5)
18/04/01 20:15:05 INFO TaskSetManager: Starting task 3.0 in stage 20.0 (TID 67, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:05 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 64) in 25 ms on localhost (executor driver) (2/5)
18/04/01 20:15:05 INFO Executor: Running task 3.0 in stage 20.0 (TID 67)
18/04/01 20:15:05 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:05 INFO Executor: Finished task 2.0 in stage 20.0 (TID 66). 938 bytes result sent to driver
18/04/01 20:15:05 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:05 INFO TaskSetManager: Starting task 4.0 in stage 20.0 (TID 68, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:05 INFO Executor: Running task 4.0 in stage 20.0 (TID 68)
18/04/01 20:15:05 INFO TaskSetManager: Finished task 2.0 in stage 20.0 (TID 66) in 21 ms on localhost (executor driver) (3/5)
18/04/01 20:15:05 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 703 -> 705
18/04/01 20:15:05 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 703
18/04/01 20:15:05 INFO Executor: Finished task 3.0 in stage 20.0 (TID 67). 938 bytes result sent to driver
18/04/01 20:15:05 INFO TaskSetManager: Finished task 3.0 in stage 20.0 (TID 67) in 34 ms on localhost (executor driver) (4/5)
18/04/01 20:15:06 INFO Executor: Finished task 4.0 in stage 20.0 (TID 68). 1024 bytes result sent to driver
18/04/01 20:15:06 INFO TaskSetManager: Finished task 4.0 in stage 20.0 (TID 68) in 284 ms on localhost (executor driver) (5/5)
18/04/01 20:15:06 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
18/04/01 20:15:06 INFO DAGScheduler: ShuffleMapStage 20 (map at RefereeStats.scala:46) finished in 0.346 s
18/04/01 20:15:06 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:06 INFO DAGScheduler: running: Set()
18/04/01 20:15:06 INFO DAGScheduler: waiting: Set(ResultStage 21)
18/04/01 20:15:06 INFO DAGScheduler: failed: Set()
18/04/01 20:15:06 INFO DAGScheduler: Submitting ResultStage 21 (ShuffledRDD[18] at reduceByKey at RefereeStats.scala:51), which has no missing parents
18/04/01 20:15:06 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:15:06 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 1709.0 B, free 477.2 MB)
18/04/01 20:15:06 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 192.168.1.3:35449 (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:15:06 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 21 (ShuffledRDD[18] at reduceByKey at RefereeStats.scala:51) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:06 INFO TaskSchedulerImpl: Adding task set 21.0 with 2 tasks
18/04/01 20:15:06 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 69, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:15:06 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 70, localhost, executor driver, partition 1, ANY, 7649 bytes)
18/04/01 20:15:06 INFO Executor: Running task 0.0 in stage 21.0 (TID 69)
18/04/01 20:15:06 INFO Executor: Running task 1.0 in stage 21.0 (TID 70)
18/04/01 20:15:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:06 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:15:06 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:06 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:06 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:06 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 395
18/04/01 20:15:06 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:06 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 396
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 336
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 459
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 316
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 409
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 340
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 341
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 301
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 351
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 482
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 442
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 357
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 378
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 411
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 440
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 312
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 309
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 451
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 397
18/04/01 20:15:06 INFO KafkaProducer: [Producer clientId=producer-15] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 362
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 317
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 392
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 417
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 365
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 436
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 487
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 475
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 338
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 313
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 445
18/04/01 20:15:06 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 192.168.1.3:35449 in memory (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 376
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 332
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 350
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 493
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 422
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 361
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 434
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 439
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 405
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 485
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 356
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 352
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 438
18/04/01 20:15:06 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 455
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 433
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 391
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 494
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 496
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 315
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 437
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 466
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 360
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 380
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 343
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 407
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 333
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 307
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 334
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 388
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 418
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 394
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 384
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 430
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 412
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 426
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 372
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 491
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 486
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 454
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 465
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 326
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 389
18/04/01 20:15:06 INFO Executor: Finished task 0.0 in stage 21.0 (TID 69). 1181 bytes result sent to driver
18/04/01 20:15:06 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:06 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 69) in 124 ms on localhost (executor driver) (1/2)
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 463
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 375
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 414
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 305
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 368
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 367
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 304
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 335
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 402
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 381
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 325
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 404
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 387
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 401
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 462
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 473
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 359
18/04/01 20:15:06 INFO KafkaProducer: [Producer clientId=producer-16] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:06 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 339
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 322
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 468
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 495
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 319
18/04/01 20:15:06 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 192.168.1.3:35449 in memory (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 460
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 470
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 374
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 408
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 478
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 432
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 323
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 410
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 498
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 337
18/04/01 20:15:06 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:06 INFO Executor: Finished task 1.0 in stage 21.0 (TID 70). 1181 bytes result sent to driver
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 448
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 318
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 429
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 469
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 453
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 492
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 383
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 452
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 386
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 370
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 441
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 427
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 472
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 347
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 490
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 306
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 474
18/04/01 20:15:06 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 70) in 150 ms on localhost (executor driver) (2/2)
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 354
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 385
18/04/01 20:15:06 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 330
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 399
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 476
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 311
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 446
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 324
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 342
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 435
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 379
18/04/01 20:15:06 INFO DAGScheduler: ResultStage 21 (foreachPartition at RefereeStats.scala:89) finished in 0.175 s
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 479
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 321
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 353
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 348
18/04/01 20:15:06 INFO DAGScheduler: Job 13 finished: foreachPartition at RefereeStats.scala:89, took 0.540289 s
18/04/01 20:15:06 INFO JobScheduler: Finished job streaming job 1522602905000 ms.2 from job set of time 1522602905000 ms
18/04/01 20:15:06 INFO JobScheduler: Starting job streaming job 1522602905000 ms.3 from job set of time 1522602905000 ms
18/04/01 20:15:06 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 192.168.1.3:35449 in memory (size: 1701.0 B, free: 477.3 MB)
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 403
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 398
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 477
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 457
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 447
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 390
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 497
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 461
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 327
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 420
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 308
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 443
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 464
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 499
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 310
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 346
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 413
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 345
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 415
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 371
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 406
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 471
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 344
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 419
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 329
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 489
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 450
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 480
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 302
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 320
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 393
18/04/01 20:15:06 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 192.168.1.3:35449 in memory (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 314
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 458
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 328
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 456
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 331
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 467
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 400
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 416
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 366
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 425
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 349
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 377
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 358
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 364
18/04/01 20:15:06 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:06 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:106
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 449
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 483
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 488
18/04/01 20:15:06 INFO DAGScheduler: Registering RDD 19 (map at RefereeStats.scala:39)
18/04/01 20:15:06 INFO DAGScheduler: Got job 14 (foreachPartition at RefereeStats.scala:106) with 2 output partitions
18/04/01 20:15:06 INFO DAGScheduler: Final stage: ResultStage 23 (foreachPartition at RefereeStats.scala:106)
18/04/01 20:15:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)
18/04/01 20:15:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 22)
18/04/01 20:15:06 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[19] at map at RefereeStats.scala:39), which has no missing parents
18/04/01 20:15:06 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:06 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 3.9 KB, free 477.3 MB)
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 355
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 444
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 421
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 363
18/04/01 20:15:06 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 423
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 481
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 369
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 431
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 382
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 303
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 428
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 300
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 373
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 424
18/04/01 20:15:06 INFO ContextCleaner: Cleaned accumulator 484
18/04/01 20:15:06 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.3 MB)
18/04/01 20:15:06 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:06 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:06 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[19] at map at RefereeStats.scala:39) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:06 INFO TaskSchedulerImpl: Adding task set 22.0 with 5 tasks
18/04/01 20:15:06 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 71, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:06 INFO TaskSetManager: Starting task 1.0 in stage 22.0 (TID 72, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:06 INFO Executor: Running task 1.0 in stage 22.0 (TID 72)
18/04/01 20:15:06 INFO Executor: Running task 0.0 in stage 22.0 (TID 71)
18/04/01 20:15:06 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:06 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:06 INFO Executor: Finished task 1.0 in stage 22.0 (TID 72). 938 bytes result sent to driver
18/04/01 20:15:06 INFO Executor: Finished task 0.0 in stage 22.0 (TID 71). 981 bytes result sent to driver
18/04/01 20:15:06 INFO TaskSetManager: Starting task 2.0 in stage 22.0 (TID 73, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:06 INFO TaskSetManager: Finished task 1.0 in stage 22.0 (TID 72) in 22 ms on localhost (executor driver) (1/5)
18/04/01 20:15:06 INFO Executor: Running task 2.0 in stage 22.0 (TID 73)
18/04/01 20:15:06 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:06 INFO Executor: Finished task 2.0 in stage 22.0 (TID 73). 938 bytes result sent to driver
18/04/01 20:15:06 INFO TaskSetManager: Starting task 3.0 in stage 22.0 (TID 74, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:06 INFO TaskSetManager: Finished task 2.0 in stage 22.0 (TID 73) in 14 ms on localhost (executor driver) (2/5)
18/04/01 20:15:06 INFO Executor: Running task 3.0 in stage 22.0 (TID 74)
18/04/01 20:15:06 INFO TaskSetManager: Starting task 4.0 in stage 22.0 (TID 75, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:06 INFO Executor: Running task 4.0 in stage 22.0 (TID 75)
18/04/01 20:15:06 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 71) in 43 ms on localhost (executor driver) (3/5)
18/04/01 20:15:06 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:06 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 703 -> 705
18/04/01 20:15:06 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 703
18/04/01 20:15:06 INFO Executor: Finished task 3.0 in stage 22.0 (TID 74). 938 bytes result sent to driver
18/04/01 20:15:06 INFO TaskSetManager: Finished task 3.0 in stage 22.0 (TID 74) in 26 ms on localhost (executor driver) (4/5)
18/04/01 20:15:06 INFO Executor: Finished task 4.0 in stage 22.0 (TID 75). 1024 bytes result sent to driver
18/04/01 20:15:06 INFO TaskSetManager: Finished task 4.0 in stage 22.0 (TID 75) in 202 ms on localhost (executor driver) (5/5)
18/04/01 20:15:06 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
18/04/01 20:15:06 INFO DAGScheduler: ShuffleMapStage 22 (map at RefereeStats.scala:39) finished in 0.274 s
18/04/01 20:15:06 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:06 INFO DAGScheduler: running: Set()
18/04/01 20:15:06 INFO DAGScheduler: waiting: Set(ResultStage 23)
18/04/01 20:15:06 INFO DAGScheduler: failed: Set()
18/04/01 20:15:06 INFO DAGScheduler: Submitting ResultStage 23 (ShuffledRDD[20] at reduceByKey at RefereeStats.scala:43), which has no missing parents
18/04/01 20:15:06 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 2.8 KB, free 477.3 MB)
18/04/01 20:15:06 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 1704.0 B, free 477.3 MB)
18/04/01 20:15:06 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 192.168.1.3:35449 (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:15:06 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 23 (ShuffledRDD[20] at reduceByKey at RefereeStats.scala:43) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:06 INFO TaskSchedulerImpl: Adding task set 23.0 with 2 tasks
18/04/01 20:15:06 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 76, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:15:06 INFO TaskSetManager: Starting task 1.0 in stage 23.0 (TID 77, localhost, executor driver, partition 1, ANY, 7649 bytes)
18/04/01 20:15:06 INFO Executor: Running task 1.0 in stage 23.0 (TID 77)
18/04/01 20:15:06 INFO Executor: Running task 0.0 in stage 23.0 (TID 76)
18/04/01 20:15:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
18/04/01 20:15:06 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:06 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:06 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:06 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:06 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:06 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:06 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:06 INFO KafkaProducer: [Producer clientId=producer-17] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:06 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:06 INFO KafkaProducer: [Producer clientId=producer-18] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:06 INFO Executor: Finished task 1.0 in stage 23.0 (TID 77). 1138 bytes result sent to driver
18/04/01 20:15:06 INFO TaskSetManager: Finished task 1.0 in stage 23.0 (TID 77) in 103 ms on localhost (executor driver) (1/2)
18/04/01 20:15:06 INFO Executor: Finished task 0.0 in stage 23.0 (TID 76). 1138 bytes result sent to driver
18/04/01 20:15:06 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 76) in 118 ms on localhost (executor driver) (2/2)
18/04/01 20:15:06 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
18/04/01 20:15:06 INFO DAGScheduler: ResultStage 23 (foreachPartition at RefereeStats.scala:106) finished in 0.133 s
18/04/01 20:15:06 INFO DAGScheduler: Job 14 finished: foreachPartition at RefereeStats.scala:106, took 0.431522 s
18/04/01 20:15:06 INFO JobScheduler: Finished job streaming job 1522602905000 ms.3 from job set of time 1522602905000 ms
18/04/01 20:15:06 INFO JobScheduler: Total delay: 1.883 s for time 1522602905000 ms (execution: 1.835 s)
18/04/01 20:15:06 INFO MapPartitionsRDD: Removing RDD 8 from persistence list
18/04/01 20:15:06 INFO BlockManager: Removing RDD 8
18/04/01 20:15:06 INFO KafkaRDD: Removing RDD 7 from persistence list
18/04/01 20:15:06 INFO BlockManager: Removing RDD 7
18/04/01 20:15:06 INFO ShuffledRDD: Removing RDD 9 from persistence list
18/04/01 20:15:06 INFO BlockManager: Removing RDD 9
18/04/01 20:15:06 INFO ShuffledRDD: Removing RDD 11 from persistence list
18/04/01 20:15:06 INFO BlockManager: Removing RDD 11
18/04/01 20:15:06 INFO MapPartitionsRDD: Removing RDD 10 from persistence list
18/04/01 20:15:06 INFO BlockManager: Removing RDD 10
18/04/01 20:15:06 INFO ShuffledRDD: Removing RDD 13 from persistence list
18/04/01 20:15:06 INFO BlockManager: Removing RDD 13
18/04/01 20:15:06 INFO MapPartitionsRDD: Removing RDD 12 from persistence list
18/04/01 20:15:06 INFO BlockManager: Removing RDD 12
18/04/01 20:15:06 INFO JobGenerator: Checkpointing graph for time 1522602905000 ms
18/04/01 20:15:06 INFO DStreamGraph: Updating checkpoint data for time 1522602905000 ms
18/04/01 20:15:06 INFO DStreamGraph: Updated checkpoint data for time 1522602905000 ms
18/04/01 20:15:06 INFO CheckpointWriter: Submitted checkpoint of time 1522602905000 ms to writer queue
18/04/01 20:15:06 INFO CheckpointWriter: Saving checkpoint for time 1522602905000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602905000'
18/04/01 20:15:06 INFO CheckpointWriter: Checkpoint for time 1522602905000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602905000', took 5532 bytes and 33 ms
18/04/01 20:15:06 INFO DStreamGraph: Clearing checkpoint data for time 1522602905000 ms
18/04/01 20:15:06 INFO DStreamGraph: Cleared checkpoint data for time 1522602905000 ms
18/04/01 20:15:06 INFO ReceivedBlockTracker: Deleting batches: 
18/04/01 20:15:06 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/tmp/refs-xyzabb/receivedBlockMetadata older than 1522602900000: 
18/04/01 20:15:06 INFO InputInfoTracker: remove old batch metadata: 1522602895000 ms
18/04/01 20:15:10 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-0 to offset 707.
18/04/01 20:15:10 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-3 to offset 0.
18/04/01 20:15:10 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-4 to offset 0.
18/04/01 20:15:10 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-1 to offset 0.
18/04/01 20:15:10 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-2 to offset 0.
18/04/01 20:15:10 INFO JobScheduler: Added jobs for time 1522602910000 ms
18/04/01 20:15:10 INFO JobGenerator: Checkpointing graph for time 1522602910000 ms
18/04/01 20:15:10 INFO DStreamGraph: Updating checkpoint data for time 1522602910000 ms
18/04/01 20:15:10 INFO JobScheduler: Starting job streaming job 1522602910000 ms.0 from job set of time 1522602910000 ms
18/04/01 20:15:10 INFO DStreamGraph: Updated checkpoint data for time 1522602910000 ms
18/04/01 20:15:10 INFO CheckpointWriter: Submitted checkpoint of time 1522602910000 ms to writer queue
18/04/01 20:15:10 INFO CheckpointWriter: Saving checkpoint for time 1522602910000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602910000'
18/04/01 20:15:10 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:15:10 INFO DAGScheduler: Got job 15 (print at RefereeStats.scala:67) with 1 output partitions
18/04/01 20:15:10 INFO DAGScheduler: Final stage: ResultStage 24 (print at RefereeStats.scala:67)
18/04/01 20:15:10 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:15:10 INFO DAGScheduler: Missing parents: List()
18/04/01 20:15:10 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[22] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:10 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 3.0 KB, free 477.3 MB)
18/04/01 20:15:10 INFO CheckpointWriter: Checkpoint for time 1522602910000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602910000', took 5590 bytes and 46 ms
18/04/01 20:15:10 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.3 MB)
18/04/01 20:15:10 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:10 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[22] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0))
18/04/01 20:15:10 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
18/04/01 20:15:10 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 78, localhost, executor driver, partition 0, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:10 INFO Executor: Running task 0.0 in stage 24.0 (TID 78)
18/04/01 20:15:10 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:10 INFO Executor: Finished task 0.0 in stage 24.0 (TID 78). 704 bytes result sent to driver
18/04/01 20:15:10 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 78) in 9 ms on localhost (executor driver) (1/1)
18/04/01 20:15:10 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
18/04/01 20:15:10 INFO DAGScheduler: ResultStage 24 (print at RefereeStats.scala:67) finished in 0.026 s
18/04/01 20:15:10 INFO DAGScheduler: Job 15 finished: print at RefereeStats.scala:67, took 0.040654 s
18/04/01 20:15:10 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:15:10 INFO DAGScheduler: Got job 16 (print at RefereeStats.scala:67) with 4 output partitions
18/04/01 20:15:10 INFO DAGScheduler: Final stage: ResultStage 25 (print at RefereeStats.scala:67)
18/04/01 20:15:10 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:15:10 INFO DAGScheduler: Missing parents: List()
18/04/01 20:15:10 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[22] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:10 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 3.0 KB, free 477.3 MB)
18/04/01 20:15:10 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.3 MB)
18/04/01 20:15:10 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:10 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:10 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 25 (MapPartitionsRDD[22] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
18/04/01 20:15:10 INFO TaskSchedulerImpl: Adding task set 25.0 with 4 tasks
18/04/01 20:15:10 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 79, localhost, executor driver, partition 1, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:10 INFO TaskSetManager: Starting task 1.0 in stage 25.0 (TID 80, localhost, executor driver, partition 2, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:10 INFO Executor: Running task 1.0 in stage 25.0 (TID 80)
18/04/01 20:15:10 INFO Executor: Running task 0.0 in stage 25.0 (TID 79)
18/04/01 20:15:10 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:10 INFO Executor: Finished task 1.0 in stage 25.0 (TID 80). 704 bytes result sent to driver
18/04/01 20:15:10 INFO TaskSetManager: Starting task 2.0 in stage 25.0 (TID 81, localhost, executor driver, partition 3, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:10 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:10 INFO TaskSetManager: Finished task 1.0 in stage 25.0 (TID 80) in 10 ms on localhost (executor driver) (1/4)
18/04/01 20:15:10 INFO Executor: Finished task 0.0 in stage 25.0 (TID 79). 704 bytes result sent to driver
18/04/01 20:15:10 INFO TaskSetManager: Starting task 3.0 in stage 25.0 (TID 82, localhost, executor driver, partition 4, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:10 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 79) in 14 ms on localhost (executor driver) (2/4)
18/04/01 20:15:10 INFO Executor: Running task 2.0 in stage 25.0 (TID 81)
18/04/01 20:15:10 INFO Executor: Running task 3.0 in stage 25.0 (TID 82)
18/04/01 20:15:10 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:10 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 705 -> 707
18/04/01 20:15:10 INFO Executor: Finished task 2.0 in stage 25.0 (TID 81). 704 bytes result sent to driver
18/04/01 20:15:10 INFO TaskSetManager: Finished task 2.0 in stage 25.0 (TID 81) in 11 ms on localhost (executor driver) (3/4)
18/04/01 20:15:10 INFO Executor: Finished task 3.0 in stage 25.0 (TID 82). 890 bytes result sent to driver
18/04/01 20:15:10 INFO TaskSetManager: Finished task 3.0 in stage 25.0 (TID 82) in 16 ms on localhost (executor driver) (4/4)
18/04/01 20:15:10 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
18/04/01 20:15:10 INFO DAGScheduler: ResultStage 25 (print at RefereeStats.scala:67) finished in 0.046 s
18/04/01 20:15:10 INFO DAGScheduler: Job 16 finished: print at RefereeStats.scala:67, took 0.056740 s
-------------------------------------------
Time: 1522602910000 ms
-------------------------------------------
18/04/01 20:15:10 INFO JobScheduler: Finished job streaming job 1522602910000 ms.0 from job set of time 1522602910000 ms
(yandex.*,8000)
(quora.com,9000)

18/04/01 20:15:10 INFO JobScheduler: Starting job streaming job 1522602910000 ms.1 from job set of time 1522602910000 ms
18/04/01 20:15:10 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:71
18/04/01 20:15:10 INFO DAGScheduler: Registering RDD 22 (map at RefereeStats.scala:53)
18/04/01 20:15:10 INFO DAGScheduler: Got job 17 (foreachPartition at RefereeStats.scala:71) with 2 output partitions
18/04/01 20:15:10 INFO DAGScheduler: Final stage: ResultStage 27 (foreachPartition at RefereeStats.scala:71)
18/04/01 20:15:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
18/04/01 20:15:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 26)
18/04/01 20:15:10 INFO DAGScheduler: Submitting ShuffleMapStage 26 (MapPartitionsRDD[22] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:10 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 3.9 KB, free 477.3 MB)
18/04/01 20:15:10 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.3 MB)
18/04/01 20:15:10 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:10 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:10 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[22] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:10 INFO TaskSchedulerImpl: Adding task set 26.0 with 5 tasks
18/04/01 20:15:10 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 83, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:10 INFO TaskSetManager: Starting task 1.0 in stage 26.0 (TID 84, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:10 INFO Executor: Running task 0.0 in stage 26.0 (TID 83)
18/04/01 20:15:10 INFO Executor: Running task 1.0 in stage 26.0 (TID 84)
18/04/01 20:15:10 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:10 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:10 INFO Executor: Finished task 1.0 in stage 26.0 (TID 84). 938 bytes result sent to driver
18/04/01 20:15:10 INFO TaskSetManager: Starting task 2.0 in stage 26.0 (TID 85, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:10 INFO TaskSetManager: Finished task 1.0 in stage 26.0 (TID 84) in 19 ms on localhost (executor driver) (1/5)
18/04/01 20:15:10 INFO Executor: Finished task 0.0 in stage 26.0 (TID 83). 938 bytes result sent to driver
18/04/01 20:15:10 INFO TaskSetManager: Starting task 3.0 in stage 26.0 (TID 86, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:10 INFO Executor: Running task 3.0 in stage 26.0 (TID 86)
18/04/01 20:15:10 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 83) in 27 ms on localhost (executor driver) (2/5)
18/04/01 20:15:10 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:10 INFO Executor: Finished task 3.0 in stage 26.0 (TID 86). 938 bytes result sent to driver
18/04/01 20:15:10 INFO Executor: Running task 2.0 in stage 26.0 (TID 85)
18/04/01 20:15:10 INFO TaskSetManager: Starting task 4.0 in stage 26.0 (TID 87, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:10 INFO Executor: Running task 4.0 in stage 26.0 (TID 87)
18/04/01 20:15:10 INFO TaskSetManager: Finished task 3.0 in stage 26.0 (TID 86) in 14 ms on localhost (executor driver) (3/5)
18/04/01 20:15:10 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:10 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 705 -> 707
18/04/01 20:15:10 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 705
18/04/01 20:15:10 INFO Executor: Finished task 2.0 in stage 26.0 (TID 85). 981 bytes result sent to driver
18/04/01 20:15:10 INFO TaskSetManager: Finished task 2.0 in stage 26.0 (TID 85) in 40 ms on localhost (executor driver) (4/5)
18/04/01 20:15:10 INFO Executor: Finished task 4.0 in stage 26.0 (TID 87). 1024 bytes result sent to driver
18/04/01 20:15:10 INFO TaskSetManager: Finished task 4.0 in stage 26.0 (TID 87) in 416 ms on localhost (executor driver) (5/5)
18/04/01 20:15:10 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
18/04/01 20:15:10 INFO DAGScheduler: ShuffleMapStage 26 (map at RefereeStats.scala:53) finished in 0.478 s
18/04/01 20:15:10 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:10 INFO DAGScheduler: running: Set()
18/04/01 20:15:10 INFO DAGScheduler: waiting: Set(ResultStage 27)
18/04/01 20:15:10 INFO DAGScheduler: failed: Set()
18/04/01 20:15:10 INFO DAGScheduler: Submitting ResultStage 27 (ShuffledRDD[23] at reduceByKey at RefereeStats.scala:60), which has no missing parents
18/04/01 20:15:10 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 2.8 KB, free 477.3 MB)
18/04/01 20:15:10 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 1706.0 B, free 477.3 MB)
18/04/01 20:15:10 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 192.168.1.3:35449 (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:15:10 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 27 (ShuffledRDD[23] at reduceByKey at RefereeStats.scala:60) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:10 INFO TaskSchedulerImpl: Adding task set 27.0 with 2 tasks
18/04/01 20:15:10 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 88, localhost, executor driver, partition 0, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:15:10 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 89, localhost, executor driver, partition 1, ANY, 7649 bytes)
18/04/01 20:15:10 INFO Executor: Running task 1.0 in stage 27.0 (TID 89)
18/04/01 20:15:10 INFO Executor: Running task 0.0 in stage 27.0 (TID 88)
18/04/01 20:15:10 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:10 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:15:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:10 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:10 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:10 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:10 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:10 INFO KafkaProducer: [Producer clientId=producer-20] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:10 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:10 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:10 INFO Executor: Finished task 0.0 in stage 27.0 (TID 88). 1138 bytes result sent to driver
18/04/01 20:15:10 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 88) in 49 ms on localhost (executor driver) (1/2)
18/04/01 20:15:10 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:10 INFO KafkaProducer: [Producer clientId=producer-19] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:10 INFO Executor: Finished task 1.0 in stage 27.0 (TID 89). 1138 bytes result sent to driver
18/04/01 20:15:10 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 89) in 87 ms on localhost (executor driver) (2/2)
18/04/01 20:15:10 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
18/04/01 20:15:10 INFO DAGScheduler: ResultStage 27 (foreachPartition at RefereeStats.scala:71) finished in 0.102 s
18/04/01 20:15:10 INFO DAGScheduler: Job 17 finished: foreachPartition at RefereeStats.scala:71, took 0.600889 s
18/04/01 20:15:10 INFO JobScheduler: Finished job streaming job 1522602910000 ms.1 from job set of time 1522602910000 ms
18/04/01 20:15:10 INFO JobScheduler: Starting job streaming job 1522602910000 ms.2 from job set of time 1522602910000 ms
18/04/01 20:15:10 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:89
18/04/01 20:15:10 INFO DAGScheduler: Registering RDD 24 (map at RefereeStats.scala:46)
18/04/01 20:15:10 INFO DAGScheduler: Got job 18 (foreachPartition at RefereeStats.scala:89) with 2 output partitions
18/04/01 20:15:10 INFO DAGScheduler: Final stage: ResultStage 29 (foreachPartition at RefereeStats.scala:89)
18/04/01 20:15:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
18/04/01 20:15:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 28)
18/04/01 20:15:10 INFO DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[24] at map at RefereeStats.scala:46), which has no missing parents
18/04/01 20:15:10 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:15:10 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:15:10 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:10 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:10 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[24] at map at RefereeStats.scala:46) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:10 INFO TaskSchedulerImpl: Adding task set 28.0 with 5 tasks
18/04/01 20:15:10 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 90, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:10 INFO TaskSetManager: Starting task 1.0 in stage 28.0 (TID 91, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:10 INFO Executor: Running task 0.0 in stage 28.0 (TID 90)
18/04/01 20:15:10 INFO Executor: Running task 1.0 in stage 28.0 (TID 91)
18/04/01 20:15:10 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:10 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:10 INFO Executor: Finished task 1.0 in stage 28.0 (TID 91). 938 bytes result sent to driver
18/04/01 20:15:10 INFO Executor: Finished task 0.0 in stage 28.0 (TID 90). 938 bytes result sent to driver
18/04/01 20:15:10 INFO TaskSetManager: Starting task 2.0 in stage 28.0 (TID 92, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:10 INFO Executor: Running task 2.0 in stage 28.0 (TID 92)
18/04/01 20:15:10 INFO TaskSetManager: Finished task 1.0 in stage 28.0 (TID 91) in 20 ms on localhost (executor driver) (1/5)
18/04/01 20:15:10 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:10 INFO Executor: Finished task 2.0 in stage 28.0 (TID 92). 938 bytes result sent to driver
18/04/01 20:15:10 INFO TaskSetManager: Starting task 3.0 in stage 28.0 (TID 93, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:10 INFO TaskSetManager: Finished task 2.0 in stage 28.0 (TID 92) in 12 ms on localhost (executor driver) (2/5)
18/04/01 20:15:10 INFO TaskSetManager: Starting task 4.0 in stage 28.0 (TID 94, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:10 INFO Executor: Running task 4.0 in stage 28.0 (TID 94)
18/04/01 20:15:10 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 90) in 34 ms on localhost (executor driver) (3/5)
18/04/01 20:15:10 INFO Executor: Running task 3.0 in stage 28.0 (TID 93)
18/04/01 20:15:10 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 705 -> 707
18/04/01 20:15:10 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 705
18/04/01 20:15:10 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:10 INFO Executor: Finished task 3.0 in stage 28.0 (TID 93). 938 bytes result sent to driver
18/04/01 20:15:10 INFO TaskSetManager: Finished task 3.0 in stage 28.0 (TID 93) in 19 ms on localhost (executor driver) (4/5)
18/04/01 20:15:11 INFO Executor: Finished task 4.0 in stage 28.0 (TID 94). 1024 bytes result sent to driver
18/04/01 20:15:11 INFO TaskSetManager: Finished task 4.0 in stage 28.0 (TID 94) in 321 ms on localhost (executor driver) (5/5)
18/04/01 20:15:11 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
18/04/01 20:15:11 INFO DAGScheduler: ShuffleMapStage 28 (map at RefereeStats.scala:46) finished in 0.370 s
18/04/01 20:15:11 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:11 INFO DAGScheduler: running: Set()
18/04/01 20:15:11 INFO DAGScheduler: waiting: Set(ResultStage 29)
18/04/01 20:15:11 INFO DAGScheduler: failed: Set()
18/04/01 20:15:11 INFO DAGScheduler: Submitting ResultStage 29 (ShuffledRDD[25] at reduceByKey at RefereeStats.scala:51), which has no missing parents
18/04/01 20:15:11 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:15:11 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 1709.0 B, free 477.2 MB)
18/04/01 20:15:11 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 192.168.1.3:35449 (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:15:11 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:11 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 29 (ShuffledRDD[25] at reduceByKey at RefereeStats.scala:51) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:11 INFO TaskSchedulerImpl: Adding task set 29.0 with 2 tasks
18/04/01 20:15:11 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 95, localhost, executor driver, partition 0, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:15:11 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 96, localhost, executor driver, partition 1, ANY, 7649 bytes)
18/04/01 20:15:11 INFO Executor: Running task 0.0 in stage 29.0 (TID 95)
18/04/01 20:15:11 INFO Executor: Running task 1.0 in stage 29.0 (TID 96)
18/04/01 20:15:11 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:15:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:11 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:11 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:11 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:11 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:11 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:11 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:11 INFO KafkaProducer: [Producer clientId=producer-21] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:11 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:11 INFO Executor: Finished task 0.0 in stage 29.0 (TID 95). 1138 bytes result sent to driver
18/04/01 20:15:11 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 95) in 40 ms on localhost (executor driver) (1/2)
18/04/01 20:15:11 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:11 INFO KafkaProducer: [Producer clientId=producer-22] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:11 INFO Executor: Finished task 1.0 in stage 29.0 (TID 96). 1138 bytes result sent to driver
18/04/01 20:15:11 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 96) in 78 ms on localhost (executor driver) (2/2)
18/04/01 20:15:11 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
18/04/01 20:15:11 INFO DAGScheduler: ResultStage 29 (foreachPartition at RefereeStats.scala:89) finished in 0.095 s
18/04/01 20:15:11 INFO DAGScheduler: Job 18 finished: foreachPartition at RefereeStats.scala:89, took 0.481281 s
18/04/01 20:15:11 INFO JobScheduler: Finished job streaming job 1522602910000 ms.2 from job set of time 1522602910000 ms
18/04/01 20:15:11 INFO JobScheduler: Starting job streaming job 1522602910000 ms.3 from job set of time 1522602910000 ms
18/04/01 20:15:11 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:106
18/04/01 20:15:11 INFO DAGScheduler: Registering RDD 26 (map at RefereeStats.scala:39)
18/04/01 20:15:11 INFO DAGScheduler: Got job 19 (foreachPartition at RefereeStats.scala:106) with 2 output partitions
18/04/01 20:15:11 INFO DAGScheduler: Final stage: ResultStage 31 (foreachPartition at RefereeStats.scala:106)
18/04/01 20:15:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)
18/04/01 20:15:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 30)
18/04/01 20:15:11 INFO DAGScheduler: Submitting ShuffleMapStage 30 (MapPartitionsRDD[26] at map at RefereeStats.scala:39), which has no missing parents
18/04/01 20:15:11 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:15:11 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:15:11 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:11 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:11 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[26] at map at RefereeStats.scala:39) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:11 INFO TaskSchedulerImpl: Adding task set 30.0 with 5 tasks
18/04/01 20:15:11 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 97, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:11 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 98, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:11 INFO Executor: Running task 0.0 in stage 30.0 (TID 97)
18/04/01 20:15:11 INFO Executor: Running task 1.0 in stage 30.0 (TID 98)
18/04/01 20:15:11 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:11 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:11 INFO Executor: Finished task 0.0 in stage 30.0 (TID 97). 938 bytes result sent to driver
18/04/01 20:15:11 INFO TaskSetManager: Starting task 2.0 in stage 30.0 (TID 99, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:11 INFO Executor: Running task 2.0 in stage 30.0 (TID 99)
18/04/01 20:15:11 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 97) in 12 ms on localhost (executor driver) (1/5)
18/04/01 20:15:11 INFO Executor: Finished task 1.0 in stage 30.0 (TID 98). 981 bytes result sent to driver
18/04/01 20:15:11 INFO TaskSetManager: Starting task 3.0 in stage 30.0 (TID 100, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:11 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 98) in 15 ms on localhost (executor driver) (2/5)
18/04/01 20:15:11 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:11 INFO Executor: Running task 3.0 in stage 30.0 (TID 100)
18/04/01 20:15:11 INFO Executor: Finished task 2.0 in stage 30.0 (TID 99). 938 bytes result sent to driver
18/04/01 20:15:11 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:11 INFO TaskSetManager: Starting task 4.0 in stage 30.0 (TID 101, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:11 INFO Executor: Running task 4.0 in stage 30.0 (TID 101)
18/04/01 20:15:11 INFO TaskSetManager: Finished task 2.0 in stage 30.0 (TID 99) in 15 ms on localhost (executor driver) (3/5)
18/04/01 20:15:11 INFO Executor: Finished task 3.0 in stage 30.0 (TID 100). 938 bytes result sent to driver
18/04/01 20:15:11 INFO TaskSetManager: Finished task 3.0 in stage 30.0 (TID 100) in 20 ms on localhost (executor driver) (4/5)
18/04/01 20:15:11 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 705 -> 707
18/04/01 20:15:11 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 705
18/04/01 20:15:11 INFO Executor: Finished task 4.0 in stage 30.0 (TID 101). 1024 bytes result sent to driver
18/04/01 20:15:11 INFO TaskSetManager: Finished task 4.0 in stage 30.0 (TID 101) in 320 ms on localhost (executor driver) (5/5)
18/04/01 20:15:11 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
18/04/01 20:15:11 INFO DAGScheduler: ShuffleMapStage 30 (map at RefereeStats.scala:39) finished in 0.377 s
18/04/01 20:15:11 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:11 INFO DAGScheduler: running: Set()
18/04/01 20:15:11 INFO DAGScheduler: waiting: Set(ResultStage 31)
18/04/01 20:15:11 INFO DAGScheduler: failed: Set()
18/04/01 20:15:11 INFO DAGScheduler: Submitting ResultStage 31 (ShuffledRDD[27] at reduceByKey at RefereeStats.scala:43), which has no missing parents
18/04/01 20:15:11 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:15:11 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 1704.0 B, free 477.2 MB)
18/04/01 20:15:11 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 192.168.1.3:35449 (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:15:11 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:11 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 31 (ShuffledRDD[27] at reduceByKey at RefereeStats.scala:43) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:11 INFO TaskSchedulerImpl: Adding task set 31.0 with 2 tasks
18/04/01 20:15:11 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 102, localhost, executor driver, partition 0, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:15:11 INFO TaskSetManager: Starting task 1.0 in stage 31.0 (TID 103, localhost, executor driver, partition 1, ANY, 7649 bytes)
18/04/01 20:15:11 INFO Executor: Running task 1.0 in stage 31.0 (TID 103)
18/04/01 20:15:11 INFO Executor: Running task 0.0 in stage 31.0 (TID 102)
18/04/01 20:15:11 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:15:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:11 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:11 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:11 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:11 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:11 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:11 INFO KafkaProducer: [Producer clientId=producer-23] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:11 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:11 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:11 INFO Executor: Finished task 0.0 in stage 31.0 (TID 102). 1138 bytes result sent to driver
18/04/01 20:15:11 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 102) in 40 ms on localhost (executor driver) (1/2)
18/04/01 20:15:11 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:11 INFO KafkaProducer: [Producer clientId=producer-24] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:11 INFO Executor: Finished task 1.0 in stage 31.0 (TID 103). 1138 bytes result sent to driver
18/04/01 20:15:11 INFO TaskSetManager: Finished task 1.0 in stage 31.0 (TID 103) in 76 ms on localhost (executor driver) (2/2)
18/04/01 20:15:11 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
18/04/01 20:15:11 INFO DAGScheduler: ResultStage 31 (foreachPartition at RefereeStats.scala:106) finished in 0.092 s
18/04/01 20:15:11 INFO DAGScheduler: Job 19 finished: foreachPartition at RefereeStats.scala:106, took 0.487316 s
18/04/01 20:15:11 INFO JobScheduler: Finished job streaming job 1522602910000 ms.3 from job set of time 1522602910000 ms
18/04/01 20:15:11 INFO JobScheduler: Total delay: 1.826 s for time 1522602910000 ms (execution: 1.777 s)
18/04/01 20:15:11 INFO MapPartitionsRDD: Removing RDD 15 from persistence list
18/04/01 20:15:11 INFO BlockManager: Removing RDD 15
18/04/01 20:15:11 INFO KafkaRDD: Removing RDD 14 from persistence list
18/04/01 20:15:11 INFO BlockManager: Removing RDD 14
18/04/01 20:15:11 INFO ShuffledRDD: Removing RDD 16 from persistence list
18/04/01 20:15:11 INFO BlockManager: Removing RDD 16
18/04/01 20:15:11 INFO ShuffledRDD: Removing RDD 18 from persistence list
18/04/01 20:15:11 INFO BlockManager: Removing RDD 18
18/04/01 20:15:11 INFO MapPartitionsRDD: Removing RDD 17 from persistence list
18/04/01 20:15:11 INFO BlockManager: Removing RDD 17
18/04/01 20:15:11 INFO ShuffledRDD: Removing RDD 20 from persistence list
18/04/01 20:15:11 INFO BlockManager: Removing RDD 20
18/04/01 20:15:11 INFO MapPartitionsRDD: Removing RDD 19 from persistence list
18/04/01 20:15:11 INFO BlockManager: Removing RDD 19
18/04/01 20:15:11 INFO JobGenerator: Checkpointing graph for time 1522602910000 ms
18/04/01 20:15:11 INFO DStreamGraph: Updating checkpoint data for time 1522602910000 ms
18/04/01 20:15:11 INFO DStreamGraph: Updated checkpoint data for time 1522602910000 ms
18/04/01 20:15:11 INFO CheckpointWriter: Submitted checkpoint of time 1522602910000 ms to writer queue
18/04/01 20:15:11 INFO CheckpointWriter: Saving checkpoint for time 1522602910000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602910000'
18/04/01 20:15:11 INFO CheckpointWriter: Checkpoint for time 1522602910000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602910000', took 5533 bytes and 23 ms
18/04/01 20:15:11 INFO DStreamGraph: Clearing checkpoint data for time 1522602910000 ms
18/04/01 20:15:11 INFO DStreamGraph: Cleared checkpoint data for time 1522602910000 ms
18/04/01 20:15:11 INFO ReceivedBlockTracker: Deleting batches: 
18/04/01 20:15:11 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/tmp/refs-xyzabb/receivedBlockMetadata older than 1522602905000: 
18/04/01 20:15:11 INFO InputInfoTracker: remove old batch metadata: 1522602900000 ms
18/04/01 20:15:15 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-0 to offset 709.
18/04/01 20:15:15 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-3 to offset 0.
18/04/01 20:15:15 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-4 to offset 0.
18/04/01 20:15:15 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-1 to offset 0.
18/04/01 20:15:15 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-2 to offset 0.
18/04/01 20:15:15 INFO JobScheduler: Added jobs for time 1522602915000 ms
18/04/01 20:15:15 INFO JobGenerator: Checkpointing graph for time 1522602915000 ms
18/04/01 20:15:15 INFO DStreamGraph: Updating checkpoint data for time 1522602915000 ms
18/04/01 20:15:15 INFO JobScheduler: Starting job streaming job 1522602915000 ms.0 from job set of time 1522602915000 ms
18/04/01 20:15:15 INFO DStreamGraph: Updated checkpoint data for time 1522602915000 ms
18/04/01 20:15:15 INFO CheckpointWriter: Submitted checkpoint of time 1522602915000 ms to writer queue
18/04/01 20:15:15 INFO CheckpointWriter: Saving checkpoint for time 1522602915000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602915000'
18/04/01 20:15:15 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:15:15 INFO DAGScheduler: Got job 20 (print at RefereeStats.scala:67) with 1 output partitions
18/04/01 20:15:15 INFO DAGScheduler: Final stage: ResultStage 32 (print at RefereeStats.scala:67)
18/04/01 20:15:15 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:15:15 INFO DAGScheduler: Missing parents: List()
18/04/01 20:15:15 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[29] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:15 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 3.0 KB, free 477.2 MB)
18/04/01 20:15:15 INFO CheckpointWriter: Checkpoint for time 1522602915000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602915000', took 5588 bytes and 43 ms
18/04/01 20:15:15 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.2 MB)
18/04/01 20:15:15 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:15 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[29] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0))
18/04/01 20:15:15 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
18/04/01 20:15:15 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 104, localhost, executor driver, partition 0, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:15 INFO Executor: Running task 0.0 in stage 32.0 (TID 104)
18/04/01 20:15:15 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:15 INFO Executor: Finished task 0.0 in stage 32.0 (TID 104). 704 bytes result sent to driver
18/04/01 20:15:15 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 104) in 8 ms on localhost (executor driver) (1/1)
18/04/01 20:15:15 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
18/04/01 20:15:15 INFO DAGScheduler: ResultStage 32 (print at RefereeStats.scala:67) finished in 0.028 s
18/04/01 20:15:15 INFO DAGScheduler: Job 20 finished: print at RefereeStats.scala:67, took 0.043138 s
18/04/01 20:15:15 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:15:15 INFO DAGScheduler: Got job 21 (print at RefereeStats.scala:67) with 4 output partitions
18/04/01 20:15:15 INFO DAGScheduler: Final stage: ResultStage 33 (print at RefereeStats.scala:67)
18/04/01 20:15:15 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:15:15 INFO DAGScheduler: Missing parents: List()
18/04/01 20:15:15 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[29] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:15 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 3.0 KB, free 477.2 MB)
18/04/01 20:15:15 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.2 MB)
18/04/01 20:15:15 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:15 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:15 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 33 (MapPartitionsRDD[29] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
18/04/01 20:15:15 INFO TaskSchedulerImpl: Adding task set 33.0 with 4 tasks
18/04/01 20:15:15 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 105, localhost, executor driver, partition 1, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:15 INFO TaskSetManager: Starting task 1.0 in stage 33.0 (TID 106, localhost, executor driver, partition 2, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:15 INFO Executor: Running task 0.0 in stage 33.0 (TID 105)
18/04/01 20:15:15 INFO Executor: Running task 1.0 in stage 33.0 (TID 106)
18/04/01 20:15:15 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:15 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:15 INFO Executor: Finished task 1.0 in stage 33.0 (TID 106). 704 bytes result sent to driver
18/04/01 20:15:15 INFO Executor: Finished task 0.0 in stage 33.0 (TID 105). 704 bytes result sent to driver
18/04/01 20:15:15 INFO TaskSetManager: Starting task 2.0 in stage 33.0 (TID 107, localhost, executor driver, partition 3, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:15 INFO TaskSetManager: Finished task 1.0 in stage 33.0 (TID 106) in 8 ms on localhost (executor driver) (1/4)
18/04/01 20:15:15 INFO Executor: Running task 2.0 in stage 33.0 (TID 107)
18/04/01 20:15:15 INFO TaskSetManager: Starting task 3.0 in stage 33.0 (TID 108, localhost, executor driver, partition 4, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:15 INFO Executor: Running task 3.0 in stage 33.0 (TID 108)
18/04/01 20:15:15 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 105) in 10 ms on localhost (executor driver) (2/4)
18/04/01 20:15:15 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:15 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 707 -> 709
18/04/01 20:15:15 INFO Executor: Finished task 2.0 in stage 33.0 (TID 107). 747 bytes result sent to driver
18/04/01 20:15:15 INFO TaskSetManager: Finished task 2.0 in stage 33.0 (TID 107) in 10 ms on localhost (executor driver) (3/4)
18/04/01 20:15:15 INFO Executor: Finished task 3.0 in stage 33.0 (TID 108). 892 bytes result sent to driver
18/04/01 20:15:15 INFO TaskSetManager: Finished task 3.0 in stage 33.0 (TID 108) in 15 ms on localhost (executor driver) (4/4)
18/04/01 20:15:15 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
18/04/01 20:15:15 INFO DAGScheduler: ResultStage 33 (print at RefereeStats.scala:67) finished in 0.039 s
18/04/01 20:15:15 INFO DAGScheduler: Job 21 finished: print at RefereeStats.scala:67, took 0.045088 s
-------------------------------------------
Time: 1522602915000 ms
-------------------------------------------
(telegram.ru,6000)
(google.*,10000)

18/04/01 20:15:15 INFO JobScheduler: Finished job streaming job 1522602915000 ms.0 from job set of time 1522602915000 ms
18/04/01 20:15:15 INFO JobScheduler: Starting job streaming job 1522602915000 ms.1 from job set of time 1522602915000 ms
18/04/01 20:15:15 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:71
18/04/01 20:15:15 INFO DAGScheduler: Registering RDD 29 (map at RefereeStats.scala:53)
18/04/01 20:15:15 INFO DAGScheduler: Got job 22 (foreachPartition at RefereeStats.scala:71) with 2 output partitions
18/04/01 20:15:15 INFO DAGScheduler: Final stage: ResultStage 35 (foreachPartition at RefereeStats.scala:71)
18/04/01 20:15:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)
18/04/01 20:15:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 34)
18/04/01 20:15:15 INFO DAGScheduler: Submitting ShuffleMapStage 34 (MapPartitionsRDD[29] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:15 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:15:15 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:15:15 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:15 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:15 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[29] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:15 INFO TaskSchedulerImpl: Adding task set 34.0 with 5 tasks
18/04/01 20:15:15 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 109, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:15 INFO TaskSetManager: Starting task 1.0 in stage 34.0 (TID 110, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:15 INFO Executor: Running task 1.0 in stage 34.0 (TID 110)
18/04/01 20:15:15 INFO Executor: Running task 0.0 in stage 34.0 (TID 109)
18/04/01 20:15:15 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:15 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:15 INFO Executor: Finished task 1.0 in stage 34.0 (TID 110). 938 bytes result sent to driver
18/04/01 20:15:15 INFO TaskSetManager: Starting task 2.0 in stage 34.0 (TID 111, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:15 INFO TaskSetManager: Finished task 1.0 in stage 34.0 (TID 110) in 16 ms on localhost (executor driver) (1/5)
18/04/01 20:15:15 INFO Executor: Running task 2.0 in stage 34.0 (TID 111)
18/04/01 20:15:15 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:15 INFO Executor: Finished task 2.0 in stage 34.0 (TID 111). 938 bytes result sent to driver
18/04/01 20:15:15 INFO Executor: Finished task 0.0 in stage 34.0 (TID 109). 938 bytes result sent to driver
18/04/01 20:15:15 INFO TaskSetManager: Starting task 3.0 in stage 34.0 (TID 112, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:15 INFO Executor: Running task 3.0 in stage 34.0 (TID 112)
18/04/01 20:15:15 INFO TaskSetManager: Finished task 2.0 in stage 34.0 (TID 111) in 13 ms on localhost (executor driver) (2/5)
18/04/01 20:15:15 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:15 INFO Executor: Finished task 3.0 in stage 34.0 (TID 112). 981 bytes result sent to driver
18/04/01 20:15:15 INFO TaskSetManager: Starting task 4.0 in stage 34.0 (TID 113, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:15 INFO TaskSetManager: Finished task 3.0 in stage 34.0 (TID 112) in 12 ms on localhost (executor driver) (3/5)
18/04/01 20:15:15 INFO Executor: Running task 4.0 in stage 34.0 (TID 113)
18/04/01 20:15:15 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 109) in 40 ms on localhost (executor driver) (4/5)
18/04/01 20:15:15 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 707 -> 709
18/04/01 20:15:15 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 707
18/04/01 20:15:15 INFO Executor: Finished task 4.0 in stage 34.0 (TID 113). 1024 bytes result sent to driver
18/04/01 20:15:15 INFO TaskSetManager: Finished task 4.0 in stage 34.0 (TID 113) in 431 ms on localhost (executor driver) (5/5)
18/04/01 20:15:15 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
18/04/01 20:15:15 INFO DAGScheduler: ShuffleMapStage 34 (map at RefereeStats.scala:53) finished in 0.487 s
18/04/01 20:15:15 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:15 INFO DAGScheduler: running: Set()
18/04/01 20:15:15 INFO DAGScheduler: waiting: Set(ResultStage 35)
18/04/01 20:15:15 INFO DAGScheduler: failed: Set()
18/04/01 20:15:15 INFO DAGScheduler: Submitting ResultStage 35 (ShuffledRDD[30] at reduceByKey at RefereeStats.scala:60), which has no missing parents
18/04/01 20:15:15 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 668
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 654
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 740
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 573
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 617
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 656
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 619
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 843
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 648
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 673
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 702
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 706
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 743
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 812
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 585
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 615
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 847
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 711
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 811
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 734
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 586
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 773
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 596
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 666
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 633
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 776
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 572
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 559
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 613
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 826
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 735
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 584
18/04/01 20:15:15 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 1706.0 B, free 477.2 MB)
18/04/01 20:15:15 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 192.168.1.3:35449 (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:15:15 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 35 (ShuffledRDD[30] at reduceByKey at RefereeStats.scala:60) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:15 INFO TaskSchedulerImpl: Adding task set 35.0 with 2 tasks
18/04/01 20:15:15 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 114, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:15:15 INFO TaskSetManager: Starting task 1.0 in stage 35.0 (TID 115, localhost, executor driver, partition 1, ANY, 7649 bytes)
18/04/01 20:15:15 INFO Executor: Running task 0.0 in stage 35.0 (TID 114)
18/04/01 20:15:15 INFO ContextCleaner: Cleaned shuffle 8
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 578
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 652
18/04/01 20:15:15 INFO Executor: Running task 1.0 in stage 35.0 (TID 115)
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 694
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 772
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 667
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 661
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 724
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 838
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 737
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 674
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 723
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 790
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 710
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 669
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 564
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 599
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 707
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 621
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 844
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 730
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 550
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 680
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 556
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 609
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 589
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 820
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 582
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 783
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 686
18/04/01 20:15:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:15 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:15 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:15 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:15 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 644
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 782
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 568
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 805
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 761
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 763
18/04/01 20:15:15 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:15 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:15 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 687
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 725
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 836
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 807
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 845
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 824
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 699
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 739
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 671
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 620
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 682
18/04/01 20:15:15 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 569
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 626
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 802
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 771
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 591
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 786
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 750
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 817
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 608
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 800
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 780
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 574
18/04/01 20:15:15 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 818
18/04/01 20:15:15 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 788
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 756
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 593
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 791
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 605
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 728
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 781
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 717
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 803
18/04/01 20:15:15 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 746
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 692
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 778
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 551
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 779
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 695
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 636
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 708
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 720
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 618
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 665
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 553
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 726
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 830
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 601
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 631
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 754
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 731
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 759
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 679
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 816
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 814
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 701
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 774
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 616
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 660
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 562
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 597
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 594
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 753
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 555
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 561
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 789
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 675
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 629
18/04/01 20:15:15 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:15 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:15 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:15 INFO KafkaProducer: [Producer clientId=producer-26] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 760
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 627
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 606
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 714
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 677
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 715
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 828
18/04/01 20:15:15 INFO KafkaProducer: [Producer clientId=producer-25] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 797
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 672
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 655
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 570
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 769
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 832
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 678
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 712
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 662
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 611
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 798
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 664
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 565
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 684
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 558
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 639
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 709
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 733
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 752
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 801
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 641
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 552
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 833
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 690
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 823
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 637
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 603
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 757
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 649
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 819
18/04/01 20:15:15 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 192.168.1.3:35449 in memory (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 831
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 765
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 846
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 645
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 716
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 770
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 848
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 729
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 822
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 663
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 579
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 697
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 647
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 643
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 764
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 841
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 604
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 685
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 839
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 625
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 792
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 577
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 806
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 560
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 719
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 758
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 670
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 849
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 787
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 742
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 563
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 704
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 767
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 834
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 810
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 612
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 738
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 748
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 600
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 638
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 683
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 566
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 622
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 642
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 768
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 624
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 557
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 835
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 766
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 632
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 595
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 727
18/04/01 20:15:15 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 192.168.1.3:35449 in memory (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 614
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 809
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 796
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 808
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 837
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 688
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 815
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 744
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 821
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 813
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 691
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 703
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 777
18/04/01 20:15:15 INFO Executor: Finished task 0.0 in stage 35.0 (TID 114). 1138 bytes result sent to driver
18/04/01 20:15:15 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 114) in 88 ms on localhost (executor driver) (1/2)
18/04/01 20:15:15 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 634
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 799
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 658
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 689
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 635
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 576
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 721
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 842
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 755
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 598
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 630
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 650
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 657
18/04/01 20:15:15 INFO Executor: Finished task 1.0 in stage 35.0 (TID 115). 1138 bytes result sent to driver
18/04/01 20:15:15 INFO TaskSetManager: Finished task 1.0 in stage 35.0 (TID 115) in 94 ms on localhost (executor driver) (2/2)
18/04/01 20:15:15 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
18/04/01 20:15:15 INFO DAGScheduler: ResultStage 35 (foreachPartition at RefereeStats.scala:71) finished in 0.123 s
18/04/01 20:15:15 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 192.168.1.3:35449 in memory (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:15:15 INFO DAGScheduler: Job 22 finished: foreachPartition at RefereeStats.scala:71, took 0.620957 s
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 713
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 736
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 793
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 827
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 587
18/04/01 20:15:15 INFO JobScheduler: Finished job streaming job 1522602915000 ms.1 from job set of time 1522602915000 ms
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 795
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 640
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 681
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 696
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 554
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 722
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 583
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 607
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 623
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 659
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 751
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 718
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 775
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 741
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 651
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 592
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 749
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 732
18/04/01 20:15:15 INFO JobScheduler: Starting job streaming job 1522602915000 ms.2 from job set of time 1522602915000 ms
18/04/01 20:15:15 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 192.168.1.3:35449 in memory (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 653
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 840
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 700
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 567
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 804
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 571
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 747
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 705
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 646
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 581
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 762
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 602
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 628
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 575
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 676
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 829
18/04/01 20:15:15 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 785
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 784
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 698
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 590
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 794
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 745
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 588
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 825
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 693
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 580
18/04/01 20:15:15 INFO ContextCleaner: Cleaned accumulator 610
18/04/01 20:15:15 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:89
18/04/01 20:15:15 INFO DAGScheduler: Registering RDD 31 (map at RefereeStats.scala:46)
18/04/01 20:15:15 INFO DAGScheduler: Got job 23 (foreachPartition at RefereeStats.scala:89) with 2 output partitions
18/04/01 20:15:15 INFO DAGScheduler: Final stage: ResultStage 37 (foreachPartition at RefereeStats.scala:89)
18/04/01 20:15:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 36)
18/04/01 20:15:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 36)
18/04/01 20:15:15 INFO DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[31] at map at RefereeStats.scala:46), which has no missing parents
18/04/01 20:15:15 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 3.9 KB, free 477.3 MB)
18/04/01 20:15:15 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.3 MB)
18/04/01 20:15:15 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:15 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:15 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[31] at map at RefereeStats.scala:46) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:15 INFO TaskSchedulerImpl: Adding task set 36.0 with 5 tasks
18/04/01 20:15:15 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 116, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:15 INFO TaskSetManager: Starting task 1.0 in stage 36.0 (TID 117, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:15 INFO Executor: Running task 0.0 in stage 36.0 (TID 116)
18/04/01 20:15:15 INFO Executor: Running task 1.0 in stage 36.0 (TID 117)
18/04/01 20:15:15 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:15 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:15 INFO Executor: Finished task 0.0 in stage 36.0 (TID 116). 938 bytes result sent to driver
18/04/01 20:15:15 INFO TaskSetManager: Starting task 2.0 in stage 36.0 (TID 118, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:15 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 116) in 17 ms on localhost (executor driver) (1/5)
18/04/01 20:15:15 INFO Executor: Running task 2.0 in stage 36.0 (TID 118)
18/04/01 20:15:15 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:15 INFO Executor: Finished task 2.0 in stage 36.0 (TID 118). 938 bytes result sent to driver
18/04/01 20:15:15 INFO TaskSetManager: Starting task 3.0 in stage 36.0 (TID 119, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:15 INFO TaskSetManager: Finished task 2.0 in stage 36.0 (TID 118) in 13 ms on localhost (executor driver) (2/5)
18/04/01 20:15:15 INFO Executor: Running task 3.0 in stage 36.0 (TID 119)
18/04/01 20:15:15 INFO Executor: Finished task 1.0 in stage 36.0 (TID 117). 981 bytes result sent to driver
18/04/01 20:15:15 INFO TaskSetManager: Starting task 4.0 in stage 36.0 (TID 120, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:15 INFO TaskSetManager: Finished task 1.0 in stage 36.0 (TID 117) in 30 ms on localhost (executor driver) (3/5)
18/04/01 20:15:15 INFO Executor: Running task 4.0 in stage 36.0 (TID 120)
18/04/01 20:15:15 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:15 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 707 -> 709
18/04/01 20:15:15 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 707
18/04/01 20:15:15 INFO Executor: Finished task 3.0 in stage 36.0 (TID 119). 938 bytes result sent to driver
18/04/01 20:15:15 INFO TaskSetManager: Finished task 3.0 in stage 36.0 (TID 119) in 18 ms on localhost (executor driver) (4/5)
18/04/01 20:15:16 INFO Executor: Finished task 4.0 in stage 36.0 (TID 120). 1024 bytes result sent to driver
18/04/01 20:15:16 INFO TaskSetManager: Finished task 4.0 in stage 36.0 (TID 120) in 298 ms on localhost (executor driver) (5/5)
18/04/01 20:15:16 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
18/04/01 20:15:16 INFO DAGScheduler: ShuffleMapStage 36 (map at RefereeStats.scala:46) finished in 0.347 s
18/04/01 20:15:16 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:16 INFO DAGScheduler: running: Set()
18/04/01 20:15:16 INFO DAGScheduler: waiting: Set(ResultStage 37)
18/04/01 20:15:16 INFO DAGScheduler: failed: Set()
18/04/01 20:15:16 INFO DAGScheduler: Submitting ResultStage 37 (ShuffledRDD[32] at reduceByKey at RefereeStats.scala:51), which has no missing parents
18/04/01 20:15:16 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 2.8 KB, free 477.3 MB)
18/04/01 20:15:16 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 1709.0 B, free 477.3 MB)
18/04/01 20:15:16 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 192.168.1.3:35449 (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:15:16 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 37 (ShuffledRDD[32] at reduceByKey at RefereeStats.scala:51) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:16 INFO TaskSchedulerImpl: Adding task set 37.0 with 2 tasks
18/04/01 20:15:16 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 121, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:15:16 INFO TaskSetManager: Starting task 1.0 in stage 37.0 (TID 122, localhost, executor driver, partition 1, ANY, 7649 bytes)
18/04/01 20:15:16 INFO Executor: Running task 0.0 in stage 37.0 (TID 121)
18/04/01 20:15:16 INFO Executor: Running task 1.0 in stage 37.0 (TID 122)
18/04/01 20:15:16 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:16 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:16 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:16 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:16 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:16 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:16 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:16 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:16 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:16 INFO KafkaProducer: [Producer clientId=producer-27] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:16 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:16 INFO KafkaProducer: [Producer clientId=producer-28] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:16 INFO Executor: Finished task 1.0 in stage 37.0 (TID 122). 1138 bytes result sent to driver
18/04/01 20:15:16 INFO TaskSetManager: Finished task 1.0 in stage 37.0 (TID 122) in 64 ms on localhost (executor driver) (1/2)
18/04/01 20:15:16 INFO Executor: Finished task 0.0 in stage 37.0 (TID 121). 1138 bytes result sent to driver
18/04/01 20:15:16 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 121) in 79 ms on localhost (executor driver) (2/2)
18/04/01 20:15:16 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
18/04/01 20:15:16 INFO DAGScheduler: ResultStage 37 (foreachPartition at RefereeStats.scala:89) finished in 0.093 s
18/04/01 20:15:16 INFO DAGScheduler: Job 23 finished: foreachPartition at RefereeStats.scala:89, took 0.453755 s
18/04/01 20:15:16 INFO JobScheduler: Finished job streaming job 1522602915000 ms.2 from job set of time 1522602915000 ms
18/04/01 20:15:16 INFO JobScheduler: Starting job streaming job 1522602915000 ms.3 from job set of time 1522602915000 ms
18/04/01 20:15:16 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:106
18/04/01 20:15:16 INFO DAGScheduler: Registering RDD 33 (map at RefereeStats.scala:39)
18/04/01 20:15:16 INFO DAGScheduler: Got job 24 (foreachPartition at RefereeStats.scala:106) with 2 output partitions
18/04/01 20:15:16 INFO DAGScheduler: Final stage: ResultStage 39 (foreachPartition at RefereeStats.scala:106)
18/04/01 20:15:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 38)
18/04/01 20:15:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 38)
18/04/01 20:15:16 INFO DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[33] at map at RefereeStats.scala:39), which has no missing parents
18/04/01 20:15:16 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 3.9 KB, free 477.3 MB)
18/04/01 20:15:16 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.3 MB)
18/04/01 20:15:16 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:16 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:16 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[33] at map at RefereeStats.scala:39) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:16 INFO TaskSchedulerImpl: Adding task set 38.0 with 5 tasks
18/04/01 20:15:16 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 123, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:16 INFO TaskSetManager: Starting task 1.0 in stage 38.0 (TID 124, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:16 INFO Executor: Running task 0.0 in stage 38.0 (TID 123)
18/04/01 20:15:16 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:16 INFO Executor: Running task 1.0 in stage 38.0 (TID 124)
18/04/01 20:15:16 INFO Executor: Finished task 0.0 in stage 38.0 (TID 123). 938 bytes result sent to driver
18/04/01 20:15:16 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:16 INFO TaskSetManager: Starting task 2.0 in stage 38.0 (TID 125, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:16 INFO Executor: Running task 2.0 in stage 38.0 (TID 125)
18/04/01 20:15:16 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 123) in 13 ms on localhost (executor driver) (1/5)
18/04/01 20:15:16 INFO Executor: Finished task 1.0 in stage 38.0 (TID 124). 938 bytes result sent to driver
18/04/01 20:15:16 INFO TaskSetManager: Starting task 3.0 in stage 38.0 (TID 126, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:16 INFO TaskSetManager: Finished task 1.0 in stage 38.0 (TID 124) in 17 ms on localhost (executor driver) (2/5)
18/04/01 20:15:16 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:16 INFO Executor: Running task 3.0 in stage 38.0 (TID 126)
18/04/01 20:15:16 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:16 INFO Executor: Finished task 2.0 in stage 38.0 (TID 125). 938 bytes result sent to driver
18/04/01 20:15:16 INFO TaskSetManager: Starting task 4.0 in stage 38.0 (TID 127, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:16 INFO TaskSetManager: Finished task 2.0 in stage 38.0 (TID 125) in 14 ms on localhost (executor driver) (3/5)
18/04/01 20:15:16 INFO Executor: Finished task 3.0 in stage 38.0 (TID 126). 938 bytes result sent to driver
18/04/01 20:15:16 INFO TaskSetManager: Finished task 3.0 in stage 38.0 (TID 126) in 11 ms on localhost (executor driver) (4/5)
18/04/01 20:15:16 INFO Executor: Running task 4.0 in stage 38.0 (TID 127)
18/04/01 20:15:16 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 707 -> 709
18/04/01 20:15:16 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 707
18/04/01 20:15:16 INFO Executor: Finished task 4.0 in stage 38.0 (TID 127). 1024 bytes result sent to driver
18/04/01 20:15:16 INFO TaskSetManager: Finished task 4.0 in stage 38.0 (TID 127) in 345 ms on localhost (executor driver) (5/5)
18/04/01 20:15:16 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
18/04/01 20:15:16 INFO DAGScheduler: ShuffleMapStage 38 (map at RefereeStats.scala:39) finished in 0.388 s
18/04/01 20:15:16 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:16 INFO DAGScheduler: running: Set()
18/04/01 20:15:16 INFO DAGScheduler: waiting: Set(ResultStage 39)
18/04/01 20:15:16 INFO DAGScheduler: failed: Set()
18/04/01 20:15:16 INFO DAGScheduler: Submitting ResultStage 39 (ShuffledRDD[34] at reduceByKey at RefereeStats.scala:43), which has no missing parents
18/04/01 20:15:16 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 2.8 KB, free 477.3 MB)
18/04/01 20:15:16 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 1703.0 B, free 477.3 MB)
18/04/01 20:15:16 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 192.168.1.3:35449 (size: 1703.0 B, free: 477.3 MB)
18/04/01 20:15:16 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 39 (ShuffledRDD[34] at reduceByKey at RefereeStats.scala:43) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:16 INFO TaskSchedulerImpl: Adding task set 39.0 with 2 tasks
18/04/01 20:15:16 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 128, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:15:16 INFO TaskSetManager: Starting task 1.0 in stage 39.0 (TID 129, localhost, executor driver, partition 1, ANY, 7649 bytes)
18/04/01 20:15:16 INFO Executor: Running task 0.0 in stage 39.0 (TID 128)
18/04/01 20:15:16 INFO Executor: Running task 1.0 in stage 39.0 (TID 129)
18/04/01 20:15:16 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
18/04/01 20:15:16 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:16 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:16 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:16 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:16 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:16 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:16 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:16 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:16 INFO KafkaProducer: [Producer clientId=producer-30] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:16 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:16 INFO KafkaProducer: [Producer clientId=producer-29] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:16 INFO Executor: Finished task 0.0 in stage 39.0 (TID 128). 1138 bytes result sent to driver
18/04/01 20:15:16 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 128) in 70 ms on localhost (executor driver) (1/2)
18/04/01 20:15:16 INFO Executor: Finished task 1.0 in stage 39.0 (TID 129). 1138 bytes result sent to driver
18/04/01 20:15:16 INFO TaskSetManager: Finished task 1.0 in stage 39.0 (TID 129) in 87 ms on localhost (executor driver) (2/2)
18/04/01 20:15:16 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
18/04/01 20:15:16 INFO DAGScheduler: ResultStage 39 (foreachPartition at RefereeStats.scala:106) finished in 0.101 s
18/04/01 20:15:16 INFO DAGScheduler: Job 24 finished: foreachPartition at RefereeStats.scala:106, took 0.502728 s
18/04/01 20:15:16 INFO JobScheduler: Finished job streaming job 1522602915000 ms.3 from job set of time 1522602915000 ms
18/04/01 20:15:16 INFO JobScheduler: Total delay: 1.792 s for time 1522602915000 ms (execution: 1.756 s)
18/04/01 20:15:16 INFO MapPartitionsRDD: Removing RDD 22 from persistence list
18/04/01 20:15:16 INFO KafkaRDD: Removing RDD 21 from persistence list
18/04/01 20:15:16 INFO BlockManager: Removing RDD 22
18/04/01 20:15:16 INFO BlockManager: Removing RDD 21
18/04/01 20:15:16 INFO ShuffledRDD: Removing RDD 23 from persistence list
18/04/01 20:15:16 INFO BlockManager: Removing RDD 23
18/04/01 20:15:16 INFO ShuffledRDD: Removing RDD 25 from persistence list
18/04/01 20:15:16 INFO BlockManager: Removing RDD 25
18/04/01 20:15:16 INFO MapPartitionsRDD: Removing RDD 24 from persistence list
18/04/01 20:15:16 INFO BlockManager: Removing RDD 24
18/04/01 20:15:16 INFO ShuffledRDD: Removing RDD 27 from persistence list
18/04/01 20:15:16 INFO BlockManager: Removing RDD 27
18/04/01 20:15:16 INFO MapPartitionsRDD: Removing RDD 26 from persistence list
18/04/01 20:15:16 INFO BlockManager: Removing RDD 26
18/04/01 20:15:16 INFO JobGenerator: Checkpointing graph for time 1522602915000 ms
18/04/01 20:15:16 INFO DStreamGraph: Updating checkpoint data for time 1522602915000 ms
18/04/01 20:15:16 INFO DStreamGraph: Updated checkpoint data for time 1522602915000 ms
18/04/01 20:15:16 INFO CheckpointWriter: Saving checkpoint for time 1522602915000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602915000'
18/04/01 20:15:16 INFO CheckpointWriter: Submitted checkpoint of time 1522602915000 ms to writer queue
18/04/01 20:15:16 INFO CheckpointWriter: Checkpoint for time 1522602915000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602915000', took 5536 bytes and 27 ms
18/04/01 20:15:16 INFO DStreamGraph: Clearing checkpoint data for time 1522602915000 ms
18/04/01 20:15:16 INFO DStreamGraph: Cleared checkpoint data for time 1522602915000 ms
18/04/01 20:15:16 INFO ReceivedBlockTracker: Deleting batches: 
18/04/01 20:15:16 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/tmp/refs-xyzabb/receivedBlockMetadata older than 1522602910000: 
18/04/01 20:15:16 INFO InputInfoTracker: remove old batch metadata: 1522602905000 ms
18/04/01 20:15:20 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-0 to offset 711.
18/04/01 20:15:20 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-3 to offset 0.
18/04/01 20:15:20 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-4 to offset 0.
18/04/01 20:15:20 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-1 to offset 0.
18/04/01 20:15:20 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-2 to offset 0.
18/04/01 20:15:20 INFO JobScheduler: Added jobs for time 1522602920000 ms
18/04/01 20:15:20 INFO JobGenerator: Checkpointing graph for time 1522602920000 ms
18/04/01 20:15:20 INFO DStreamGraph: Updating checkpoint data for time 1522602920000 ms
18/04/01 20:15:20 INFO JobScheduler: Starting job streaming job 1522602920000 ms.0 from job set of time 1522602920000 ms
18/04/01 20:15:20 INFO DStreamGraph: Updated checkpoint data for time 1522602920000 ms
18/04/01 20:15:20 INFO CheckpointWriter: Submitted checkpoint of time 1522602920000 ms to writer queue
18/04/01 20:15:20 INFO CheckpointWriter: Saving checkpoint for time 1522602920000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602920000'
18/04/01 20:15:20 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:15:20 INFO DAGScheduler: Got job 25 (print at RefereeStats.scala:67) with 1 output partitions
18/04/01 20:15:20 INFO DAGScheduler: Final stage: ResultStage 40 (print at RefereeStats.scala:67)
18/04/01 20:15:20 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:15:20 INFO DAGScheduler: Missing parents: List()
18/04/01 20:15:20 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[36] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:20 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 3.0 KB, free 477.2 MB)
18/04/01 20:15:20 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602895000.bk
18/04/01 20:15:20 INFO CheckpointWriter: Checkpoint for time 1522602920000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602920000', took 5591 bytes and 30 ms
18/04/01 20:15:20 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.2 MB)
18/04/01 20:15:20 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:20 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[36] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0))
18/04/01 20:15:20 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
18/04/01 20:15:20 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 130, localhost, executor driver, partition 0, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:20 INFO Executor: Running task 0.0 in stage 40.0 (TID 130)
18/04/01 20:15:20 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:20 INFO Executor: Finished task 0.0 in stage 40.0 (TID 130). 704 bytes result sent to driver
18/04/01 20:15:20 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 130) in 7 ms on localhost (executor driver) (1/1)
18/04/01 20:15:20 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
18/04/01 20:15:20 INFO DAGScheduler: ResultStage 40 (print at RefereeStats.scala:67) finished in 0.023 s
18/04/01 20:15:20 INFO DAGScheduler: Job 25 finished: print at RefereeStats.scala:67, took 0.031488 s
18/04/01 20:15:20 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:15:20 INFO DAGScheduler: Got job 26 (print at RefereeStats.scala:67) with 4 output partitions
18/04/01 20:15:20 INFO DAGScheduler: Final stage: ResultStage 41 (print at RefereeStats.scala:67)
18/04/01 20:15:20 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:15:20 INFO DAGScheduler: Missing parents: List()
18/04/01 20:15:20 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[36] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:20 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 3.0 KB, free 477.2 MB)
18/04/01 20:15:20 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.2 MB)
18/04/01 20:15:20 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:20 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 41 (MapPartitionsRDD[36] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
18/04/01 20:15:20 INFO TaskSchedulerImpl: Adding task set 41.0 with 4 tasks
18/04/01 20:15:20 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 131, localhost, executor driver, partition 1, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:20 INFO TaskSetManager: Starting task 1.0 in stage 41.0 (TID 132, localhost, executor driver, partition 2, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:20 INFO Executor: Running task 0.0 in stage 41.0 (TID 131)
18/04/01 20:15:20 INFO Executor: Running task 1.0 in stage 41.0 (TID 132)
18/04/01 20:15:20 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:20 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:20 INFO Executor: Finished task 1.0 in stage 41.0 (TID 132). 747 bytes result sent to driver
18/04/01 20:15:20 INFO Executor: Finished task 0.0 in stage 41.0 (TID 131). 704 bytes result sent to driver
18/04/01 20:15:20 INFO TaskSetManager: Starting task 2.0 in stage 41.0 (TID 133, localhost, executor driver, partition 3, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:20 INFO Executor: Running task 2.0 in stage 41.0 (TID 133)
18/04/01 20:15:20 INFO TaskSetManager: Starting task 3.0 in stage 41.0 (TID 134, localhost, executor driver, partition 4, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:20 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:20 INFO Executor: Finished task 2.0 in stage 41.0 (TID 133). 704 bytes result sent to driver
18/04/01 20:15:20 INFO TaskSetManager: Finished task 1.0 in stage 41.0 (TID 132) in 15 ms on localhost (executor driver) (1/4)
18/04/01 20:15:20 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 131) in 16 ms on localhost (executor driver) (2/4)
18/04/01 20:15:20 INFO TaskSetManager: Finished task 2.0 in stage 41.0 (TID 133) in 7 ms on localhost (executor driver) (3/4)
18/04/01 20:15:20 INFO Executor: Running task 3.0 in stage 41.0 (TID 134)
18/04/01 20:15:20 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 709 -> 711
18/04/01 20:15:20 INFO Executor: Finished task 3.0 in stage 41.0 (TID 134). 890 bytes result sent to driver
18/04/01 20:15:20 INFO TaskSetManager: Finished task 3.0 in stage 41.0 (TID 134) in 17 ms on localhost (executor driver) (4/4)
18/04/01 20:15:20 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
18/04/01 20:15:20 INFO DAGScheduler: ResultStage 41 (print at RefereeStats.scala:67) finished in 0.045 s
18/04/01 20:15:20 INFO DAGScheduler: Job 26 finished: print at RefereeStats.scala:67, took 0.052073 s
18/04/01 20:15:20 INFO JobScheduler: Finished job streaming job 1522602920000 ms.0 from job set of time 1522602920000 ms
18/04/01 20:15:20 INFO JobScheduler: Starting job streaming job 1522602920000 ms.1 from job set of time 1522602920000 ms
-------------------------------------------
Time: 1522602920000 ms
-------------------------------------------
(quora.com,0)
(nextanalytics.com,0)

18/04/01 20:15:20 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:71
18/04/01 20:15:20 INFO DAGScheduler: Registering RDD 36 (map at RefereeStats.scala:53)
18/04/01 20:15:20 INFO DAGScheduler: Got job 27 (foreachPartition at RefereeStats.scala:71) with 2 output partitions
18/04/01 20:15:20 INFO DAGScheduler: Final stage: ResultStage 43 (foreachPartition at RefereeStats.scala:71)
18/04/01 20:15:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 42)
18/04/01 20:15:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 42)
18/04/01 20:15:20 INFO DAGScheduler: Submitting ShuffleMapStage 42 (MapPartitionsRDD[36] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:20 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:15:20 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:15:20 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:20 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:20 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[36] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:20 INFO TaskSchedulerImpl: Adding task set 42.0 with 5 tasks
18/04/01 20:15:20 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 135, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:20 INFO TaskSetManager: Starting task 1.0 in stage 42.0 (TID 136, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:20 INFO Executor: Running task 1.0 in stage 42.0 (TID 136)
18/04/01 20:15:20 INFO Executor: Running task 0.0 in stage 42.0 (TID 135)
18/04/01 20:15:20 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:20 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:20 INFO Executor: Finished task 1.0 in stage 42.0 (TID 136). 938 bytes result sent to driver
18/04/01 20:15:20 INFO Executor: Finished task 0.0 in stage 42.0 (TID 135). 938 bytes result sent to driver
18/04/01 20:15:20 INFO TaskSetManager: Starting task 2.0 in stage 42.0 (TID 137, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:20 INFO TaskSetManager: Finished task 1.0 in stage 42.0 (TID 136) in 9 ms on localhost (executor driver) (1/5)
18/04/01 20:15:20 INFO Executor: Running task 2.0 in stage 42.0 (TID 137)
18/04/01 20:15:20 INFO TaskSetManager: Starting task 3.0 in stage 42.0 (TID 138, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:20 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 135) in 12 ms on localhost (executor driver) (2/5)
18/04/01 20:15:20 INFO Executor: Running task 3.0 in stage 42.0 (TID 138)
18/04/01 20:15:20 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:20 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:20 INFO Executor: Finished task 2.0 in stage 42.0 (TID 137). 938 bytes result sent to driver
18/04/01 20:15:20 INFO TaskSetManager: Starting task 4.0 in stage 42.0 (TID 139, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:20 INFO Executor: Running task 4.0 in stage 42.0 (TID 139)
18/04/01 20:15:20 INFO TaskSetManager: Finished task 2.0 in stage 42.0 (TID 137) in 11 ms on localhost (executor driver) (3/5)
18/04/01 20:15:20 INFO Executor: Finished task 3.0 in stage 42.0 (TID 138). 938 bytes result sent to driver
18/04/01 20:15:20 INFO TaskSetManager: Finished task 3.0 in stage 42.0 (TID 138) in 12 ms on localhost (executor driver) (4/5)
18/04/01 20:15:20 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 709 -> 711
18/04/01 20:15:20 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 709
18/04/01 20:15:20 INFO Executor: Finished task 4.0 in stage 42.0 (TID 139). 1024 bytes result sent to driver
18/04/01 20:15:20 INFO TaskSetManager: Finished task 4.0 in stage 42.0 (TID 139) in 462 ms on localhost (executor driver) (5/5)
18/04/01 20:15:20 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
18/04/01 20:15:20 INFO DAGScheduler: ShuffleMapStage 42 (map at RefereeStats.scala:53) finished in 0.493 s
18/04/01 20:15:20 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:20 INFO DAGScheduler: running: Set()
18/04/01 20:15:20 INFO DAGScheduler: waiting: Set(ResultStage 43)
18/04/01 20:15:20 INFO DAGScheduler: failed: Set()
18/04/01 20:15:20 INFO DAGScheduler: Submitting ResultStage 43 (ShuffledRDD[37] at reduceByKey at RefereeStats.scala:60), which has no missing parents
18/04/01 20:15:20 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:15:20 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 1706.0 B, free 477.2 MB)
18/04/01 20:15:20 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 192.168.1.3:35449 (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:15:20 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:20 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 43 (ShuffledRDD[37] at reduceByKey at RefereeStats.scala:60) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:20 INFO TaskSchedulerImpl: Adding task set 43.0 with 2 tasks
18/04/01 20:15:20 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 140, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:15:20 INFO TaskSetManager: Starting task 1.0 in stage 43.0 (TID 141, localhost, executor driver, partition 1, ANY, 7649 bytes)
18/04/01 20:15:20 INFO Executor: Running task 0.0 in stage 43.0 (TID 140)
18/04/01 20:15:20 INFO Executor: Running task 1.0 in stage 43.0 (TID 141)
18/04/01 20:15:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:15:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:15:20 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:20 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:20 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:20 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:20 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:20 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:20 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:20 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:20 INFO KafkaProducer: [Producer clientId=producer-32] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:20 INFO KafkaProducer: [Producer clientId=producer-31] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:20 INFO Executor: Finished task 1.0 in stage 43.0 (TID 141). 1138 bytes result sent to driver
18/04/01 20:15:20 INFO Executor: Finished task 0.0 in stage 43.0 (TID 140). 1138 bytes result sent to driver
18/04/01 20:15:20 INFO TaskSetManager: Finished task 1.0 in stage 43.0 (TID 141) in 101 ms on localhost (executor driver) (1/2)
18/04/01 20:15:20 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 140) in 103 ms on localhost (executor driver) (2/2)
18/04/01 20:15:20 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
18/04/01 20:15:20 INFO DAGScheduler: ResultStage 43 (foreachPartition at RefereeStats.scala:71) finished in 0.114 s
18/04/01 20:15:20 INFO DAGScheduler: Job 27 finished: foreachPartition at RefereeStats.scala:71, took 0.617406 s
18/04/01 20:15:20 INFO JobScheduler: Finished job streaming job 1522602920000 ms.1 from job set of time 1522602920000 ms
18/04/01 20:15:20 INFO JobScheduler: Starting job streaming job 1522602920000 ms.2 from job set of time 1522602920000 ms
18/04/01 20:15:20 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:89
18/04/01 20:15:20 INFO DAGScheduler: Registering RDD 38 (map at RefereeStats.scala:46)
18/04/01 20:15:20 INFO DAGScheduler: Got job 28 (foreachPartition at RefereeStats.scala:89) with 2 output partitions
18/04/01 20:15:20 INFO DAGScheduler: Final stage: ResultStage 45 (foreachPartition at RefereeStats.scala:89)
18/04/01 20:15:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 44)
18/04/01 20:15:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 44)
18/04/01 20:15:20 INFO DAGScheduler: Submitting ShuffleMapStage 44 (MapPartitionsRDD[38] at map at RefereeStats.scala:46), which has no missing parents
18/04/01 20:15:20 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:15:20 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:15:20 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:20 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:20 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[38] at map at RefereeStats.scala:46) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:20 INFO TaskSchedulerImpl: Adding task set 44.0 with 5 tasks
18/04/01 20:15:20 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 142, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:20 INFO TaskSetManager: Starting task 1.0 in stage 44.0 (TID 143, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:20 INFO Executor: Running task 0.0 in stage 44.0 (TID 142)
18/04/01 20:15:20 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:20 INFO Executor: Finished task 0.0 in stage 44.0 (TID 142). 938 bytes result sent to driver
18/04/01 20:15:20 INFO Executor: Running task 1.0 in stage 44.0 (TID 143)
18/04/01 20:15:20 INFO TaskSetManager: Starting task 2.0 in stage 44.0 (TID 144, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:20 INFO Executor: Running task 2.0 in stage 44.0 (TID 144)
18/04/01 20:15:20 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 142) in 10 ms on localhost (executor driver) (1/5)
18/04/01 20:15:20 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:20 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:20 INFO Executor: Finished task 1.0 in stage 44.0 (TID 143). 938 bytes result sent to driver
18/04/01 20:15:20 INFO Executor: Finished task 2.0 in stage 44.0 (TID 144). 938 bytes result sent to driver
18/04/01 20:15:20 INFO TaskSetManager: Starting task 3.0 in stage 44.0 (TID 145, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:20 INFO Executor: Running task 3.0 in stage 44.0 (TID 145)
18/04/01 20:15:20 INFO TaskSetManager: Starting task 4.0 in stage 44.0 (TID 146, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:20 INFO TaskSetManager: Finished task 1.0 in stage 44.0 (TID 143) in 17 ms on localhost (executor driver) (2/5)
18/04/01 20:15:20 INFO TaskSetManager: Finished task 2.0 in stage 44.0 (TID 144) in 10 ms on localhost (executor driver) (3/5)
18/04/01 20:15:20 INFO Executor: Running task 4.0 in stage 44.0 (TID 146)
18/04/01 20:15:20 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 709 -> 711
18/04/01 20:15:20 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 709
18/04/01 20:15:20 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:20 INFO Executor: Finished task 3.0 in stage 44.0 (TID 145). 938 bytes result sent to driver
18/04/01 20:15:20 INFO TaskSetManager: Finished task 3.0 in stage 44.0 (TID 145) in 14 ms on localhost (executor driver) (4/5)
18/04/01 20:15:21 INFO Executor: Finished task 4.0 in stage 44.0 (TID 146). 1024 bytes result sent to driver
18/04/01 20:15:21 INFO TaskSetManager: Finished task 4.0 in stage 44.0 (TID 146) in 331 ms on localhost (executor driver) (5/5)
18/04/01 20:15:21 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
18/04/01 20:15:21 INFO DAGScheduler: ShuffleMapStage 44 (map at RefereeStats.scala:46) finished in 0.362 s
18/04/01 20:15:21 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:21 INFO DAGScheduler: running: Set()
18/04/01 20:15:21 INFO DAGScheduler: waiting: Set(ResultStage 45)
18/04/01 20:15:21 INFO DAGScheduler: failed: Set()
18/04/01 20:15:21 INFO DAGScheduler: Submitting ResultStage 45 (ShuffledRDD[39] at reduceByKey at RefereeStats.scala:51), which has no missing parents
18/04/01 20:15:21 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:15:21 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 1709.0 B, free 477.2 MB)
18/04/01 20:15:21 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 192.168.1.3:35449 (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:15:21 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:21 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 45 (ShuffledRDD[39] at reduceByKey at RefereeStats.scala:51) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:21 INFO TaskSchedulerImpl: Adding task set 45.0 with 2 tasks
18/04/01 20:15:21 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 147, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:15:21 INFO TaskSetManager: Starting task 1.0 in stage 45.0 (TID 148, localhost, executor driver, partition 1, ANY, 7649 bytes)
18/04/01 20:15:21 INFO Executor: Running task 1.0 in stage 45.0 (TID 148)
18/04/01 20:15:21 INFO Executor: Running task 0.0 in stage 45.0 (TID 147)
18/04/01 20:15:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:21 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:21 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:21 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:21 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:21 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:21 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:21 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:21 INFO KafkaProducer: [Producer clientId=producer-33] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:21 INFO Executor: Finished task 0.0 in stage 45.0 (TID 147). 1138 bytes result sent to driver
18/04/01 20:15:21 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:21 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 147) in 47 ms on localhost (executor driver) (1/2)
18/04/01 20:15:21 INFO KafkaProducer: [Producer clientId=producer-34] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:21 INFO Executor: Finished task 1.0 in stage 45.0 (TID 148). 1138 bytes result sent to driver
18/04/01 20:15:21 INFO TaskSetManager: Finished task 1.0 in stage 45.0 (TID 148) in 64 ms on localhost (executor driver) (2/2)
18/04/01 20:15:21 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
18/04/01 20:15:21 INFO DAGScheduler: ResultStage 45 (foreachPartition at RefereeStats.scala:89) finished in 0.077 s
18/04/01 20:15:21 INFO DAGScheduler: Job 28 finished: foreachPartition at RefereeStats.scala:89, took 0.457098 s
18/04/01 20:15:21 INFO JobScheduler: Finished job streaming job 1522602920000 ms.2 from job set of time 1522602920000 ms
18/04/01 20:15:21 INFO JobScheduler: Starting job streaming job 1522602920000 ms.3 from job set of time 1522602920000 ms
18/04/01 20:15:21 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:106
18/04/01 20:15:21 INFO DAGScheduler: Registering RDD 40 (map at RefereeStats.scala:39)
18/04/01 20:15:21 INFO DAGScheduler: Got job 29 (foreachPartition at RefereeStats.scala:106) with 2 output partitions
18/04/01 20:15:21 INFO DAGScheduler: Final stage: ResultStage 47 (foreachPartition at RefereeStats.scala:106)
18/04/01 20:15:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 46)
18/04/01 20:15:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 46)
18/04/01 20:15:21 INFO DAGScheduler: Submitting ShuffleMapStage 46 (MapPartitionsRDD[40] at map at RefereeStats.scala:39), which has no missing parents
18/04/01 20:15:21 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:15:21 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:15:21 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:21 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:21 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 46 (MapPartitionsRDD[40] at map at RefereeStats.scala:39) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:21 INFO TaskSchedulerImpl: Adding task set 46.0 with 5 tasks
18/04/01 20:15:21 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 149, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:21 INFO TaskSetManager: Starting task 1.0 in stage 46.0 (TID 150, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:21 INFO Executor: Running task 0.0 in stage 46.0 (TID 149)
18/04/01 20:15:21 INFO Executor: Running task 1.0 in stage 46.0 (TID 150)
18/04/01 20:15:21 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:21 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:21 INFO Executor: Finished task 1.0 in stage 46.0 (TID 150). 938 bytes result sent to driver
18/04/01 20:15:21 INFO TaskSetManager: Starting task 2.0 in stage 46.0 (TID 151, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:21 INFO Executor: Running task 2.0 in stage 46.0 (TID 151)
18/04/01 20:15:21 INFO TaskSetManager: Finished task 1.0 in stage 46.0 (TID 150) in 15 ms on localhost (executor driver) (1/5)
18/04/01 20:15:21 INFO Executor: Finished task 0.0 in stage 46.0 (TID 149). 981 bytes result sent to driver
18/04/01 20:15:21 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:21 INFO TaskSetManager: Starting task 3.0 in stage 46.0 (TID 152, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:21 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 149) in 22 ms on localhost (executor driver) (2/5)
18/04/01 20:15:21 INFO Executor: Running task 3.0 in stage 46.0 (TID 152)
18/04/01 20:15:21 INFO Executor: Finished task 2.0 in stage 46.0 (TID 151). 981 bytes result sent to driver
18/04/01 20:15:21 INFO TaskSetManager: Starting task 4.0 in stage 46.0 (TID 153, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:21 INFO TaskSetManager: Finished task 2.0 in stage 46.0 (TID 151) in 11 ms on localhost (executor driver) (3/5)
18/04/01 20:15:21 INFO Executor: Running task 4.0 in stage 46.0 (TID 153)
18/04/01 20:15:21 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 709 -> 711
18/04/01 20:15:21 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:21 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 709
18/04/01 20:15:21 INFO Executor: Finished task 3.0 in stage 46.0 (TID 152). 938 bytes result sent to driver
18/04/01 20:15:21 INFO TaskSetManager: Finished task 3.0 in stage 46.0 (TID 152) in 19 ms on localhost (executor driver) (4/5)
18/04/01 20:15:21 INFO Executor: Finished task 4.0 in stage 46.0 (TID 153). 1024 bytes result sent to driver
18/04/01 20:15:21 INFO TaskSetManager: Finished task 4.0 in stage 46.0 (TID 153) in 366 ms on localhost (executor driver) (5/5)
18/04/01 20:15:21 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
18/04/01 20:15:21 INFO DAGScheduler: ShuffleMapStage 46 (map at RefereeStats.scala:39) finished in 0.404 s
18/04/01 20:15:21 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:21 INFO DAGScheduler: running: Set()
18/04/01 20:15:21 INFO DAGScheduler: waiting: Set(ResultStage 47)
18/04/01 20:15:21 INFO DAGScheduler: failed: Set()
18/04/01 20:15:21 INFO DAGScheduler: Submitting ResultStage 47 (ShuffledRDD[41] at reduceByKey at RefereeStats.scala:43), which has no missing parents
18/04/01 20:15:21 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:15:21 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 1704.0 B, free 477.2 MB)
18/04/01 20:15:21 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 192.168.1.3:35449 (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:15:21 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:21 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 47 (ShuffledRDD[41] at reduceByKey at RefereeStats.scala:43) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:21 INFO TaskSchedulerImpl: Adding task set 47.0 with 2 tasks
18/04/01 20:15:21 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 154, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:15:21 INFO TaskSetManager: Starting task 1.0 in stage 47.0 (TID 155, localhost, executor driver, partition 1, ANY, 7649 bytes)
18/04/01 20:15:21 INFO Executor: Running task 1.0 in stage 47.0 (TID 155)
18/04/01 20:15:21 INFO Executor: Running task 0.0 in stage 47.0 (TID 154)
18/04/01 20:15:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:15:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:21 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:15:21 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:21 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:21 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:21 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:21 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:21 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:21 INFO KafkaProducer: [Producer clientId=producer-35] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:21 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:21 INFO KafkaProducer: [Producer clientId=producer-36] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:21 INFO Executor: Finished task 1.0 in stage 47.0 (TID 155). 1138 bytes result sent to driver
18/04/01 20:15:21 INFO TaskSetManager: Finished task 1.0 in stage 47.0 (TID 155) in 52 ms on localhost (executor driver) (1/2)
18/04/01 20:15:21 INFO Executor: Finished task 0.0 in stage 47.0 (TID 154). 1138 bytes result sent to driver
18/04/01 20:15:21 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 154) in 67 ms on localhost (executor driver) (2/2)
18/04/01 20:15:21 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
18/04/01 20:15:21 INFO DAGScheduler: ResultStage 47 (foreachPartition at RefereeStats.scala:106) finished in 0.078 s
18/04/01 20:15:21 INFO DAGScheduler: Job 29 finished: foreachPartition at RefereeStats.scala:106, took 0.495133 s
18/04/01 20:15:21 INFO JobScheduler: Finished job streaming job 1522602920000 ms.3 from job set of time 1522602920000 ms
18/04/01 20:15:21 INFO JobScheduler: Total delay: 1.769 s for time 1522602920000 ms (execution: 1.731 s)
18/04/01 20:15:21 INFO MapPartitionsRDD: Removing RDD 29 from persistence list
18/04/01 20:15:21 INFO BlockManager: Removing RDD 29
18/04/01 20:15:21 INFO KafkaRDD: Removing RDD 28 from persistence list
18/04/01 20:15:21 INFO BlockManager: Removing RDD 28
18/04/01 20:15:21 INFO ShuffledRDD: Removing RDD 30 from persistence list
18/04/01 20:15:21 INFO BlockManager: Removing RDD 30
18/04/01 20:15:21 INFO ShuffledRDD: Removing RDD 32 from persistence list
18/04/01 20:15:21 INFO BlockManager: Removing RDD 32
18/04/01 20:15:21 INFO MapPartitionsRDD: Removing RDD 31 from persistence list
18/04/01 20:15:21 INFO BlockManager: Removing RDD 31
18/04/01 20:15:21 INFO ShuffledRDD: Removing RDD 34 from persistence list
18/04/01 20:15:21 INFO BlockManager: Removing RDD 34
18/04/01 20:15:21 INFO MapPartitionsRDD: Removing RDD 33 from persistence list
18/04/01 20:15:21 INFO BlockManager: Removing RDD 33
18/04/01 20:15:21 INFO JobGenerator: Checkpointing graph for time 1522602920000 ms
18/04/01 20:15:21 INFO DStreamGraph: Updating checkpoint data for time 1522602920000 ms
18/04/01 20:15:21 INFO DStreamGraph: Updated checkpoint data for time 1522602920000 ms
18/04/01 20:15:21 INFO CheckpointWriter: Submitted checkpoint of time 1522602920000 ms to writer queue
18/04/01 20:15:21 INFO CheckpointWriter: Saving checkpoint for time 1522602920000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602920000'
18/04/01 20:15:21 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602895000
18/04/01 20:15:21 INFO CheckpointWriter: Checkpoint for time 1522602920000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602920000', took 5536 bytes and 22 ms
18/04/01 20:15:21 INFO DStreamGraph: Clearing checkpoint data for time 1522602920000 ms
18/04/01 20:15:21 INFO DStreamGraph: Cleared checkpoint data for time 1522602920000 ms
18/04/01 20:15:21 INFO ReceivedBlockTracker: Deleting batches: 
18/04/01 20:15:21 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/tmp/refs-xyzabb/receivedBlockMetadata older than 1522602915000: 
18/04/01 20:15:21 INFO InputInfoTracker: remove old batch metadata: 1522602910000 ms
18/04/01 20:15:25 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-0 to offset 712.
18/04/01 20:15:25 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-3 to offset 0.
18/04/01 20:15:25 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-4 to offset 0.
18/04/01 20:15:25 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-1 to offset 0.
18/04/01 20:15:25 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-2 to offset 0.
18/04/01 20:15:25 INFO JobScheduler: Added jobs for time 1522602925000 ms
18/04/01 20:15:25 INFO JobScheduler: Starting job streaming job 1522602925000 ms.0 from job set of time 1522602925000 ms
18/04/01 20:15:25 INFO JobGenerator: Checkpointing graph for time 1522602925000 ms
18/04/01 20:15:25 INFO DStreamGraph: Updating checkpoint data for time 1522602925000 ms
18/04/01 20:15:25 INFO DStreamGraph: Updated checkpoint data for time 1522602925000 ms
18/04/01 20:15:25 INFO CheckpointWriter: Submitted checkpoint of time 1522602925000 ms to writer queue
18/04/01 20:15:25 INFO CheckpointWriter: Saving checkpoint for time 1522602925000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602925000'
18/04/01 20:15:25 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:15:25 INFO DAGScheduler: Got job 30 (print at RefereeStats.scala:67) with 1 output partitions
18/04/01 20:15:25 INFO DAGScheduler: Final stage: ResultStage 48 (print at RefereeStats.scala:67)
18/04/01 20:15:25 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:15:25 INFO DAGScheduler: Missing parents: List()
18/04/01 20:15:25 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[43] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:25 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 3.0 KB, free 477.2 MB)
18/04/01 20:15:25 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602900000.bk
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1101
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1036
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1187
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1028
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1017
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1088
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1120
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1068
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1071
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 900
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1161
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1004
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1144
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1040
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 934
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 945
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1145
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1176
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1046
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 937
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 989
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 927
18/04/01 20:15:25 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:25 INFO CheckpointWriter: Checkpoint for time 1522602925000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602925000', took 5587 bytes and 38 ms
18/04/01 20:15:25 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.2 MB)
18/04/01 20:15:25 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1064
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 949
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1160
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1007
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1014
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1037
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1181
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1178
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1177
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1153
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1188
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 902
18/04/01 20:15:25 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1098
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1117
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1065
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1168
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1010
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1105
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 965
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1198
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1056
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1096
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1169
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 910
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1061
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1086
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1121
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 930
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1067
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1034
18/04/01 20:15:25 INFO ContextCleaner: Cleaned shuffle 13
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 933
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 944
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1052
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1154
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 936
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 954
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1135
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1079
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 962
18/04/01 20:15:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[43] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0))
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1122
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1149
18/04/01 20:15:25 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1057
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1124
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 918
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 968
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1108
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1197
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 943
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 971
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 901
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 907
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 979
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1134
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 917
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1093
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 991
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1051
18/04/01 20:15:25 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 156, localhost, executor driver, partition 0, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:25 INFO Executor: Running task 0.0 in stage 48.0 (TID 156)
18/04/01 20:15:25 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:25 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 192.168.1.3:35449 in memory (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:15:25 INFO Executor: Finished task 0.0 in stage 48.0 (TID 156). 704 bytes result sent to driver
18/04/01 20:15:25 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 156) in 8 ms on localhost (executor driver) (1/1)
18/04/01 20:15:25 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
18/04/01 20:15:25 INFO DAGScheduler: ResultStage 48 (print at RefereeStats.scala:67) finished in 0.036 s
18/04/01 20:15:25 INFO DAGScheduler: Job 30 finished: print at RefereeStats.scala:67, took 0.041147 s
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 928
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1146
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 920
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 923
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 926
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1157
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 970
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1148
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1033
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1147
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1030
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 973
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1140
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1166
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1066
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1167
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1112
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1041
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1193
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1074
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1000
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 955
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1076
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1087
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 990
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1159
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1006
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 974
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1031
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1152
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1173
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1055
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1150
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 950
18/04/01 20:15:25 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 192.168.1.3:35449 in memory (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 964
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 951
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1081
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 904
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1199
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 908
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1059
18/04/01 20:15:25 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1029
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1114
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1142
18/04/01 20:15:25 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 192.168.1.3:35449 in memory (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1151
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1118
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 967
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1058
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1070
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1130
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1103
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1012
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 912
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 947
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1180
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 938
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1091
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1172
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1020
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1016
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 919
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1078
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1094
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 953
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1039
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1136
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 986
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 921
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1003
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1138
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1025
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1126
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1080
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1186
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1137
18/04/01 20:15:25 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1129
18/04/01 20:15:25 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 946
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 963
18/04/01 20:15:25 INFO DAGScheduler: Got job 31 (print at RefereeStats.scala:67) with 4 output partitions
18/04/01 20:15:25 INFO DAGScheduler: Final stage: ResultStage 49 (print at RefereeStats.scala:67)
18/04/01 20:15:25 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:15:25 INFO DAGScheduler: Missing parents: List()
18/04/01 20:15:25 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[43] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:25 INFO ContextCleaner: Cleaned shuffle 14
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1190
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1073
18/04/01 20:15:25 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1156
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1127
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1164
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 999
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1053
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 988
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1196
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1125
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1072
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 981
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1179
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1085
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1102
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 980
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 969
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1043
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 997
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1174
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1013
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1182
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1116
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 948
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1090
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 978
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1060
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 914
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 931
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 992
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1032
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1163
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1084
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 935
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1119
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1047
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 961
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 984
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 994
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1092
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1045
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1049
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1077
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1005
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1022
18/04/01 20:15:25 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 3.0 KB, free 477.2 MB)
18/04/01 20:15:25 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.2 MB)
18/04/01 20:15:25 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 192.168.1.3:35449 in memory (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 987
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1194
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1050
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1189
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 998
18/04/01 20:15:25 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:25 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 192.168.1.3:35449 in memory (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 911
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 909
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1099
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1141
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1132
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1062
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 977
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 959
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 932
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 913
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1008
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1063
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1131
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 942
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 924
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 966
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1023
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1035
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1075
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 982
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1139
18/04/01 20:15:25 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:25 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:25 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 49 (MapPartitionsRDD[43] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
18/04/01 20:15:25 INFO TaskSchedulerImpl: Adding task set 49.0 with 4 tasks
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1133
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1026
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 906
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1162
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 985
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1100
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1175
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 925
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1191
18/04/01 20:15:25 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 957
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1069
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1089
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 922
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 940
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 941
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 916
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 983
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1113
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1143
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1192
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1115
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1155
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1111
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 976
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 972
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1183
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1024
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 939
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1019
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1123
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1184
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1048
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1195
18/04/01 20:15:25 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 192.168.1.3:35449 in memory (size: 1703.0 B, free: 477.3 MB)
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 929
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1107
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1095
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1002
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1038
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1110
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1170
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 903
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 975
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1083
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 996
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1001
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 952
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1042
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 960
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 958
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1027
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1104
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1128
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1018
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1044
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1165
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1021
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 995
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 956
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 993
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1171
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1011
18/04/01 20:15:25 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:25 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 157, localhost, executor driver, partition 1, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:25 INFO TaskSetManager: Starting task 1.0 in stage 49.0 (TID 158, localhost, executor driver, partition 2, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:25 INFO Executor: Running task 0.0 in stage 49.0 (TID 157)
18/04/01 20:15:25 INFO Executor: Running task 1.0 in stage 49.0 (TID 158)
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1185
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1109
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1106
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 905
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1082
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 915
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1015
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1054
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1158
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1097
18/04/01 20:15:25 INFO ContextCleaner: Cleaned accumulator 1009
18/04/01 20:15:25 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:25 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:25 INFO Executor: Finished task 1.0 in stage 49.0 (TID 158). 704 bytes result sent to driver
18/04/01 20:15:25 INFO TaskSetManager: Starting task 2.0 in stage 49.0 (TID 159, localhost, executor driver, partition 3, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:25 INFO TaskSetManager: Finished task 1.0 in stage 49.0 (TID 158) in 9 ms on localhost (executor driver) (1/4)
18/04/01 20:15:25 INFO Executor: Finished task 0.0 in stage 49.0 (TID 157). 661 bytes result sent to driver
18/04/01 20:15:25 INFO Executor: Running task 2.0 in stage 49.0 (TID 159)
18/04/01 20:15:25 INFO TaskSetManager: Starting task 3.0 in stage 49.0 (TID 160, localhost, executor driver, partition 4, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:25 INFO Executor: Running task 3.0 in stage 49.0 (TID 160)
18/04/01 20:15:25 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 157) in 11 ms on localhost (executor driver) (2/4)
18/04/01 20:15:25 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 711 -> 712
18/04/01 20:15:25 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:25 INFO Executor: Finished task 2.0 in stage 49.0 (TID 159). 704 bytes result sent to driver
18/04/01 20:15:25 INFO Executor: Finished task 3.0 in stage 49.0 (TID 160). 861 bytes result sent to driver
18/04/01 20:15:25 INFO TaskSetManager: Finished task 2.0 in stage 49.0 (TID 159) in 12 ms on localhost (executor driver) (3/4)
18/04/01 20:15:25 INFO TaskSetManager: Finished task 3.0 in stage 49.0 (TID 160) in 12 ms on localhost (executor driver) (4/4)
18/04/01 20:15:25 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
18/04/01 20:15:25 INFO DAGScheduler: ResultStage 49 (print at RefereeStats.scala:67) finished in 0.063 s
18/04/01 20:15:25 INFO DAGScheduler: Job 31 finished: print at RefereeStats.scala:67, took 0.076587 s
18/04/01 20:15:25 INFO JobScheduler: Finished job streaming job 1522602925000 ms.0 from job set of time 1522602925000 ms
18/04/01 20:15:25 INFO JobScheduler: Starting job streaming job 1522602925000 ms.1 from job set of time 1522602925000 ms
-------------------------------------------
Time: 1522602925000 ms
-------------------------------------------
(instagram.*,0)

18/04/01 20:15:25 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:71
18/04/01 20:15:25 INFO DAGScheduler: Registering RDD 43 (map at RefereeStats.scala:53)
18/04/01 20:15:25 INFO DAGScheduler: Got job 32 (foreachPartition at RefereeStats.scala:71) with 2 output partitions
18/04/01 20:15:25 INFO DAGScheduler: Final stage: ResultStage 51 (foreachPartition at RefereeStats.scala:71)
18/04/01 20:15:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 50)
18/04/01 20:15:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 50)
18/04/01 20:15:25 INFO DAGScheduler: Submitting ShuffleMapStage 50 (MapPartitionsRDD[43] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:25 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 3.9 KB, free 477.3 MB)
18/04/01 20:15:25 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.3 MB)
18/04/01 20:15:25 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:25 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:25 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[43] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:25 INFO TaskSchedulerImpl: Adding task set 50.0 with 5 tasks
18/04/01 20:15:25 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 161, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:25 INFO TaskSetManager: Starting task 1.0 in stage 50.0 (TID 162, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:25 INFO Executor: Running task 1.0 in stage 50.0 (TID 162)
18/04/01 20:15:25 INFO Executor: Running task 0.0 in stage 50.0 (TID 161)
18/04/01 20:15:25 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:25 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:25 INFO Executor: Finished task 1.0 in stage 50.0 (TID 162). 938 bytes result sent to driver
18/04/01 20:15:25 INFO Executor: Finished task 0.0 in stage 50.0 (TID 161). 938 bytes result sent to driver
18/04/01 20:15:25 INFO TaskSetManager: Starting task 2.0 in stage 50.0 (TID 163, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:25 INFO Executor: Running task 2.0 in stage 50.0 (TID 163)
18/04/01 20:15:25 INFO TaskSetManager: Finished task 1.0 in stage 50.0 (TID 162) in 9 ms on localhost (executor driver) (1/5)
18/04/01 20:15:25 INFO TaskSetManager: Starting task 3.0 in stage 50.0 (TID 164, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:25 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 161) in 10 ms on localhost (executor driver) (2/5)
18/04/01 20:15:25 INFO Executor: Running task 3.0 in stage 50.0 (TID 164)
18/04/01 20:15:25 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:25 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:25 INFO Executor: Finished task 3.0 in stage 50.0 (TID 164). 938 bytes result sent to driver
18/04/01 20:15:25 INFO TaskSetManager: Starting task 4.0 in stage 50.0 (TID 165, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:25 INFO TaskSetManager: Finished task 3.0 in stage 50.0 (TID 164) in 8 ms on localhost (executor driver) (3/5)
18/04/01 20:15:25 INFO Executor: Running task 4.0 in stage 50.0 (TID 165)
18/04/01 20:15:25 INFO Executor: Finished task 2.0 in stage 50.0 (TID 163). 938 bytes result sent to driver
18/04/01 20:15:25 INFO TaskSetManager: Finished task 2.0 in stage 50.0 (TID 163) in 12 ms on localhost (executor driver) (4/5)
18/04/01 20:15:25 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 711 -> 712
18/04/01 20:15:25 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 711
18/04/01 20:15:25 INFO Executor: Finished task 4.0 in stage 50.0 (TID 165). 1024 bytes result sent to driver
18/04/01 20:15:25 INFO TaskSetManager: Finished task 4.0 in stage 50.0 (TID 165) in 385 ms on localhost (executor driver) (5/5)
18/04/01 20:15:25 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
18/04/01 20:15:25 INFO DAGScheduler: ShuffleMapStage 50 (map at RefereeStats.scala:53) finished in 0.414 s
18/04/01 20:15:25 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:25 INFO DAGScheduler: running: Set()
18/04/01 20:15:25 INFO DAGScheduler: waiting: Set(ResultStage 51)
18/04/01 20:15:25 INFO DAGScheduler: failed: Set()
18/04/01 20:15:25 INFO DAGScheduler: Submitting ResultStage 51 (ShuffledRDD[44] at reduceByKey at RefereeStats.scala:60), which has no missing parents
18/04/01 20:15:25 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 2.8 KB, free 477.3 MB)
18/04/01 20:15:25 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 1706.0 B, free 477.3 MB)
18/04/01 20:15:25 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 192.168.1.3:35449 (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:15:25 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:25 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 51 (ShuffledRDD[44] at reduceByKey at RefereeStats.scala:60) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:25 INFO TaskSchedulerImpl: Adding task set 51.0 with 2 tasks
18/04/01 20:15:25 INFO TaskSetManager: Starting task 1.0 in stage 51.0 (TID 166, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:15:25 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 167, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:15:25 INFO Executor: Running task 0.0 in stage 51.0 (TID 167)
18/04/01 20:15:25 INFO Executor: Running task 1.0 in stage 51.0 (TID 166)
18/04/01 20:15:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:25 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:25 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:15:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:15:25 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:25 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:25 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:25 INFO KafkaProducer: [Producer clientId=producer-38] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:25 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:25 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:25 INFO Executor: Finished task 1.0 in stage 51.0 (TID 166). 1138 bytes result sent to driver
18/04/01 20:15:25 INFO TaskSetManager: Finished task 1.0 in stage 51.0 (TID 166) in 44 ms on localhost (executor driver) (1/2)
18/04/01 20:15:25 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:25 INFO KafkaProducer: [Producer clientId=producer-37] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:25 INFO Executor: Finished task 0.0 in stage 51.0 (TID 167). 1138 bytes result sent to driver
18/04/01 20:15:25 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 167) in 86 ms on localhost (executor driver) (2/2)
18/04/01 20:15:25 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
18/04/01 20:15:25 INFO DAGScheduler: ResultStage 51 (foreachPartition at RefereeStats.scala:71) finished in 0.108 s
18/04/01 20:15:25 INFO DAGScheduler: Job 32 finished: foreachPartition at RefereeStats.scala:71, took 0.535400 s
18/04/01 20:15:25 INFO JobScheduler: Finished job streaming job 1522602925000 ms.1 from job set of time 1522602925000 ms
18/04/01 20:15:25 INFO JobScheduler: Starting job streaming job 1522602925000 ms.2 from job set of time 1522602925000 ms
18/04/01 20:15:25 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:89
18/04/01 20:15:25 INFO DAGScheduler: Registering RDD 45 (map at RefereeStats.scala:46)
18/04/01 20:15:25 INFO DAGScheduler: Got job 33 (foreachPartition at RefereeStats.scala:89) with 2 output partitions
18/04/01 20:15:25 INFO DAGScheduler: Final stage: ResultStage 53 (foreachPartition at RefereeStats.scala:89)
18/04/01 20:15:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)
18/04/01 20:15:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 52)
18/04/01 20:15:25 INFO DAGScheduler: Submitting ShuffleMapStage 52 (MapPartitionsRDD[45] at map at RefereeStats.scala:46), which has no missing parents
18/04/01 20:15:25 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 3.9 KB, free 477.3 MB)
18/04/01 20:15:25 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.3 MB)
18/04/01 20:15:25 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:25 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:25 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 52 (MapPartitionsRDD[45] at map at RefereeStats.scala:46) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:25 INFO TaskSchedulerImpl: Adding task set 52.0 with 5 tasks
18/04/01 20:15:25 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 168, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:25 INFO TaskSetManager: Starting task 1.0 in stage 52.0 (TID 169, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:25 INFO Executor: Running task 0.0 in stage 52.0 (TID 168)
18/04/01 20:15:25 INFO Executor: Running task 1.0 in stage 52.0 (TID 169)
18/04/01 20:15:25 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:25 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:25 INFO Executor: Finished task 0.0 in stage 52.0 (TID 168). 938 bytes result sent to driver
18/04/01 20:15:25 INFO TaskSetManager: Starting task 2.0 in stage 52.0 (TID 170, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:25 INFO Executor: Running task 2.0 in stage 52.0 (TID 170)
18/04/01 20:15:25 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 168) in 11 ms on localhost (executor driver) (1/5)
18/04/01 20:15:25 INFO Executor: Finished task 1.0 in stage 52.0 (TID 169). 938 bytes result sent to driver
18/04/01 20:15:25 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:25 INFO TaskSetManager: Starting task 3.0 in stage 52.0 (TID 171, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:25 INFO Executor: Running task 3.0 in stage 52.0 (TID 171)
18/04/01 20:15:25 INFO TaskSetManager: Finished task 1.0 in stage 52.0 (TID 169) in 16 ms on localhost (executor driver) (2/5)
18/04/01 20:15:25 INFO Executor: Finished task 2.0 in stage 52.0 (TID 170). 938 bytes result sent to driver
18/04/01 20:15:25 INFO TaskSetManager: Starting task 4.0 in stage 52.0 (TID 172, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:25 INFO Executor: Running task 4.0 in stage 52.0 (TID 172)
18/04/01 20:15:25 INFO TaskSetManager: Finished task 2.0 in stage 52.0 (TID 170) in 11 ms on localhost (executor driver) (3/5)
18/04/01 20:15:25 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:25 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 711 -> 712
18/04/01 20:15:25 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 711
18/04/01 20:15:25 INFO Executor: Finished task 3.0 in stage 52.0 (TID 171). 981 bytes result sent to driver
18/04/01 20:15:25 INFO TaskSetManager: Finished task 3.0 in stage 52.0 (TID 171) in 23 ms on localhost (executor driver) (4/5)
18/04/01 20:15:26 INFO Executor: Finished task 4.0 in stage 52.0 (TID 172). 1024 bytes result sent to driver
18/04/01 20:15:26 INFO TaskSetManager: Finished task 4.0 in stage 52.0 (TID 172) in 307 ms on localhost (executor driver) (5/5)
18/04/01 20:15:26 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
18/04/01 20:15:26 INFO DAGScheduler: ShuffleMapStage 52 (map at RefereeStats.scala:46) finished in 0.354 s
18/04/01 20:15:26 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:26 INFO DAGScheduler: running: Set()
18/04/01 20:15:26 INFO DAGScheduler: waiting: Set(ResultStage 53)
18/04/01 20:15:26 INFO DAGScheduler: failed: Set()
18/04/01 20:15:26 INFO DAGScheduler: Submitting ResultStage 53 (ShuffledRDD[46] at reduceByKey at RefereeStats.scala:51), which has no missing parents
18/04/01 20:15:26 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:15:26 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 1709.0 B, free 477.2 MB)
18/04/01 20:15:26 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 192.168.1.3:35449 (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:15:26 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 53 (ShuffledRDD[46] at reduceByKey at RefereeStats.scala:51) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:26 INFO TaskSchedulerImpl: Adding task set 53.0 with 2 tasks
18/04/01 20:15:26 INFO TaskSetManager: Starting task 1.0 in stage 53.0 (TID 173, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:15:26 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 174, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:15:26 INFO Executor: Running task 0.0 in stage 53.0 (TID 174)
18/04/01 20:15:26 INFO Executor: Running task 1.0 in stage 53.0 (TID 173)
18/04/01 20:15:26 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:15:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:15:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:15:26 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:26 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:26 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:26 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:26 INFO KafkaProducer: [Producer clientId=producer-39] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:26 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:26 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:26 INFO Executor: Finished task 1.0 in stage 53.0 (TID 173). 1138 bytes result sent to driver
18/04/01 20:15:26 INFO TaskSetManager: Finished task 1.0 in stage 53.0 (TID 173) in 32 ms on localhost (executor driver) (1/2)
18/04/01 20:15:26 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:26 INFO KafkaProducer: [Producer clientId=producer-40] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:26 INFO Executor: Finished task 0.0 in stage 53.0 (TID 174). 1138 bytes result sent to driver
18/04/01 20:15:26 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 174) in 51 ms on localhost (executor driver) (2/2)
18/04/01 20:15:26 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
18/04/01 20:15:26 INFO DAGScheduler: ResultStage 53 (foreachPartition at RefereeStats.scala:89) finished in 0.062 s
18/04/01 20:15:26 INFO DAGScheduler: Job 33 finished: foreachPartition at RefereeStats.scala:89, took 0.428809 s
18/04/01 20:15:26 INFO JobScheduler: Finished job streaming job 1522602925000 ms.2 from job set of time 1522602925000 ms
18/04/01 20:15:26 INFO JobScheduler: Starting job streaming job 1522602925000 ms.3 from job set of time 1522602925000 ms
18/04/01 20:15:26 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:106
18/04/01 20:15:26 INFO DAGScheduler: Registering RDD 47 (map at RefereeStats.scala:39)
18/04/01 20:15:26 INFO DAGScheduler: Got job 34 (foreachPartition at RefereeStats.scala:106) with 2 output partitions
18/04/01 20:15:26 INFO DAGScheduler: Final stage: ResultStage 55 (foreachPartition at RefereeStats.scala:106)
18/04/01 20:15:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 54)
18/04/01 20:15:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 54)
18/04/01 20:15:26 INFO DAGScheduler: Submitting ShuffleMapStage 54 (MapPartitionsRDD[47] at map at RefereeStats.scala:39), which has no missing parents
18/04/01 20:15:26 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:15:26 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:15:26 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:26 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:26 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[47] at map at RefereeStats.scala:39) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:26 INFO TaskSchedulerImpl: Adding task set 54.0 with 5 tasks
18/04/01 20:15:26 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 175, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:26 INFO TaskSetManager: Starting task 1.0 in stage 54.0 (TID 176, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:26 INFO Executor: Running task 0.0 in stage 54.0 (TID 175)
18/04/01 20:15:26 INFO Executor: Running task 1.0 in stage 54.0 (TID 176)
18/04/01 20:15:26 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:26 INFO Executor: Finished task 1.0 in stage 54.0 (TID 176). 938 bytes result sent to driver
18/04/01 20:15:26 INFO TaskSetManager: Starting task 2.0 in stage 54.0 (TID 177, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:26 INFO TaskSetManager: Finished task 1.0 in stage 54.0 (TID 176) in 26 ms on localhost (executor driver) (1/5)
18/04/01 20:15:26 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:26 INFO Executor: Finished task 0.0 in stage 54.0 (TID 175). 938 bytes result sent to driver
18/04/01 20:15:26 INFO Executor: Running task 2.0 in stage 54.0 (TID 177)
18/04/01 20:15:26 INFO TaskSetManager: Starting task 3.0 in stage 54.0 (TID 178, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:26 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 175) in 32 ms on localhost (executor driver) (2/5)
18/04/01 20:15:26 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:26 INFO Executor: Running task 3.0 in stage 54.0 (TID 178)
18/04/01 20:15:26 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:26 INFO Executor: Finished task 2.0 in stage 54.0 (TID 177). 938 bytes result sent to driver
18/04/01 20:15:26 INFO Executor: Finished task 3.0 in stage 54.0 (TID 178). 938 bytes result sent to driver
18/04/01 20:15:26 INFO TaskSetManager: Starting task 4.0 in stage 54.0 (TID 179, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:26 INFO Executor: Running task 4.0 in stage 54.0 (TID 179)
18/04/01 20:15:26 INFO TaskSetManager: Finished task 2.0 in stage 54.0 (TID 177) in 25 ms on localhost (executor driver) (3/5)
18/04/01 20:15:26 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 711 -> 712
18/04/01 20:15:26 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 711
18/04/01 20:15:26 INFO TaskSetManager: Finished task 3.0 in stage 54.0 (TID 178) in 29 ms on localhost (executor driver) (4/5)
18/04/01 20:15:26 INFO Executor: Finished task 4.0 in stage 54.0 (TID 179). 1067 bytes result sent to driver
18/04/01 20:15:26 INFO TaskSetManager: Finished task 4.0 in stage 54.0 (TID 179) in 355 ms on localhost (executor driver) (5/5)
18/04/01 20:15:26 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
18/04/01 20:15:26 INFO DAGScheduler: ShuffleMapStage 54 (map at RefereeStats.scala:39) finished in 0.413 s
18/04/01 20:15:26 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:26 INFO DAGScheduler: running: Set()
18/04/01 20:15:26 INFO DAGScheduler: waiting: Set(ResultStage 55)
18/04/01 20:15:26 INFO DAGScheduler: failed: Set()
18/04/01 20:15:26 INFO DAGScheduler: Submitting ResultStage 55 (ShuffledRDD[48] at reduceByKey at RefereeStats.scala:43), which has no missing parents
18/04/01 20:15:26 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:15:26 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 1704.0 B, free 477.2 MB)
18/04/01 20:15:26 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 192.168.1.3:35449 (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:15:26 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 55 (ShuffledRDD[48] at reduceByKey at RefereeStats.scala:43) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:26 INFO TaskSchedulerImpl: Adding task set 55.0 with 2 tasks
18/04/01 20:15:26 INFO TaskSetManager: Starting task 1.0 in stage 55.0 (TID 180, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:15:26 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 181, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:15:26 INFO Executor: Running task 0.0 in stage 55.0 (TID 181)
18/04/01 20:15:26 INFO Executor: Running task 1.0 in stage 55.0 (TID 180)
18/04/01 20:15:26 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:15:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:26 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
18/04/01 20:15:26 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:26 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:26 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:26 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:26 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:26 INFO KafkaProducer: [Producer clientId=producer-42] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:26 INFO Executor: Finished task 1.0 in stage 55.0 (TID 180). 1138 bytes result sent to driver
18/04/01 20:15:26 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:26 INFO TaskSetManager: Finished task 1.0 in stage 55.0 (TID 180) in 45 ms on localhost (executor driver) (1/2)
18/04/01 20:15:26 INFO KafkaProducer: [Producer clientId=producer-41] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:26 INFO Executor: Finished task 0.0 in stage 55.0 (TID 181). 1138 bytes result sent to driver
18/04/01 20:15:26 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 181) in 66 ms on localhost (executor driver) (2/2)
18/04/01 20:15:26 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
18/04/01 20:15:26 INFO DAGScheduler: ResultStage 55 (foreachPartition at RefereeStats.scala:106) finished in 0.081 s
18/04/01 20:15:26 INFO DAGScheduler: Job 34 finished: foreachPartition at RefereeStats.scala:106, took 0.510181 s
18/04/01 20:15:26 INFO JobScheduler: Finished job streaming job 1522602925000 ms.3 from job set of time 1522602925000 ms
18/04/01 20:15:26 INFO JobScheduler: Total delay: 1.727 s for time 1522602925000 ms (execution: 1.693 s)
18/04/01 20:15:26 INFO MapPartitionsRDD: Removing RDD 36 from persistence list
18/04/01 20:15:26 INFO BlockManager: Removing RDD 36
18/04/01 20:15:26 INFO KafkaRDD: Removing RDD 35 from persistence list
18/04/01 20:15:26 INFO BlockManager: Removing RDD 35
18/04/01 20:15:26 INFO ShuffledRDD: Removing RDD 37 from persistence list
18/04/01 20:15:26 INFO BlockManager: Removing RDD 37
18/04/01 20:15:26 INFO ShuffledRDD: Removing RDD 39 from persistence list
18/04/01 20:15:26 INFO BlockManager: Removing RDD 39
18/04/01 20:15:26 INFO MapPartitionsRDD: Removing RDD 38 from persistence list
18/04/01 20:15:26 INFO BlockManager: Removing RDD 38
18/04/01 20:15:26 INFO ShuffledRDD: Removing RDD 41 from persistence list
18/04/01 20:15:26 INFO BlockManager: Removing RDD 41
18/04/01 20:15:26 INFO MapPartitionsRDD: Removing RDD 40 from persistence list
18/04/01 20:15:26 INFO BlockManager: Removing RDD 40
18/04/01 20:15:26 INFO JobGenerator: Checkpointing graph for time 1522602925000 ms
18/04/01 20:15:26 INFO DStreamGraph: Updating checkpoint data for time 1522602925000 ms
18/04/01 20:15:26 INFO DStreamGraph: Updated checkpoint data for time 1522602925000 ms
18/04/01 20:15:26 INFO CheckpointWriter: Saving checkpoint for time 1522602925000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602925000'
18/04/01 20:15:26 INFO CheckpointWriter: Submitted checkpoint of time 1522602925000 ms to writer queue
18/04/01 20:15:26 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602900000
18/04/01 20:15:26 INFO CheckpointWriter: Checkpoint for time 1522602925000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602925000', took 5536 bytes and 33 ms
18/04/01 20:15:26 INFO DStreamGraph: Clearing checkpoint data for time 1522602925000 ms
18/04/01 20:15:26 INFO DStreamGraph: Cleared checkpoint data for time 1522602925000 ms
18/04/01 20:15:26 INFO ReceivedBlockTracker: Deleting batches: 
18/04/01 20:15:26 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/tmp/refs-xyzabb/receivedBlockMetadata older than 1522602920000: 
18/04/01 20:15:26 INFO InputInfoTracker: remove old batch metadata: 1522602915000 ms
18/04/01 20:15:30 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-0 to offset 714.
18/04/01 20:15:30 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-3 to offset 0.
18/04/01 20:15:30 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-4 to offset 0.
18/04/01 20:15:30 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-1 to offset 0.
18/04/01 20:15:30 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-2 to offset 0.
18/04/01 20:15:30 INFO JobScheduler: Starting job streaming job 1522602930000 ms.0 from job set of time 1522602930000 ms
18/04/01 20:15:30 INFO JobScheduler: Added jobs for time 1522602930000 ms
18/04/01 20:15:30 INFO JobGenerator: Checkpointing graph for time 1522602930000 ms
18/04/01 20:15:30 INFO DStreamGraph: Updating checkpoint data for time 1522602930000 ms
18/04/01 20:15:30 INFO DStreamGraph: Updated checkpoint data for time 1522602930000 ms
18/04/01 20:15:30 INFO CheckpointWriter: Submitted checkpoint of time 1522602930000 ms to writer queue
18/04/01 20:15:30 INFO CheckpointWriter: Saving checkpoint for time 1522602930000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602930000'
18/04/01 20:15:30 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:15:30 INFO DAGScheduler: Got job 35 (print at RefereeStats.scala:67) with 1 output partitions
18/04/01 20:15:30 INFO DAGScheduler: Final stage: ResultStage 56 (print at RefereeStats.scala:67)
18/04/01 20:15:30 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:15:30 INFO DAGScheduler: Missing parents: List()
18/04/01 20:15:30 INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[50] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:30 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 3.0 KB, free 477.2 MB)
18/04/01 20:15:30 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.2 MB)
18/04/01 20:15:30 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:30 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[50] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0))
18/04/01 20:15:30 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks
18/04/01 20:15:30 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 182, localhost, executor driver, partition 0, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:30 INFO Executor: Running task 0.0 in stage 56.0 (TID 182)
18/04/01 20:15:30 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:30 INFO Executor: Finished task 0.0 in stage 56.0 (TID 182). 704 bytes result sent to driver
18/04/01 20:15:30 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 182) in 6 ms on localhost (executor driver) (1/1)
18/04/01 20:15:30 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
18/04/01 20:15:30 INFO DAGScheduler: ResultStage 56 (print at RefereeStats.scala:67) finished in 0.022 s
18/04/01 20:15:30 INFO DAGScheduler: Job 35 finished: print at RefereeStats.scala:67, took 0.027073 s
18/04/01 20:15:30 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602905000.bk
18/04/01 20:15:30 INFO CheckpointWriter: Checkpoint for time 1522602930000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602930000', took 5589 bytes and 31 ms
18/04/01 20:15:30 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:15:30 INFO DAGScheduler: Got job 36 (print at RefereeStats.scala:67) with 4 output partitions
18/04/01 20:15:30 INFO DAGScheduler: Final stage: ResultStage 57 (print at RefereeStats.scala:67)
18/04/01 20:15:30 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:15:30 INFO DAGScheduler: Missing parents: List()
18/04/01 20:15:30 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[50] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:30 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 3.0 KB, free 477.2 MB)
18/04/01 20:15:30 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.2 MB)
18/04/01 20:15:30 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:30 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:30 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 57 (MapPartitionsRDD[50] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
18/04/01 20:15:30 INFO TaskSchedulerImpl: Adding task set 57.0 with 4 tasks
18/04/01 20:15:30 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 183, localhost, executor driver, partition 1, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:30 INFO TaskSetManager: Starting task 1.0 in stage 57.0 (TID 184, localhost, executor driver, partition 2, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:30 INFO Executor: Running task 1.0 in stage 57.0 (TID 184)
18/04/01 20:15:30 INFO Executor: Running task 0.0 in stage 57.0 (TID 183)
18/04/01 20:15:30 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:30 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:30 INFO Executor: Finished task 0.0 in stage 57.0 (TID 183). 704 bytes result sent to driver
18/04/01 20:15:30 INFO Executor: Finished task 1.0 in stage 57.0 (TID 184). 704 bytes result sent to driver
18/04/01 20:15:30 INFO TaskSetManager: Starting task 2.0 in stage 57.0 (TID 185, localhost, executor driver, partition 3, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:30 INFO Executor: Running task 2.0 in stage 57.0 (TID 185)
18/04/01 20:15:30 INFO TaskSetManager: Starting task 3.0 in stage 57.0 (TID 186, localhost, executor driver, partition 4, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:30 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 183) in 9 ms on localhost (executor driver) (1/4)
18/04/01 20:15:30 INFO TaskSetManager: Finished task 1.0 in stage 57.0 (TID 184) in 8 ms on localhost (executor driver) (2/4)
18/04/01 20:15:30 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:30 INFO Executor: Running task 3.0 in stage 57.0 (TID 186)
18/04/01 20:15:30 INFO Executor: Finished task 2.0 in stage 57.0 (TID 185). 704 bytes result sent to driver
18/04/01 20:15:30 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 712 -> 714
18/04/01 20:15:30 INFO TaskSetManager: Finished task 2.0 in stage 57.0 (TID 185) in 7 ms on localhost (executor driver) (3/4)
18/04/01 20:15:30 INFO Executor: Finished task 3.0 in stage 57.0 (TID 186). 930 bytes result sent to driver
18/04/01 20:15:30 INFO TaskSetManager: Finished task 3.0 in stage 57.0 (TID 186) in 14 ms on localhost (executor driver) (4/4)
18/04/01 20:15:30 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
18/04/01 20:15:30 INFO DAGScheduler: ResultStage 57 (print at RefereeStats.scala:67) finished in 0.054 s
18/04/01 20:15:30 INFO DAGScheduler: Job 36 finished: print at RefereeStats.scala:67, took 0.059260 s
18/04/01 20:15:30 INFO JobScheduler: Finished job streaming job 1522602930000 ms.0 from job set of time 1522602930000 ms
18/04/01 20:15:30 INFO JobScheduler: Starting job streaming job 1522602930000 ms.1 from job set of time 1522602930000 ms
-------------------------------------------
Time: 1522602930000 ms
-------------------------------------------
(google.*,0)
(vk.com,6000)

18/04/01 20:15:30 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:71
18/04/01 20:15:30 INFO DAGScheduler: Registering RDD 50 (map at RefereeStats.scala:53)
18/04/01 20:15:30 INFO DAGScheduler: Got job 37 (foreachPartition at RefereeStats.scala:71) with 2 output partitions
18/04/01 20:15:30 INFO DAGScheduler: Final stage: ResultStage 59 (foreachPartition at RefereeStats.scala:71)
18/04/01 20:15:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 58)
18/04/01 20:15:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 58)
18/04/01 20:15:30 INFO DAGScheduler: Submitting ShuffleMapStage 58 (MapPartitionsRDD[50] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:30 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:15:30 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:15:30 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:30 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:30 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 58 (MapPartitionsRDD[50] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:30 INFO TaskSchedulerImpl: Adding task set 58.0 with 5 tasks
18/04/01 20:15:30 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 187, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:30 INFO TaskSetManager: Starting task 1.0 in stage 58.0 (TID 188, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:30 INFO Executor: Running task 0.0 in stage 58.0 (TID 187)
18/04/01 20:15:30 INFO Executor: Running task 1.0 in stage 58.0 (TID 188)
18/04/01 20:15:30 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:30 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:30 INFO Executor: Finished task 1.0 in stage 58.0 (TID 188). 938 bytes result sent to driver
18/04/01 20:15:30 INFO Executor: Finished task 0.0 in stage 58.0 (TID 187). 938 bytes result sent to driver
18/04/01 20:15:30 INFO TaskSetManager: Starting task 2.0 in stage 58.0 (TID 189, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:30 INFO TaskSetManager: Finished task 1.0 in stage 58.0 (TID 188) in 8 ms on localhost (executor driver) (1/5)
18/04/01 20:15:30 INFO TaskSetManager: Starting task 3.0 in stage 58.0 (TID 190, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:30 INFO Executor: Running task 3.0 in stage 58.0 (TID 190)
18/04/01 20:15:30 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 187) in 11 ms on localhost (executor driver) (2/5)
18/04/01 20:15:30 INFO Executor: Running task 2.0 in stage 58.0 (TID 189)
18/04/01 20:15:30 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:30 INFO Executor: Finished task 3.0 in stage 58.0 (TID 190). 938 bytes result sent to driver
18/04/01 20:15:30 INFO TaskSetManager: Starting task 4.0 in stage 58.0 (TID 191, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:30 INFO TaskSetManager: Finished task 3.0 in stage 58.0 (TID 190) in 16 ms on localhost (executor driver) (3/5)
18/04/01 20:15:30 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:30 INFO Executor: Running task 4.0 in stage 58.0 (TID 191)
18/04/01 20:15:30 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 712 -> 714
18/04/01 20:15:30 INFO Executor: Finished task 2.0 in stage 58.0 (TID 189). 938 bytes result sent to driver
18/04/01 20:15:30 INFO TaskSetManager: Finished task 2.0 in stage 58.0 (TID 189) in 30 ms on localhost (executor driver) (4/5)
18/04/01 20:15:30 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 712
18/04/01 20:15:30 INFO Executor: Finished task 4.0 in stage 58.0 (TID 191). 1067 bytes result sent to driver
18/04/01 20:15:30 INFO TaskSetManager: Finished task 4.0 in stage 58.0 (TID 191) in 453 ms on localhost (executor driver) (5/5)
18/04/01 20:15:30 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
18/04/01 20:15:30 INFO DAGScheduler: ShuffleMapStage 58 (map at RefereeStats.scala:53) finished in 0.493 s
18/04/01 20:15:30 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:30 INFO DAGScheduler: running: Set()
18/04/01 20:15:30 INFO DAGScheduler: waiting: Set(ResultStage 59)
18/04/01 20:15:30 INFO DAGScheduler: failed: Set()
18/04/01 20:15:30 INFO DAGScheduler: Submitting ResultStage 59 (ShuffledRDD[51] at reduceByKey at RefereeStats.scala:60), which has no missing parents
18/04/01 20:15:30 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:15:30 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 1706.0 B, free 477.2 MB)
18/04/01 20:15:30 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 192.168.1.3:35449 (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:15:30 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 59 (ShuffledRDD[51] at reduceByKey at RefereeStats.scala:60) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:30 INFO TaskSchedulerImpl: Adding task set 59.0 with 2 tasks
18/04/01 20:15:30 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 192, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:15:30 INFO TaskSetManager: Starting task 1.0 in stage 59.0 (TID 193, localhost, executor driver, partition 1, ANY, 7649 bytes)
18/04/01 20:15:30 INFO Executor: Running task 0.0 in stage 59.0 (TID 192)
18/04/01 20:15:30 INFO Executor: Running task 1.0 in stage 59.0 (TID 193)
18/04/01 20:15:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
18/04/01 20:15:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:15:30 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:30 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:30 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:30 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:30 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:30 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:30 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:30 INFO KafkaProducer: [Producer clientId=producer-44] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:30 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:30 INFO KafkaProducer: [Producer clientId=producer-43] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:30 INFO Executor: Finished task 1.0 in stage 59.0 (TID 193). 1138 bytes result sent to driver
18/04/01 20:15:30 INFO TaskSetManager: Finished task 1.0 in stage 59.0 (TID 193) in 67 ms on localhost (executor driver) (1/2)
18/04/01 20:15:30 INFO Executor: Finished task 0.0 in stage 59.0 (TID 192). 1138 bytes result sent to driver
18/04/01 20:15:30 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 192) in 77 ms on localhost (executor driver) (2/2)
18/04/01 20:15:30 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
18/04/01 20:15:30 INFO DAGScheduler: ResultStage 59 (foreachPartition at RefereeStats.scala:71) finished in 0.092 s
18/04/01 20:15:30 INFO DAGScheduler: Job 37 finished: foreachPartition at RefereeStats.scala:71, took 0.595742 s
18/04/01 20:15:30 INFO JobScheduler: Finished job streaming job 1522602930000 ms.1 from job set of time 1522602930000 ms
18/04/01 20:15:30 INFO JobScheduler: Starting job streaming job 1522602930000 ms.2 from job set of time 1522602930000 ms
18/04/01 20:15:30 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:89
18/04/01 20:15:30 INFO DAGScheduler: Registering RDD 52 (map at RefereeStats.scala:46)
18/04/01 20:15:30 INFO DAGScheduler: Got job 38 (foreachPartition at RefereeStats.scala:89) with 2 output partitions
18/04/01 20:15:30 INFO DAGScheduler: Final stage: ResultStage 61 (foreachPartition at RefereeStats.scala:89)
18/04/01 20:15:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 60)
18/04/01 20:15:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 60)
18/04/01 20:15:30 INFO DAGScheduler: Submitting ShuffleMapStage 60 (MapPartitionsRDD[52] at map at RefereeStats.scala:46), which has no missing parents
18/04/01 20:15:30 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:15:30 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:15:30 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:30 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:30 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 60 (MapPartitionsRDD[52] at map at RefereeStats.scala:46) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:30 INFO TaskSchedulerImpl: Adding task set 60.0 with 5 tasks
18/04/01 20:15:30 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 194, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:30 INFO TaskSetManager: Starting task 1.0 in stage 60.0 (TID 195, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:30 INFO Executor: Running task 0.0 in stage 60.0 (TID 194)
18/04/01 20:15:30 INFO Executor: Running task 1.0 in stage 60.0 (TID 195)
18/04/01 20:15:30 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:30 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:30 INFO Executor: Finished task 0.0 in stage 60.0 (TID 194). 938 bytes result sent to driver
18/04/01 20:15:30 INFO TaskSetManager: Starting task 2.0 in stage 60.0 (TID 196, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:30 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 194) in 13 ms on localhost (executor driver) (1/5)
18/04/01 20:15:30 INFO Executor: Finished task 1.0 in stage 60.0 (TID 195). 938 bytes result sent to driver
18/04/01 20:15:30 INFO Executor: Running task 2.0 in stage 60.0 (TID 196)
18/04/01 20:15:30 INFO TaskSetManager: Starting task 3.0 in stage 60.0 (TID 197, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:30 INFO TaskSetManager: Finished task 1.0 in stage 60.0 (TID 195) in 17 ms on localhost (executor driver) (2/5)
18/04/01 20:15:30 INFO Executor: Running task 3.0 in stage 60.0 (TID 197)
18/04/01 20:15:30 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:30 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:30 INFO Executor: Finished task 3.0 in stage 60.0 (TID 197). 981 bytes result sent to driver
18/04/01 20:15:30 INFO Executor: Finished task 2.0 in stage 60.0 (TID 196). 938 bytes result sent to driver
18/04/01 20:15:30 INFO TaskSetManager: Starting task 4.0 in stage 60.0 (TID 198, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:30 INFO Executor: Running task 4.0 in stage 60.0 (TID 198)
18/04/01 20:15:30 INFO TaskSetManager: Finished task 3.0 in stage 60.0 (TID 197) in 19 ms on localhost (executor driver) (3/5)
18/04/01 20:15:30 INFO TaskSetManager: Finished task 2.0 in stage 60.0 (TID 196) in 25 ms on localhost (executor driver) (4/5)
18/04/01 20:15:30 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 712 -> 714
18/04/01 20:15:30 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 712
18/04/01 20:15:31 INFO Executor: Finished task 4.0 in stage 60.0 (TID 198). 1024 bytes result sent to driver
18/04/01 20:15:31 INFO TaskSetManager: Finished task 4.0 in stage 60.0 (TID 198) in 336 ms on localhost (executor driver) (5/5)
18/04/01 20:15:31 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
18/04/01 20:15:31 INFO DAGScheduler: ShuffleMapStage 60 (map at RefereeStats.scala:46) finished in 0.387 s
18/04/01 20:15:31 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:31 INFO DAGScheduler: running: Set()
18/04/01 20:15:31 INFO DAGScheduler: waiting: Set(ResultStage 61)
18/04/01 20:15:31 INFO DAGScheduler: failed: Set()
18/04/01 20:15:31 INFO DAGScheduler: Submitting ResultStage 61 (ShuffledRDD[53] at reduceByKey at RefereeStats.scala:51), which has no missing parents
18/04/01 20:15:31 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:15:31 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 1709.0 B, free 477.2 MB)
18/04/01 20:15:31 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 192.168.1.3:35449 (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:15:31 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 61 (ShuffledRDD[53] at reduceByKey at RefereeStats.scala:51) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:31 INFO TaskSchedulerImpl: Adding task set 61.0 with 2 tasks
18/04/01 20:15:31 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 199, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:15:31 INFO TaskSetManager: Starting task 1.0 in stage 61.0 (TID 200, localhost, executor driver, partition 1, ANY, 7649 bytes)
18/04/01 20:15:31 INFO Executor: Running task 0.0 in stage 61.0 (TID 199)
18/04/01 20:15:31 INFO Executor: Running task 1.0 in stage 61.0 (TID 200)
18/04/01 20:15:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:15:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:15:31 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:31 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:31 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:31 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:31 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:31 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:31 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:31 INFO KafkaProducer: [Producer clientId=producer-46] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:31 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:31 INFO KafkaProducer: [Producer clientId=producer-45] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:31 INFO Executor: Finished task 0.0 in stage 61.0 (TID 199). 1138 bytes result sent to driver
18/04/01 20:15:31 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 199) in 54 ms on localhost (executor driver) (1/2)
18/04/01 20:15:31 INFO Executor: Finished task 1.0 in stage 61.0 (TID 200). 1138 bytes result sent to driver
18/04/01 20:15:31 INFO TaskSetManager: Finished task 1.0 in stage 61.0 (TID 200) in 66 ms on localhost (executor driver) (2/2)
18/04/01 20:15:31 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
18/04/01 20:15:31 INFO DAGScheduler: ResultStage 61 (foreachPartition at RefereeStats.scala:89) finished in 0.079 s
18/04/01 20:15:31 INFO DAGScheduler: Job 38 finished: foreachPartition at RefereeStats.scala:89, took 0.477448 s
18/04/01 20:15:31 INFO JobScheduler: Finished job streaming job 1522602930000 ms.2 from job set of time 1522602930000 ms
18/04/01 20:15:31 INFO JobScheduler: Starting job streaming job 1522602930000 ms.3 from job set of time 1522602930000 ms
18/04/01 20:15:31 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:106
18/04/01 20:15:31 INFO DAGScheduler: Registering RDD 54 (map at RefereeStats.scala:39)
18/04/01 20:15:31 INFO DAGScheduler: Got job 39 (foreachPartition at RefereeStats.scala:106) with 2 output partitions
18/04/01 20:15:31 INFO DAGScheduler: Final stage: ResultStage 63 (foreachPartition at RefereeStats.scala:106)
18/04/01 20:15:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 62)
18/04/01 20:15:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 62)
18/04/01 20:15:31 INFO DAGScheduler: Submitting ShuffleMapStage 62 (MapPartitionsRDD[54] at map at RefereeStats.scala:39), which has no missing parents
18/04/01 20:15:31 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:15:31 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:15:31 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:31 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:31 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[54] at map at RefereeStats.scala:39) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:31 INFO TaskSchedulerImpl: Adding task set 62.0 with 5 tasks
18/04/01 20:15:31 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 201, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:31 INFO TaskSetManager: Starting task 1.0 in stage 62.0 (TID 202, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:31 INFO Executor: Running task 1.0 in stage 62.0 (TID 202)
18/04/01 20:15:31 INFO Executor: Running task 0.0 in stage 62.0 (TID 201)
18/04/01 20:15:31 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:31 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:31 INFO Executor: Finished task 0.0 in stage 62.0 (TID 201). 938 bytes result sent to driver
18/04/01 20:15:31 INFO TaskSetManager: Starting task 2.0 in stage 62.0 (TID 203, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:31 INFO Executor: Running task 2.0 in stage 62.0 (TID 203)
18/04/01 20:15:31 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 201) in 12 ms on localhost (executor driver) (1/5)
18/04/01 20:15:31 INFO Executor: Finished task 1.0 in stage 62.0 (TID 202). 938 bytes result sent to driver
18/04/01 20:15:31 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:31 INFO TaskSetManager: Starting task 3.0 in stage 62.0 (TID 204, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:31 INFO Executor: Running task 3.0 in stage 62.0 (TID 204)
18/04/01 20:15:31 INFO TaskSetManager: Finished task 1.0 in stage 62.0 (TID 202) in 20 ms on localhost (executor driver) (2/5)
18/04/01 20:15:31 INFO Executor: Finished task 2.0 in stage 62.0 (TID 203). 938 bytes result sent to driver
18/04/01 20:15:31 INFO TaskSetManager: Starting task 4.0 in stage 62.0 (TID 205, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:31 INFO Executor: Running task 4.0 in stage 62.0 (TID 205)
18/04/01 20:15:31 INFO TaskSetManager: Finished task 2.0 in stage 62.0 (TID 203) in 16 ms on localhost (executor driver) (3/5)
18/04/01 20:15:31 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:31 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 712 -> 714
18/04/01 20:15:31 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 712
18/04/01 20:15:31 INFO Executor: Finished task 3.0 in stage 62.0 (TID 204). 938 bytes result sent to driver
18/04/01 20:15:31 INFO TaskSetManager: Finished task 3.0 in stage 62.0 (TID 204) in 16 ms on localhost (executor driver) (4/5)
18/04/01 20:15:31 INFO Executor: Finished task 4.0 in stage 62.0 (TID 205). 1024 bytes result sent to driver
18/04/01 20:15:31 INFO TaskSetManager: Finished task 4.0 in stage 62.0 (TID 205) in 362 ms on localhost (executor driver) (5/5)
18/04/01 20:15:31 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
18/04/01 20:15:31 INFO DAGScheduler: ShuffleMapStage 62 (map at RefereeStats.scala:39) finished in 0.402 s
18/04/01 20:15:31 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:31 INFO DAGScheduler: running: Set()
18/04/01 20:15:31 INFO DAGScheduler: waiting: Set(ResultStage 63)
18/04/01 20:15:31 INFO DAGScheduler: failed: Set()
18/04/01 20:15:31 INFO DAGScheduler: Submitting ResultStage 63 (ShuffledRDD[55] at reduceByKey at RefereeStats.scala:43), which has no missing parents
18/04/01 20:15:31 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:15:31 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 1704.0 B, free 477.2 MB)
18/04/01 20:15:31 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 192.168.1.3:35449 (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:15:31 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 63 (ShuffledRDD[55] at reduceByKey at RefereeStats.scala:43) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:31 INFO TaskSchedulerImpl: Adding task set 63.0 with 2 tasks
18/04/01 20:15:31 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 206, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:15:31 INFO TaskSetManager: Starting task 1.0 in stage 63.0 (TID 207, localhost, executor driver, partition 1, ANY, 7649 bytes)
18/04/01 20:15:31 INFO Executor: Running task 1.0 in stage 63.0 (TID 207)
18/04/01 20:15:31 INFO Executor: Running task 0.0 in stage 63.0 (TID 206)
18/04/01 20:15:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:31 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:31 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:31 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:31 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:31 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:31 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:31 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:31 INFO KafkaProducer: [Producer clientId=producer-48] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:31 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:31 INFO KafkaProducer: [Producer clientId=producer-47] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:31 INFO Executor: Finished task 1.0 in stage 63.0 (TID 207). 1138 bytes result sent to driver
18/04/01 20:15:31 INFO TaskSetManager: Finished task 1.0 in stage 63.0 (TID 207) in 49 ms on localhost (executor driver) (1/2)
18/04/01 20:15:31 INFO Executor: Finished task 0.0 in stage 63.0 (TID 206). 1138 bytes result sent to driver
18/04/01 20:15:31 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 206) in 54 ms on localhost (executor driver) (2/2)
18/04/01 20:15:31 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
18/04/01 20:15:31 INFO DAGScheduler: ResultStage 63 (foreachPartition at RefereeStats.scala:106) finished in 0.067 s
18/04/01 20:15:31 INFO DAGScheduler: Job 39 finished: foreachPartition at RefereeStats.scala:106, took 0.479801 s
18/04/01 20:15:31 INFO JobScheduler: Finished job streaming job 1522602930000 ms.3 from job set of time 1522602930000 ms
18/04/01 20:15:31 INFO JobScheduler: Total delay: 1.759 s for time 1522602930000 ms (execution: 1.713 s)
18/04/01 20:15:31 INFO MapPartitionsRDD: Removing RDD 43 from persistence list
18/04/01 20:15:31 INFO BlockManager: Removing RDD 43
18/04/01 20:15:31 INFO KafkaRDD: Removing RDD 42 from persistence list
18/04/01 20:15:31 INFO ShuffledRDD: Removing RDD 44 from persistence list
18/04/01 20:15:31 INFO BlockManager: Removing RDD 42
18/04/01 20:15:31 INFO BlockManager: Removing RDD 44
18/04/01 20:15:31 INFO ShuffledRDD: Removing RDD 46 from persistence list
18/04/01 20:15:31 INFO MapPartitionsRDD: Removing RDD 45 from persistence list
18/04/01 20:15:31 INFO BlockManager: Removing RDD 46
18/04/01 20:15:31 INFO BlockManager: Removing RDD 45
18/04/01 20:15:31 INFO ShuffledRDD: Removing RDD 48 from persistence list
18/04/01 20:15:31 INFO BlockManager: Removing RDD 48
18/04/01 20:15:31 INFO MapPartitionsRDD: Removing RDD 47 from persistence list
18/04/01 20:15:31 INFO BlockManager: Removing RDD 47
18/04/01 20:15:31 INFO JobGenerator: Checkpointing graph for time 1522602930000 ms
18/04/01 20:15:31 INFO DStreamGraph: Updating checkpoint data for time 1522602930000 ms
18/04/01 20:15:31 INFO DStreamGraph: Updated checkpoint data for time 1522602930000 ms
18/04/01 20:15:31 INFO CheckpointWriter: Submitted checkpoint of time 1522602930000 ms to writer queue
18/04/01 20:15:31 INFO CheckpointWriter: Saving checkpoint for time 1522602930000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602930000'
18/04/01 20:15:31 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602905000
18/04/01 20:15:31 INFO CheckpointWriter: Checkpoint for time 1522602930000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602930000', took 5541 bytes and 24 ms
18/04/01 20:15:31 INFO DStreamGraph: Clearing checkpoint data for time 1522602930000 ms
18/04/01 20:15:31 INFO DStreamGraph: Cleared checkpoint data for time 1522602930000 ms
18/04/01 20:15:31 INFO ReceivedBlockTracker: Deleting batches: 
18/04/01 20:15:31 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/tmp/refs-xyzabb/receivedBlockMetadata older than 1522602925000: 
18/04/01 20:15:31 INFO InputInfoTracker: remove old batch metadata: 1522602920000 ms
18/04/01 20:15:35 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-0 to offset 715.
18/04/01 20:15:35 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-3 to offset 0.
18/04/01 20:15:35 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-4 to offset 0.
18/04/01 20:15:35 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-1 to offset 0.
18/04/01 20:15:35 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-2 to offset 0.
18/04/01 20:15:35 INFO JobScheduler: Added jobs for time 1522602935000 ms
18/04/01 20:15:35 INFO JobGenerator: Checkpointing graph for time 1522602935000 ms
18/04/01 20:15:35 INFO DStreamGraph: Updating checkpoint data for time 1522602935000 ms
18/04/01 20:15:35 INFO JobScheduler: Starting job streaming job 1522602935000 ms.0 from job set of time 1522602935000 ms
18/04/01 20:15:35 INFO DStreamGraph: Updated checkpoint data for time 1522602935000 ms
18/04/01 20:15:35 INFO CheckpointWriter: Submitted checkpoint of time 1522602935000 ms to writer queue
18/04/01 20:15:35 INFO CheckpointWriter: Saving checkpoint for time 1522602935000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602935000'
18/04/01 20:15:35 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:15:35 INFO DAGScheduler: Got job 40 (print at RefereeStats.scala:67) with 1 output partitions
18/04/01 20:15:35 INFO DAGScheduler: Final stage: ResultStage 64 (print at RefereeStats.scala:67)
18/04/01 20:15:35 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:15:35 INFO DAGScheduler: Missing parents: List()
18/04/01 20:15:35 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[57] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:35 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 3.0 KB, free 477.2 MB)
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1237
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1317
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1426
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1438
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1423
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1529
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1445
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1557
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1523
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1241
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1281
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1298
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1374
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1533
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1503
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1230
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1444
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1512
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1532
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1316
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1590
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1515
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1538
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1268
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1514
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1565
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1411
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1498
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1236
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1510
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1485
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1588
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1394
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1493
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1595
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1299
18/04/01 20:15:35 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.2 MB)
18/04/01 20:15:35 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:35 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 192.168.1.3:35449 in memory (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:15:35 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602910000.bk
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1419
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1228
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1338
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1455
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1466
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1301
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1296
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1591
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1264
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1337
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1555
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1554
18/04/01 20:15:35 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:35 INFO CheckpointWriter: Checkpoint for time 1522602935000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602935000', took 5590 bytes and 40 ms
18/04/01 20:15:35 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[57] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0))
18/04/01 20:15:35 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1454
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1542
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1564
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1247
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1584
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1254
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1522
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1342
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1412
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1488
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1457
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1468
18/04/01 20:15:35 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 208, localhost, executor driver, partition 0, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:35 INFO Executor: Running task 0.0 in stage 64.0 (TID 208)
18/04/01 20:15:35 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 192.168.1.3:35449 in memory (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:15:35 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1567
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1448
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1339
18/04/01 20:15:35 INFO Executor: Finished task 0.0 in stage 64.0 (TID 208). 704 bytes result sent to driver
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1368
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1345
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1253
18/04/01 20:15:35 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 208) in 6 ms on localhost (executor driver) (1/1)
18/04/01 20:15:35 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1350
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1362
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1308
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1537
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1396
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1226
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1436
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1578
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1505
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1558
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1484
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1577
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1292
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1451
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1269
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1234
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1252
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1534
18/04/01 20:15:35 INFO DAGScheduler: ResultStage 64 (print at RefereeStats.scala:67) finished in 0.032 s
18/04/01 20:15:35 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:35 INFO DAGScheduler: Job 40 finished: print at RefereeStats.scala:67, took 0.038826 s
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1328
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1546
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1528
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1242
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1225
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1255
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1439
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1327
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1244
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1304
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1261
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1390
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1250
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1547
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1582
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1266
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1283
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1575
18/04/01 20:15:35 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:35 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 192.168.1.3:35449 in memory (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:15:35 INFO ContextCleaner: Cleaned shuffle 20
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1501
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1377
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1535
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1370
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1520
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1320
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1369
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1410
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1262
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1313
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1422
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1367
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1388
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1587
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1246
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1400
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1540
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1233
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1459
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1427
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1280
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1432
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1276
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1305
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1594
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1561
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1500
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1576
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1494
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1511
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1516
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1319
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1384
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1570
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1489
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1458
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1312
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1291
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1270
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1428
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1358
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1551
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1583
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1277
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1417
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1324
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1586
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1232
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1517
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1409
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1524
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1389
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1486
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1353
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1562
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1271
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1573
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1357
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1550
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1521
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1487
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1322
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1361
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1541
18/04/01 20:15:35 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 192.168.1.3:35449 in memory (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1381
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1580
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1589
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1294
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1504
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1273
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1382
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1302
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1495
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1452
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1303
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1363
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1593
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1289
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1295
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1525
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1449
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1496
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1371
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1506
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1375
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1456
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1518
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1256
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1323
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1265
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1460
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1592
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1341
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1450
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1347
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1392
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1429
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1574
18/04/01 20:15:35 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:15:35 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:35 INFO DAGScheduler: Got job 41 (print at RefereeStats.scala:67) with 4 output partitions
18/04/01 20:15:35 INFO DAGScheduler: Final stage: ResultStage 65 (print at RefereeStats.scala:67)
18/04/01 20:15:35 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:15:35 INFO DAGScheduler: Missing parents: List()
18/04/01 20:15:35 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[57] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1329
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1267
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1526
18/04/01 20:15:35 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 3.0 KB, free 477.2 MB)
18/04/01 20:15:35 INFO ContextCleaner: Cleaned shuffle 19
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1332
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1401
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1437
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1441
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1285
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1325
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1414
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1536
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1502
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1490
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1556
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1397
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1263
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1474
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1288
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1240
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1315
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1585
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1433
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1359
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1380
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1568
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1408
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1447
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1314
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1559
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1476
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1552
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1331
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1259
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1272
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1491
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1492
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1545
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1402
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1311
18/04/01 20:15:35 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 192.168.1.3:35449 in memory (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:15:35 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.2 MB)
18/04/01 20:15:35 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:35 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1508
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1539
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1373
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1418
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1398
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1421
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1354
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1407
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1527
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1306
18/04/01 20:15:35 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 65 (MapPartitionsRDD[57] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
18/04/01 20:15:35 INFO TaskSchedulerImpl: Adding task set 65.0 with 4 tasks
18/04/01 20:15:35 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 209, localhost, executor driver, partition 1, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:35 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:35 INFO TaskSetManager: Starting task 1.0 in stage 65.0 (TID 210, localhost, executor driver, partition 2, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:35 INFO Executor: Running task 1.0 in stage 65.0 (TID 210)
18/04/01 20:15:35 INFO Executor: Running task 0.0 in stage 65.0 (TID 209)
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1393
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1351
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1599
18/04/01 20:15:35 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:35 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 192.168.1.3:35449 in memory (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:15:35 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:35 INFO Executor: Finished task 0.0 in stage 65.0 (TID 209). 704 bytes result sent to driver
18/04/01 20:15:35 INFO Executor: Finished task 1.0 in stage 65.0 (TID 210). 704 bytes result sent to driver
18/04/01 20:15:35 INFO TaskSetManager: Starting task 2.0 in stage 65.0 (TID 211, localhost, executor driver, partition 3, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:35 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 209) in 11 ms on localhost (executor driver) (1/4)
18/04/01 20:15:35 INFO Executor: Running task 2.0 in stage 65.0 (TID 211)
18/04/01 20:15:35 INFO TaskSetManager: Finished task 1.0 in stage 65.0 (TID 210) in 13 ms on localhost (executor driver) (2/4)
18/04/01 20:15:35 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:35 INFO Executor: Finished task 2.0 in stage 65.0 (TID 211). 704 bytes result sent to driver
18/04/01 20:15:35 INFO TaskSetManager: Starting task 3.0 in stage 65.0 (TID 212, localhost, executor driver, partition 4, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:35 INFO Executor: Running task 3.0 in stage 65.0 (TID 212)
18/04/01 20:15:35 INFO TaskSetManager: Finished task 2.0 in stage 65.0 (TID 211) in 9 ms on localhost (executor driver) (3/4)
18/04/01 20:15:35 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 714 -> 715
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1243
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1548
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1563
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1443
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1364
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1462
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1597
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1465
18/04/01 20:15:35 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1352
18/04/01 20:15:35 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1335
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1275
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1360
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1318
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1530
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1464
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1343
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1344
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1442
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1300
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1349
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1482
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1365
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1453
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1310
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1356
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1598
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1473
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1472
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1346
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1477
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1406
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1581
18/04/01 20:15:35 INFO Executor: Finished task 3.0 in stage 65.0 (TID 212). 861 bytes result sent to driver
18/04/01 20:15:35 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:35 INFO TaskSetManager: Finished task 3.0 in stage 65.0 (TID 212) in 20 ms on localhost (executor driver) (4/4)
18/04/01 20:15:35 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
18/04/01 20:15:35 INFO DAGScheduler: ResultStage 65 (print at RefereeStats.scala:67) finished in 0.056 s
18/04/01 20:15:35 INFO DAGScheduler: Job 41 finished: print at RefereeStats.scala:67, took 0.066452 s
-------------------------------------------
Time: 1522602935000 ms
-------------------------------------------
(instagram.*,0)

18/04/01 20:15:35 INFO ContextCleaner: Cleaned shuffle 18
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1483
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1569
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1366
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1340
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1274
18/04/01 20:15:35 INFO JobScheduler: Finished job streaming job 1522602935000 ms.0 from job set of time 1522602935000 ms
18/04/01 20:15:35 INFO JobScheduler: Starting job streaming job 1522602935000 ms.1 from job set of time 1522602935000 ms
18/04/01 20:15:35 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1560
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1334
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1497
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1309
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1321
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1471
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1372
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1376
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1470
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1467
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1579
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1403
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1434
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1469
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1405
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1499
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1435
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1475
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1425
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1446
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1399
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1287
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1463
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1378
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1440
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1481
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1480
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1260
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1543
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1572
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1519
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1227
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1431
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1284
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1531
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1326
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1333
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1596
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1239
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1383
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1479
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1420
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1416
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1286
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1430
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1235
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1229
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1290
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1507
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1238
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1553
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1257
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1379
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1509
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1330
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1245
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1258
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1231
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1404
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1415
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1386
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1461
18/04/01 20:15:35 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1385
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1387
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1279
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1297
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1566
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1249
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1307
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1424
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1391
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1549
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1395
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1278
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1348
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1336
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1571
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1251
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1413
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1544
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1248
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1293
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1355
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1478
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1282
18/04/01 20:15:35 INFO ContextCleaner: Cleaned accumulator 1513
18/04/01 20:15:35 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:71
18/04/01 20:15:35 INFO DAGScheduler: Registering RDD 57 (map at RefereeStats.scala:53)
18/04/01 20:15:35 INFO DAGScheduler: Got job 42 (foreachPartition at RefereeStats.scala:71) with 2 output partitions
18/04/01 20:15:35 INFO DAGScheduler: Final stage: ResultStage 67 (foreachPartition at RefereeStats.scala:71)
18/04/01 20:15:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 66)
18/04/01 20:15:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 66)
18/04/01 20:15:35 INFO DAGScheduler: Submitting ShuffleMapStage 66 (MapPartitionsRDD[57] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:35 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 3.9 KB, free 477.3 MB)
18/04/01 20:15:35 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.3 MB)
18/04/01 20:15:35 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:35 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:35 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 66 (MapPartitionsRDD[57] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:35 INFO TaskSchedulerImpl: Adding task set 66.0 with 5 tasks
18/04/01 20:15:35 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 213, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:35 INFO TaskSetManager: Starting task 1.0 in stage 66.0 (TID 214, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:35 INFO Executor: Running task 0.0 in stage 66.0 (TID 213)
18/04/01 20:15:35 INFO Executor: Running task 1.0 in stage 66.0 (TID 214)
18/04/01 20:15:35 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:35 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:35 INFO Executor: Finished task 0.0 in stage 66.0 (TID 213). 938 bytes result sent to driver
18/04/01 20:15:35 INFO Executor: Finished task 1.0 in stage 66.0 (TID 214). 938 bytes result sent to driver
18/04/01 20:15:35 INFO TaskSetManager: Starting task 2.0 in stage 66.0 (TID 215, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:35 INFO Executor: Running task 2.0 in stage 66.0 (TID 215)
18/04/01 20:15:35 INFO TaskSetManager: Starting task 3.0 in stage 66.0 (TID 216, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:35 INFO Executor: Running task 3.0 in stage 66.0 (TID 216)
18/04/01 20:15:35 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 213) in 12 ms on localhost (executor driver) (1/5)
18/04/01 20:15:35 INFO TaskSetManager: Finished task 1.0 in stage 66.0 (TID 214) in 11 ms on localhost (executor driver) (2/5)
18/04/01 20:15:35 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:35 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:35 INFO Executor: Finished task 3.0 in stage 66.0 (TID 216). 938 bytes result sent to driver
18/04/01 20:15:35 INFO Executor: Finished task 2.0 in stage 66.0 (TID 215). 938 bytes result sent to driver
18/04/01 20:15:35 INFO TaskSetManager: Starting task 4.0 in stage 66.0 (TID 217, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:35 INFO TaskSetManager: Finished task 2.0 in stage 66.0 (TID 215) in 7 ms on localhost (executor driver) (3/5)
18/04/01 20:15:35 INFO TaskSetManager: Finished task 3.0 in stage 66.0 (TID 216) in 7 ms on localhost (executor driver) (4/5)
18/04/01 20:15:35 INFO Executor: Running task 4.0 in stage 66.0 (TID 217)
18/04/01 20:15:35 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 714 -> 715
18/04/01 20:15:35 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 714
18/04/01 20:15:35 INFO Executor: Finished task 4.0 in stage 66.0 (TID 217). 1024 bytes result sent to driver
18/04/01 20:15:35 INFO TaskSetManager: Finished task 4.0 in stage 66.0 (TID 217) in 19 ms on localhost (executor driver) (5/5)
18/04/01 20:15:35 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
18/04/01 20:15:35 INFO DAGScheduler: ShuffleMapStage 66 (map at RefereeStats.scala:53) finished in 0.055 s
18/04/01 20:15:35 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:35 INFO DAGScheduler: running: Set()
18/04/01 20:15:35 INFO DAGScheduler: waiting: Set(ResultStage 67)
18/04/01 20:15:35 INFO DAGScheduler: failed: Set()
18/04/01 20:15:35 INFO DAGScheduler: Submitting ResultStage 67 (ShuffledRDD[58] at reduceByKey at RefereeStats.scala:60), which has no missing parents
18/04/01 20:15:35 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 2.8 KB, free 477.3 MB)
18/04/01 20:15:35 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 1706.0 B, free 477.3 MB)
18/04/01 20:15:35 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 192.168.1.3:35449 (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:15:35 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 67 (ShuffledRDD[58] at reduceByKey at RefereeStats.scala:60) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:35 INFO TaskSchedulerImpl: Adding task set 67.0 with 2 tasks
18/04/01 20:15:35 INFO TaskSetManager: Starting task 1.0 in stage 67.0 (TID 218, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:15:35 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 219, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:15:35 INFO Executor: Running task 1.0 in stage 67.0 (TID 218)
18/04/01 20:15:35 INFO Executor: Running task 0.0 in stage 67.0 (TID 219)
18/04/01 20:15:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:35 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:15:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
18/04/01 20:15:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:35 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:35 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:35 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:35 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:35 INFO KafkaProducer: [Producer clientId=producer-50] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:35 INFO Executor: Finished task 1.0 in stage 67.0 (TID 218). 1138 bytes result sent to driver
18/04/01 20:15:35 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:35 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:35 INFO TaskSetManager: Finished task 1.0 in stage 67.0 (TID 218) in 38 ms on localhost (executor driver) (1/2)
18/04/01 20:15:35 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:35 INFO KafkaProducer: [Producer clientId=producer-49] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:35 INFO Executor: Finished task 0.0 in stage 67.0 (TID 219). 1138 bytes result sent to driver
18/04/01 20:15:35 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 219) in 63 ms on localhost (executor driver) (2/2)
18/04/01 20:15:35 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
18/04/01 20:15:35 INFO DAGScheduler: ResultStage 67 (foreachPartition at RefereeStats.scala:71) finished in 0.080 s
18/04/01 20:15:35 INFO DAGScheduler: Job 42 finished: foreachPartition at RefereeStats.scala:71, took 0.144804 s
18/04/01 20:15:35 INFO JobScheduler: Finished job streaming job 1522602935000 ms.1 from job set of time 1522602935000 ms
18/04/01 20:15:35 INFO JobScheduler: Starting job streaming job 1522602935000 ms.2 from job set of time 1522602935000 ms
18/04/01 20:15:35 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:89
18/04/01 20:15:35 INFO DAGScheduler: Registering RDD 59 (map at RefereeStats.scala:46)
18/04/01 20:15:35 INFO DAGScheduler: Got job 43 (foreachPartition at RefereeStats.scala:89) with 2 output partitions
18/04/01 20:15:35 INFO DAGScheduler: Final stage: ResultStage 69 (foreachPartition at RefereeStats.scala:89)
18/04/01 20:15:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 68)
18/04/01 20:15:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 68)
18/04/01 20:15:35 INFO DAGScheduler: Submitting ShuffleMapStage 68 (MapPartitionsRDD[59] at map at RefereeStats.scala:46), which has no missing parents
18/04/01 20:15:35 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 3.9 KB, free 477.3 MB)
18/04/01 20:15:35 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.3 MB)
18/04/01 20:15:35 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:35 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:35 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 68 (MapPartitionsRDD[59] at map at RefereeStats.scala:46) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:35 INFO TaskSchedulerImpl: Adding task set 68.0 with 5 tasks
18/04/01 20:15:35 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 220, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:35 INFO TaskSetManager: Starting task 1.0 in stage 68.0 (TID 221, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:35 INFO Executor: Running task 1.0 in stage 68.0 (TID 221)
18/04/01 20:15:35 INFO Executor: Running task 0.0 in stage 68.0 (TID 220)
18/04/01 20:15:35 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:35 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:35 INFO Executor: Finished task 1.0 in stage 68.0 (TID 221). 938 bytes result sent to driver
18/04/01 20:15:35 INFO TaskSetManager: Starting task 2.0 in stage 68.0 (TID 222, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:35 INFO TaskSetManager: Finished task 1.0 in stage 68.0 (TID 221) in 9 ms on localhost (executor driver) (1/5)
18/04/01 20:15:35 INFO Executor: Finished task 0.0 in stage 68.0 (TID 220). 938 bytes result sent to driver
18/04/01 20:15:35 INFO Executor: Running task 2.0 in stage 68.0 (TID 222)
18/04/01 20:15:35 INFO TaskSetManager: Starting task 3.0 in stage 68.0 (TID 223, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:35 INFO Executor: Running task 3.0 in stage 68.0 (TID 223)
18/04/01 20:15:35 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 220) in 14 ms on localhost (executor driver) (2/5)
18/04/01 20:15:35 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:35 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:35 INFO Executor: Finished task 3.0 in stage 68.0 (TID 223). 938 bytes result sent to driver
18/04/01 20:15:35 INFO Executor: Finished task 2.0 in stage 68.0 (TID 222). 981 bytes result sent to driver
18/04/01 20:15:35 INFO TaskSetManager: Starting task 4.0 in stage 68.0 (TID 224, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:35 INFO TaskSetManager: Finished task 3.0 in stage 68.0 (TID 223) in 8 ms on localhost (executor driver) (3/5)
18/04/01 20:15:35 INFO TaskSetManager: Finished task 2.0 in stage 68.0 (TID 222) in 12 ms on localhost (executor driver) (4/5)
18/04/01 20:15:35 INFO Executor: Running task 4.0 in stage 68.0 (TID 224)
18/04/01 20:15:35 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 714 -> 715
18/04/01 20:15:35 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 714
18/04/01 20:15:35 INFO Executor: Finished task 4.0 in stage 68.0 (TID 224). 1024 bytes result sent to driver
18/04/01 20:15:35 INFO TaskSetManager: Finished task 4.0 in stage 68.0 (TID 224) in 367 ms on localhost (executor driver) (5/5)
18/04/01 20:15:35 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
18/04/01 20:15:35 INFO DAGScheduler: ShuffleMapStage 68 (map at RefereeStats.scala:46) finished in 0.398 s
18/04/01 20:15:35 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:35 INFO DAGScheduler: running: Set()
18/04/01 20:15:35 INFO DAGScheduler: waiting: Set(ResultStage 69)
18/04/01 20:15:35 INFO DAGScheduler: failed: Set()
18/04/01 20:15:35 INFO DAGScheduler: Submitting ResultStage 69 (ShuffledRDD[60] at reduceByKey at RefereeStats.scala:51), which has no missing parents
18/04/01 20:15:35 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:15:35 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 1709.0 B, free 477.2 MB)
18/04/01 20:15:35 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 192.168.1.3:35449 (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:15:35 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 69 (ShuffledRDD[60] at reduceByKey at RefereeStats.scala:51) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:35 INFO TaskSchedulerImpl: Adding task set 69.0 with 2 tasks
18/04/01 20:15:35 INFO TaskSetManager: Starting task 1.0 in stage 69.0 (TID 225, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:15:35 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 226, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:15:35 INFO Executor: Running task 0.0 in stage 69.0 (TID 226)
18/04/01 20:15:35 INFO Executor: Running task 1.0 in stage 69.0 (TID 225)
18/04/01 20:15:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:35 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:15:35 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:35 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:35 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:35 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:35 INFO KafkaProducer: [Producer clientId=producer-52] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:35 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:35 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:35 INFO Executor: Finished task 1.0 in stage 69.0 (TID 225). 1138 bytes result sent to driver
18/04/01 20:15:35 INFO TaskSetManager: Finished task 1.0 in stage 69.0 (TID 225) in 25 ms on localhost (executor driver) (1/2)
18/04/01 20:15:35 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:35 INFO KafkaProducer: [Producer clientId=producer-51] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:35 INFO Executor: Finished task 0.0 in stage 69.0 (TID 226). 1138 bytes result sent to driver
18/04/01 20:15:35 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 226) in 40 ms on localhost (executor driver) (2/2)
18/04/01 20:15:35 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
18/04/01 20:15:35 INFO DAGScheduler: ResultStage 69 (foreachPartition at RefereeStats.scala:89) finished in 0.052 s
18/04/01 20:15:35 INFO DAGScheduler: Job 43 finished: foreachPartition at RefereeStats.scala:89, took 0.463248 s
18/04/01 20:15:35 INFO JobScheduler: Finished job streaming job 1522602935000 ms.2 from job set of time 1522602935000 ms
18/04/01 20:15:35 INFO JobScheduler: Starting job streaming job 1522602935000 ms.3 from job set of time 1522602935000 ms
18/04/01 20:15:35 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:106
18/04/01 20:15:35 INFO DAGScheduler: Registering RDD 61 (map at RefereeStats.scala:39)
18/04/01 20:15:35 INFO DAGScheduler: Got job 44 (foreachPartition at RefereeStats.scala:106) with 2 output partitions
18/04/01 20:15:35 INFO DAGScheduler: Final stage: ResultStage 71 (foreachPartition at RefereeStats.scala:106)
18/04/01 20:15:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 70)
18/04/01 20:15:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 70)
18/04/01 20:15:35 INFO DAGScheduler: Submitting ShuffleMapStage 70 (MapPartitionsRDD[61] at map at RefereeStats.scala:39), which has no missing parents
18/04/01 20:15:35 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:15:35 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:15:35 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:35 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:35 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 70 (MapPartitionsRDD[61] at map at RefereeStats.scala:39) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:35 INFO TaskSchedulerImpl: Adding task set 70.0 with 5 tasks
18/04/01 20:15:35 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 227, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:35 INFO TaskSetManager: Starting task 1.0 in stage 70.0 (TID 228, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:35 INFO Executor: Running task 1.0 in stage 70.0 (TID 228)
18/04/01 20:15:35 INFO Executor: Running task 0.0 in stage 70.0 (TID 227)
18/04/01 20:15:35 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:35 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:35 INFO Executor: Finished task 0.0 in stage 70.0 (TID 227). 938 bytes result sent to driver
18/04/01 20:15:35 INFO Executor: Finished task 1.0 in stage 70.0 (TID 228). 981 bytes result sent to driver
18/04/01 20:15:35 INFO TaskSetManager: Starting task 2.0 in stage 70.0 (TID 229, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:35 INFO Executor: Running task 2.0 in stage 70.0 (TID 229)
18/04/01 20:15:35 INFO TaskSetManager: Starting task 3.0 in stage 70.0 (TID 230, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:35 INFO TaskSetManager: Finished task 1.0 in stage 70.0 (TID 228) in 14 ms on localhost (executor driver) (1/5)
18/04/01 20:15:35 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 227) in 15 ms on localhost (executor driver) (2/5)
18/04/01 20:15:35 INFO Executor: Running task 3.0 in stage 70.0 (TID 230)
18/04/01 20:15:35 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:35 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:35 INFO Executor: Finished task 3.0 in stage 70.0 (TID 230). 981 bytes result sent to driver
18/04/01 20:15:35 INFO TaskSetManager: Starting task 4.0 in stage 70.0 (TID 231, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:35 INFO TaskSetManager: Finished task 3.0 in stage 70.0 (TID 230) in 12 ms on localhost (executor driver) (3/5)
18/04/01 20:15:35 INFO Executor: Finished task 2.0 in stage 70.0 (TID 229). 938 bytes result sent to driver
18/04/01 20:15:35 INFO Executor: Running task 4.0 in stage 70.0 (TID 231)
18/04/01 20:15:35 INFO TaskSetManager: Finished task 2.0 in stage 70.0 (TID 229) in 17 ms on localhost (executor driver) (4/5)
18/04/01 20:15:35 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 714 -> 715
18/04/01 20:15:35 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 714
18/04/01 20:15:36 INFO Executor: Finished task 4.0 in stage 70.0 (TID 231). 1024 bytes result sent to driver
18/04/01 20:15:36 INFO TaskSetManager: Finished task 4.0 in stage 70.0 (TID 231) in 396 ms on localhost (executor driver) (5/5)
18/04/01 20:15:36 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool 
18/04/01 20:15:36 INFO DAGScheduler: ShuffleMapStage 70 (map at RefereeStats.scala:39) finished in 0.433 s
18/04/01 20:15:36 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:36 INFO DAGScheduler: running: Set()
18/04/01 20:15:36 INFO DAGScheduler: waiting: Set(ResultStage 71)
18/04/01 20:15:36 INFO DAGScheduler: failed: Set()
18/04/01 20:15:36 INFO DAGScheduler: Submitting ResultStage 71 (ShuffledRDD[62] at reduceByKey at RefereeStats.scala:43), which has no missing parents
18/04/01 20:15:36 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:15:36 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 1704.0 B, free 477.2 MB)
18/04/01 20:15:36 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 192.168.1.3:35449 (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:15:36 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 71 (ShuffledRDD[62] at reduceByKey at RefereeStats.scala:43) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:36 INFO TaskSchedulerImpl: Adding task set 71.0 with 2 tasks
18/04/01 20:15:36 INFO TaskSetManager: Starting task 1.0 in stage 71.0 (TID 232, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:15:36 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 233, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:15:36 INFO Executor: Running task 0.0 in stage 71.0 (TID 233)
18/04/01 20:15:36 INFO Executor: Running task 1.0 in stage 71.0 (TID 232)
18/04/01 20:15:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:15:36 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:36 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:15:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:15:36 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:36 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:36 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:36 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:36 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:36 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:36 INFO KafkaProducer: [Producer clientId=producer-53] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:36 INFO KafkaProducer: [Producer clientId=producer-54] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:36 INFO Executor: Finished task 1.0 in stage 71.0 (TID 232). 1138 bytes result sent to driver
18/04/01 20:15:36 INFO TaskSetManager: Finished task 1.0 in stage 71.0 (TID 232) in 22 ms on localhost (executor driver) (1/2)
18/04/01 20:15:36 INFO Executor: Finished task 0.0 in stage 71.0 (TID 233). 1138 bytes result sent to driver
18/04/01 20:15:36 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 233) in 28 ms on localhost (executor driver) (2/2)
18/04/01 20:15:36 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
18/04/01 20:15:36 INFO DAGScheduler: ResultStage 71 (foreachPartition at RefereeStats.scala:106) finished in 0.039 s
18/04/01 20:15:36 INFO DAGScheduler: Job 44 finished: foreachPartition at RefereeStats.scala:106, took 0.483717 s
18/04/01 20:15:36 INFO JobScheduler: Finished job streaming job 1522602935000 ms.3 from job set of time 1522602935000 ms
18/04/01 20:15:36 INFO MapPartitionsRDD: Removing RDD 50 from persistence list
18/04/01 20:15:36 INFO JobScheduler: Total delay: 1.330 s for time 1522602935000 ms (execution: 1.294 s)
18/04/01 20:15:36 INFO BlockManager: Removing RDD 50
18/04/01 20:15:36 INFO KafkaRDD: Removing RDD 49 from persistence list
18/04/01 20:15:36 INFO BlockManager: Removing RDD 49
18/04/01 20:15:36 INFO ShuffledRDD: Removing RDD 51 from persistence list
18/04/01 20:15:36 INFO BlockManager: Removing RDD 51
18/04/01 20:15:36 INFO ShuffledRDD: Removing RDD 53 from persistence list
18/04/01 20:15:36 INFO BlockManager: Removing RDD 53
18/04/01 20:15:36 INFO MapPartitionsRDD: Removing RDD 52 from persistence list
18/04/01 20:15:36 INFO BlockManager: Removing RDD 52
18/04/01 20:15:36 INFO ShuffledRDD: Removing RDD 55 from persistence list
18/04/01 20:15:36 INFO BlockManager: Removing RDD 55
18/04/01 20:15:36 INFO MapPartitionsRDD: Removing RDD 54 from persistence list
18/04/01 20:15:36 INFO BlockManager: Removing RDD 54
18/04/01 20:15:36 INFO JobGenerator: Checkpointing graph for time 1522602935000 ms
18/04/01 20:15:36 INFO DStreamGraph: Updating checkpoint data for time 1522602935000 ms
18/04/01 20:15:36 INFO DStreamGraph: Updated checkpoint data for time 1522602935000 ms
18/04/01 20:15:36 INFO CheckpointWriter: Submitted checkpoint of time 1522602935000 ms to writer queue
18/04/01 20:15:36 INFO CheckpointWriter: Saving checkpoint for time 1522602935000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602935000'
18/04/01 20:15:36 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602910000
18/04/01 20:15:36 INFO CheckpointWriter: Checkpoint for time 1522602935000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602935000', took 5537 bytes and 22 ms
18/04/01 20:15:36 INFO DStreamGraph: Clearing checkpoint data for time 1522602935000 ms
18/04/01 20:15:36 INFO DStreamGraph: Cleared checkpoint data for time 1522602935000 ms
18/04/01 20:15:36 INFO ReceivedBlockTracker: Deleting batches: 
18/04/01 20:15:36 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/tmp/refs-xyzabb/receivedBlockMetadata older than 1522602930000: 
18/04/01 20:15:36 INFO InputInfoTracker: remove old batch metadata: 1522602925000 ms
18/04/01 20:15:40 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-0 to offset 718.
18/04/01 20:15:40 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-3 to offset 0.
18/04/01 20:15:40 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-4 to offset 0.
18/04/01 20:15:40 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-1 to offset 0.
18/04/01 20:15:40 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-2 to offset 0.
18/04/01 20:15:40 INFO JobScheduler: Added jobs for time 1522602940000 ms
18/04/01 20:15:40 INFO JobGenerator: Checkpointing graph for time 1522602940000 ms
18/04/01 20:15:40 INFO DStreamGraph: Updating checkpoint data for time 1522602940000 ms
18/04/01 20:15:40 INFO JobScheduler: Starting job streaming job 1522602940000 ms.0 from job set of time 1522602940000 ms
18/04/01 20:15:40 INFO DStreamGraph: Updated checkpoint data for time 1522602940000 ms
18/04/01 20:15:40 INFO CheckpointWriter: Saving checkpoint for time 1522602940000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602940000'
18/04/01 20:15:40 INFO CheckpointWriter: Submitted checkpoint of time 1522602940000 ms to writer queue
18/04/01 20:15:40 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:15:40 INFO DAGScheduler: Got job 45 (print at RefereeStats.scala:67) with 1 output partitions
18/04/01 20:15:40 INFO DAGScheduler: Final stage: ResultStage 72 (print at RefereeStats.scala:67)
18/04/01 20:15:40 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:15:40 INFO DAGScheduler: Missing parents: List()
18/04/01 20:15:40 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[64] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:40 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 3.0 KB, free 477.2 MB)
18/04/01 20:15:40 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602915000.bk
18/04/01 20:15:40 INFO CheckpointWriter: Checkpoint for time 1522602940000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602940000', took 5595 bytes and 20 ms
18/04/01 20:15:40 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.2 MB)
18/04/01 20:15:40 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:40 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[64] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0))
18/04/01 20:15:40 INFO TaskSchedulerImpl: Adding task set 72.0 with 1 tasks
18/04/01 20:15:40 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 234, localhost, executor driver, partition 0, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:40 INFO Executor: Running task 0.0 in stage 72.0 (TID 234)
18/04/01 20:15:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:40 INFO Executor: Finished task 0.0 in stage 72.0 (TID 234). 704 bytes result sent to driver
18/04/01 20:15:40 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 234) in 5 ms on localhost (executor driver) (1/1)
18/04/01 20:15:40 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool 
18/04/01 20:15:40 INFO DAGScheduler: ResultStage 72 (print at RefereeStats.scala:67) finished in 0.029 s
18/04/01 20:15:40 INFO DAGScheduler: Job 45 finished: print at RefereeStats.scala:67, took 0.033098 s
18/04/01 20:15:40 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:15:40 INFO DAGScheduler: Got job 46 (print at RefereeStats.scala:67) with 4 output partitions
18/04/01 20:15:40 INFO DAGScheduler: Final stage: ResultStage 73 (print at RefereeStats.scala:67)
18/04/01 20:15:40 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:15:40 INFO DAGScheduler: Missing parents: List()
18/04/01 20:15:40 INFO DAGScheduler: Submitting ResultStage 73 (MapPartitionsRDD[64] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:40 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 3.0 KB, free 477.2 MB)
18/04/01 20:15:40 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.2 MB)
18/04/01 20:15:40 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:40 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:40 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 73 (MapPartitionsRDD[64] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
18/04/01 20:15:40 INFO TaskSchedulerImpl: Adding task set 73.0 with 4 tasks
18/04/01 20:15:40 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 235, localhost, executor driver, partition 1, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:40 INFO TaskSetManager: Starting task 1.0 in stage 73.0 (TID 236, localhost, executor driver, partition 2, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:40 INFO Executor: Running task 1.0 in stage 73.0 (TID 236)
18/04/01 20:15:40 INFO Executor: Running task 0.0 in stage 73.0 (TID 235)
18/04/01 20:15:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:40 INFO Executor: Finished task 0.0 in stage 73.0 (TID 235). 747 bytes result sent to driver
18/04/01 20:15:40 INFO Executor: Finished task 1.0 in stage 73.0 (TID 236). 747 bytes result sent to driver
18/04/01 20:15:40 INFO TaskSetManager: Starting task 2.0 in stage 73.0 (TID 237, localhost, executor driver, partition 3, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:40 INFO Executor: Running task 2.0 in stage 73.0 (TID 237)
18/04/01 20:15:40 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 235) in 6 ms on localhost (executor driver) (1/4)
18/04/01 20:15:40 INFO TaskSetManager: Starting task 3.0 in stage 73.0 (TID 238, localhost, executor driver, partition 4, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:40 INFO TaskSetManager: Finished task 1.0 in stage 73.0 (TID 236) in 7 ms on localhost (executor driver) (2/4)
18/04/01 20:15:40 INFO Executor: Running task 3.0 in stage 73.0 (TID 238)
18/04/01 20:15:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:40 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 715 -> 718
18/04/01 20:15:40 INFO Executor: Finished task 2.0 in stage 73.0 (TID 237). 704 bytes result sent to driver
18/04/01 20:15:40 INFO TaskSetManager: Finished task 2.0 in stage 73.0 (TID 237) in 7 ms on localhost (executor driver) (3/4)
18/04/01 20:15:40 INFO Executor: Finished task 3.0 in stage 73.0 (TID 238). 919 bytes result sent to driver
18/04/01 20:15:40 INFO TaskSetManager: Finished task 3.0 in stage 73.0 (TID 238) in 10 ms on localhost (executor driver) (4/4)
18/04/01 20:15:40 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool 
18/04/01 20:15:40 INFO DAGScheduler: ResultStage 73 (print at RefereeStats.scala:67) finished in 0.027 s
18/04/01 20:15:40 INFO DAGScheduler: Job 46 finished: print at RefereeStats.scala:67, took 0.032236 s
18/04/01 20:15:40 INFO JobScheduler: Finished job streaming job 1522602940000 ms.0 from job set of time 1522602940000 ms
-------------------------------------------
Time: 1522602940000 ms
18/04/01 20:15:40 INFO JobScheduler: Starting job streaming job 1522602940000 ms.1 from job set of time 1522602940000 ms
-------------------------------------------
(yandex.*,4000)
(vk.com,5000)
(vk.com,7000)

18/04/01 20:15:40 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:71
18/04/01 20:15:40 INFO DAGScheduler: Registering RDD 64 (map at RefereeStats.scala:53)
18/04/01 20:15:40 INFO DAGScheduler: Got job 47 (foreachPartition at RefereeStats.scala:71) with 2 output partitions
18/04/01 20:15:40 INFO DAGScheduler: Final stage: ResultStage 75 (foreachPartition at RefereeStats.scala:71)
18/04/01 20:15:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 74)
18/04/01 20:15:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 74)
18/04/01 20:15:40 INFO DAGScheduler: Submitting ShuffleMapStage 74 (MapPartitionsRDD[64] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:40 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:15:40 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:15:40 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:40 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:40 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 74 (MapPartitionsRDD[64] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:40 INFO TaskSchedulerImpl: Adding task set 74.0 with 5 tasks
18/04/01 20:15:40 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 239, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:40 INFO TaskSetManager: Starting task 1.0 in stage 74.0 (TID 240, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:40 INFO Executor: Running task 0.0 in stage 74.0 (TID 239)
18/04/01 20:15:40 INFO Executor: Running task 1.0 in stage 74.0 (TID 240)
18/04/01 20:15:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:40 INFO Executor: Finished task 1.0 in stage 74.0 (TID 240). 938 bytes result sent to driver
18/04/01 20:15:40 INFO TaskSetManager: Starting task 2.0 in stage 74.0 (TID 241, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:40 INFO Executor: Running task 2.0 in stage 74.0 (TID 241)
18/04/01 20:15:40 INFO TaskSetManager: Finished task 1.0 in stage 74.0 (TID 240) in 8 ms on localhost (executor driver) (1/5)
18/04/01 20:15:40 INFO Executor: Finished task 0.0 in stage 74.0 (TID 239). 938 bytes result sent to driver
18/04/01 20:15:40 INFO TaskSetManager: Starting task 3.0 in stage 74.0 (TID 242, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:40 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 239) in 12 ms on localhost (executor driver) (2/5)
18/04/01 20:15:40 INFO Executor: Running task 3.0 in stage 74.0 (TID 242)
18/04/01 20:15:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:40 INFO Executor: Finished task 2.0 in stage 74.0 (TID 241). 938 bytes result sent to driver
18/04/01 20:15:40 INFO Executor: Finished task 3.0 in stage 74.0 (TID 242). 981 bytes result sent to driver
18/04/01 20:15:40 INFO TaskSetManager: Starting task 4.0 in stage 74.0 (TID 243, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:40 INFO Executor: Running task 4.0 in stage 74.0 (TID 243)
18/04/01 20:15:40 INFO TaskSetManager: Finished task 2.0 in stage 74.0 (TID 241) in 13 ms on localhost (executor driver) (3/5)
18/04/01 20:15:40 INFO TaskSetManager: Finished task 3.0 in stage 74.0 (TID 242) in 12 ms on localhost (executor driver) (4/5)
18/04/01 20:15:40 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 715 -> 718
18/04/01 20:15:40 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 715
18/04/01 20:15:40 INFO Executor: Finished task 4.0 in stage 74.0 (TID 243). 1024 bytes result sent to driver
18/04/01 20:15:40 INFO TaskSetManager: Finished task 4.0 in stage 74.0 (TID 243) in 462 ms on localhost (executor driver) (5/5)
18/04/01 20:15:40 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
18/04/01 20:15:40 INFO DAGScheduler: ShuffleMapStage 74 (map at RefereeStats.scala:53) finished in 0.493 s
18/04/01 20:15:40 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:40 INFO DAGScheduler: running: Set()
18/04/01 20:15:40 INFO DAGScheduler: waiting: Set(ResultStage 75)
18/04/01 20:15:40 INFO DAGScheduler: failed: Set()
18/04/01 20:15:40 INFO DAGScheduler: Submitting ResultStage 75 (ShuffledRDD[65] at reduceByKey at RefereeStats.scala:60), which has no missing parents
18/04/01 20:15:40 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:15:40 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 1706.0 B, free 477.2 MB)
18/04/01 20:15:40 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 192.168.1.3:35449 (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:15:40 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:40 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 75 (ShuffledRDD[65] at reduceByKey at RefereeStats.scala:60) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:40 INFO TaskSchedulerImpl: Adding task set 75.0 with 2 tasks
18/04/01 20:15:40 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 244, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:15:40 INFO TaskSetManager: Starting task 1.0 in stage 75.0 (TID 245, localhost, executor driver, partition 1, ANY, 7649 bytes)
18/04/01 20:15:40 INFO Executor: Running task 1.0 in stage 75.0 (TID 245)
18/04/01 20:15:40 INFO Executor: Running task 0.0 in stage 75.0 (TID 244)
18/04/01 20:15:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:40 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:40 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:40 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:40 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:40 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:40 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:40 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:40 INFO KafkaProducer: [Producer clientId=producer-56] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:40 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:40 INFO KafkaProducer: [Producer clientId=producer-55] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:40 INFO Executor: Finished task 0.0 in stage 75.0 (TID 244). 1138 bytes result sent to driver
18/04/01 20:15:40 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 244) in 39 ms on localhost (executor driver) (1/2)
18/04/01 20:15:40 INFO Executor: Finished task 1.0 in stage 75.0 (TID 245). 1138 bytes result sent to driver
18/04/01 20:15:40 INFO TaskSetManager: Finished task 1.0 in stage 75.0 (TID 245) in 45 ms on localhost (executor driver) (2/2)
18/04/01 20:15:40 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool 
18/04/01 20:15:40 INFO DAGScheduler: ResultStage 75 (foreachPartition at RefereeStats.scala:71) finished in 0.057 s
18/04/01 20:15:40 INFO DAGScheduler: Job 47 finished: foreachPartition at RefereeStats.scala:71, took 0.559370 s
18/04/01 20:15:40 INFO JobScheduler: Finished job streaming job 1522602940000 ms.1 from job set of time 1522602940000 ms
18/04/01 20:15:40 INFO JobScheduler: Starting job streaming job 1522602940000 ms.2 from job set of time 1522602940000 ms
18/04/01 20:15:40 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:89
18/04/01 20:15:40 INFO DAGScheduler: Registering RDD 66 (map at RefereeStats.scala:46)
18/04/01 20:15:40 INFO DAGScheduler: Got job 48 (foreachPartition at RefereeStats.scala:89) with 2 output partitions
18/04/01 20:15:40 INFO DAGScheduler: Final stage: ResultStage 77 (foreachPartition at RefereeStats.scala:89)
18/04/01 20:15:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 76)
18/04/01 20:15:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 76)
18/04/01 20:15:40 INFO DAGScheduler: Submitting ShuffleMapStage 76 (MapPartitionsRDD[66] at map at RefereeStats.scala:46), which has no missing parents
18/04/01 20:15:40 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:15:40 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:15:40 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:40 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:40 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 76 (MapPartitionsRDD[66] at map at RefereeStats.scala:46) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:40 INFO TaskSchedulerImpl: Adding task set 76.0 with 5 tasks
18/04/01 20:15:40 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 246, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:40 INFO TaskSetManager: Starting task 1.0 in stage 76.0 (TID 247, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:40 INFO Executor: Running task 1.0 in stage 76.0 (TID 247)
18/04/01 20:15:40 INFO Executor: Running task 0.0 in stage 76.0 (TID 246)
18/04/01 20:15:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:40 INFO Executor: Finished task 0.0 in stage 76.0 (TID 246). 938 bytes result sent to driver
18/04/01 20:15:40 INFO Executor: Finished task 1.0 in stage 76.0 (TID 247). 938 bytes result sent to driver
18/04/01 20:15:40 INFO TaskSetManager: Starting task 2.0 in stage 76.0 (TID 248, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:40 INFO Executor: Running task 2.0 in stage 76.0 (TID 248)
18/04/01 20:15:40 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 246) in 9 ms on localhost (executor driver) (1/5)
18/04/01 20:15:40 INFO TaskSetManager: Starting task 3.0 in stage 76.0 (TID 249, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:40 INFO TaskSetManager: Finished task 1.0 in stage 76.0 (TID 247) in 11 ms on localhost (executor driver) (2/5)
18/04/01 20:15:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:40 INFO Executor: Running task 3.0 in stage 76.0 (TID 249)
18/04/01 20:15:40 INFO Executor: Finished task 2.0 in stage 76.0 (TID 248). 938 bytes result sent to driver
18/04/01 20:15:40 INFO TaskSetManager: Starting task 4.0 in stage 76.0 (TID 250, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:40 INFO Executor: Running task 4.0 in stage 76.0 (TID 250)
18/04/01 20:15:40 INFO TaskSetManager: Finished task 2.0 in stage 76.0 (TID 248) in 9 ms on localhost (executor driver) (3/5)
18/04/01 20:15:40 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 715 -> 718
18/04/01 20:15:40 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 715
18/04/01 20:15:40 INFO Executor: Finished task 3.0 in stage 76.0 (TID 249). 981 bytes result sent to driver
18/04/01 20:15:40 INFO TaskSetManager: Finished task 3.0 in stage 76.0 (TID 249) in 12 ms on localhost (executor driver) (4/5)
18/04/01 20:15:41 INFO Executor: Finished task 4.0 in stage 76.0 (TID 250). 1024 bytes result sent to driver
18/04/01 20:15:41 INFO TaskSetManager: Finished task 4.0 in stage 76.0 (TID 250) in 397 ms on localhost (executor driver) (5/5)
18/04/01 20:15:41 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool 
18/04/01 20:15:41 INFO DAGScheduler: ShuffleMapStage 76 (map at RefereeStats.scala:46) finished in 0.424 s
18/04/01 20:15:41 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:41 INFO DAGScheduler: running: Set()
18/04/01 20:15:41 INFO DAGScheduler: waiting: Set(ResultStage 77)
18/04/01 20:15:41 INFO DAGScheduler: failed: Set()
18/04/01 20:15:41 INFO DAGScheduler: Submitting ResultStage 77 (ShuffledRDD[67] at reduceByKey at RefereeStats.scala:51), which has no missing parents
18/04/01 20:15:41 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:15:41 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 1709.0 B, free 477.2 MB)
18/04/01 20:15:41 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 192.168.1.3:35449 (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:15:41 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:41 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 77 (ShuffledRDD[67] at reduceByKey at RefereeStats.scala:51) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:41 INFO TaskSchedulerImpl: Adding task set 77.0 with 2 tasks
18/04/01 20:15:41 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 251, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:15:41 INFO TaskSetManager: Starting task 1.0 in stage 77.0 (TID 252, localhost, executor driver, partition 1, ANY, 7649 bytes)
18/04/01 20:15:41 INFO Executor: Running task 0.0 in stage 77.0 (TID 251)
18/04/01 20:15:41 INFO Executor: Running task 1.0 in stage 77.0 (TID 252)
18/04/01 20:15:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:15:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:15:41 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:41 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:41 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:41 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:41 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:41 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:41 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:41 INFO KafkaProducer: [Producer clientId=producer-58] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:41 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:41 INFO KafkaProducer: [Producer clientId=producer-57] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:41 INFO Executor: Finished task 1.0 in stage 77.0 (TID 252). 1138 bytes result sent to driver
18/04/01 20:15:41 INFO TaskSetManager: Finished task 1.0 in stage 77.0 (TID 252) in 37 ms on localhost (executor driver) (1/2)
18/04/01 20:15:41 INFO Executor: Finished task 0.0 in stage 77.0 (TID 251). 1181 bytes result sent to driver
18/04/01 20:15:41 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 251) in 45 ms on localhost (executor driver) (2/2)
18/04/01 20:15:41 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool 
18/04/01 20:15:41 INFO DAGScheduler: ResultStage 77 (foreachPartition at RefereeStats.scala:89) finished in 0.055 s
18/04/01 20:15:41 INFO DAGScheduler: Job 48 finished: foreachPartition at RefereeStats.scala:89, took 0.489123 s
18/04/01 20:15:41 INFO JobScheduler: Finished job streaming job 1522602940000 ms.2 from job set of time 1522602940000 ms
18/04/01 20:15:41 INFO JobScheduler: Starting job streaming job 1522602940000 ms.3 from job set of time 1522602940000 ms
18/04/01 20:15:41 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:106
18/04/01 20:15:41 INFO DAGScheduler: Registering RDD 68 (map at RefereeStats.scala:39)
18/04/01 20:15:41 INFO DAGScheduler: Got job 49 (foreachPartition at RefereeStats.scala:106) with 2 output partitions
18/04/01 20:15:41 INFO DAGScheduler: Final stage: ResultStage 79 (foreachPartition at RefereeStats.scala:106)
18/04/01 20:15:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 78)
18/04/01 20:15:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 78)
18/04/01 20:15:41 INFO DAGScheduler: Submitting ShuffleMapStage 78 (MapPartitionsRDD[68] at map at RefereeStats.scala:39), which has no missing parents
18/04/01 20:15:41 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:15:41 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:15:41 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:41 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:41 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 78 (MapPartitionsRDD[68] at map at RefereeStats.scala:39) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:41 INFO TaskSchedulerImpl: Adding task set 78.0 with 5 tasks
18/04/01 20:15:41 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 253, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:41 INFO TaskSetManager: Starting task 1.0 in stage 78.0 (TID 254, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:41 INFO Executor: Running task 0.0 in stage 78.0 (TID 253)
18/04/01 20:15:41 INFO Executor: Running task 1.0 in stage 78.0 (TID 254)
18/04/01 20:15:41 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:41 INFO Executor: Finished task 0.0 in stage 78.0 (TID 253). 938 bytes result sent to driver
18/04/01 20:15:41 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:41 INFO TaskSetManager: Starting task 2.0 in stage 78.0 (TID 255, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:41 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 253) in 8 ms on localhost (executor driver) (1/5)
18/04/01 20:15:41 INFO Executor: Finished task 1.0 in stage 78.0 (TID 254). 938 bytes result sent to driver
18/04/01 20:15:41 INFO Executor: Running task 2.0 in stage 78.0 (TID 255)
18/04/01 20:15:41 INFO TaskSetManager: Starting task 3.0 in stage 78.0 (TID 256, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:41 INFO TaskSetManager: Finished task 1.0 in stage 78.0 (TID 254) in 10 ms on localhost (executor driver) (2/5)
18/04/01 20:15:41 INFO Executor: Running task 3.0 in stage 78.0 (TID 256)
18/04/01 20:15:41 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:41 INFO Executor: Finished task 2.0 in stage 78.0 (TID 255). 938 bytes result sent to driver
18/04/01 20:15:41 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:41 INFO TaskSetManager: Starting task 4.0 in stage 78.0 (TID 257, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:41 INFO TaskSetManager: Finished task 2.0 in stage 78.0 (TID 255) in 13 ms on localhost (executor driver) (3/5)
18/04/01 20:15:41 INFO Executor: Running task 4.0 in stage 78.0 (TID 257)
18/04/01 20:15:41 INFO Executor: Finished task 3.0 in stage 78.0 (TID 256). 938 bytes result sent to driver
18/04/01 20:15:41 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 715 -> 718
18/04/01 20:15:41 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 715
18/04/01 20:15:41 INFO TaskSetManager: Finished task 3.0 in stage 78.0 (TID 256) in 16 ms on localhost (executor driver) (4/5)
18/04/01 20:15:41 INFO Executor: Finished task 4.0 in stage 78.0 (TID 257). 1024 bytes result sent to driver
18/04/01 20:15:41 INFO TaskSetManager: Finished task 4.0 in stage 78.0 (TID 257) in 403 ms on localhost (executor driver) (5/5)
18/04/01 20:15:41 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
18/04/01 20:15:41 INFO DAGScheduler: ShuffleMapStage 78 (map at RefereeStats.scala:39) finished in 0.433 s
18/04/01 20:15:41 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:41 INFO DAGScheduler: running: Set()
18/04/01 20:15:41 INFO DAGScheduler: waiting: Set(ResultStage 79)
18/04/01 20:15:41 INFO DAGScheduler: failed: Set()
18/04/01 20:15:41 INFO DAGScheduler: Submitting ResultStage 79 (ShuffledRDD[69] at reduceByKey at RefereeStats.scala:43), which has no missing parents
18/04/01 20:15:41 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:15:41 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 1704.0 B, free 477.2 MB)
18/04/01 20:15:41 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 192.168.1.3:35449 (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:15:41 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:41 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 79 (ShuffledRDD[69] at reduceByKey at RefereeStats.scala:43) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:41 INFO TaskSchedulerImpl: Adding task set 79.0 with 2 tasks
18/04/01 20:15:41 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 258, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:15:41 INFO TaskSetManager: Starting task 1.0 in stage 79.0 (TID 259, localhost, executor driver, partition 1, ANY, 7649 bytes)
18/04/01 20:15:41 INFO Executor: Running task 0.0 in stage 79.0 (TID 258)
18/04/01 20:15:41 INFO Executor: Running task 1.0 in stage 79.0 (TID 259)
18/04/01 20:15:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:15:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:15:41 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:41 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:41 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:41 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:41 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:41 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:41 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:41 INFO KafkaProducer: [Producer clientId=producer-60] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:41 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:41 INFO KafkaProducer: [Producer clientId=producer-59] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:41 INFO Executor: Finished task 0.0 in stage 79.0 (TID 258). 1138 bytes result sent to driver
18/04/01 20:15:41 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 258) in 46 ms on localhost (executor driver) (1/2)
18/04/01 20:15:41 INFO Executor: Finished task 1.0 in stage 79.0 (TID 259). 1138 bytes result sent to driver
18/04/01 20:15:41 INFO TaskSetManager: Finished task 1.0 in stage 79.0 (TID 259) in 53 ms on localhost (executor driver) (2/2)
18/04/01 20:15:41 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
18/04/01 20:15:41 INFO DAGScheduler: ResultStage 79 (foreachPartition at RefereeStats.scala:106) finished in 0.068 s
18/04/01 20:15:41 INFO DAGScheduler: Job 49 finished: foreachPartition at RefereeStats.scala:106, took 0.512218 s
18/04/01 20:15:41 INFO JobScheduler: Finished job streaming job 1522602940000 ms.3 from job set of time 1522602940000 ms
18/04/01 20:15:41 INFO JobScheduler: Total delay: 1.722 s for time 1522602940000 ms (execution: 1.693 s)
18/04/01 20:15:41 INFO MapPartitionsRDD: Removing RDD 57 from persistence list
18/04/01 20:15:41 INFO BlockManager: Removing RDD 57
18/04/01 20:15:41 INFO KafkaRDD: Removing RDD 56 from persistence list
18/04/01 20:15:41 INFO BlockManager: Removing RDD 56
18/04/01 20:15:41 INFO ShuffledRDD: Removing RDD 58 from persistence list
18/04/01 20:15:41 INFO BlockManager: Removing RDD 58
18/04/01 20:15:41 INFO ShuffledRDD: Removing RDD 60 from persistence list
18/04/01 20:15:41 INFO BlockManager: Removing RDD 60
18/04/01 20:15:41 INFO MapPartitionsRDD: Removing RDD 59 from persistence list
18/04/01 20:15:41 INFO BlockManager: Removing RDD 59
18/04/01 20:15:41 INFO ShuffledRDD: Removing RDD 62 from persistence list
18/04/01 20:15:41 INFO BlockManager: Removing RDD 62
18/04/01 20:15:41 INFO MapPartitionsRDD: Removing RDD 61 from persistence list
18/04/01 20:15:41 INFO BlockManager: Removing RDD 61
18/04/01 20:15:41 INFO JobGenerator: Checkpointing graph for time 1522602940000 ms
18/04/01 20:15:41 INFO DStreamGraph: Updating checkpoint data for time 1522602940000 ms
18/04/01 20:15:41 INFO DStreamGraph: Updated checkpoint data for time 1522602940000 ms
18/04/01 20:15:41 INFO CheckpointWriter: Submitted checkpoint of time 1522602940000 ms to writer queue
18/04/01 20:15:41 INFO CheckpointWriter: Saving checkpoint for time 1522602940000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602940000'
18/04/01 20:15:41 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602915000
18/04/01 20:15:41 INFO CheckpointWriter: Checkpoint for time 1522602940000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602940000', took 5537 bytes and 34 ms
18/04/01 20:15:41 INFO DStreamGraph: Clearing checkpoint data for time 1522602940000 ms
18/04/01 20:15:41 INFO DStreamGraph: Cleared checkpoint data for time 1522602940000 ms
18/04/01 20:15:41 INFO ReceivedBlockTracker: Deleting batches: 
18/04/01 20:15:41 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/tmp/refs-xyzabb/receivedBlockMetadata older than 1522602935000: 
18/04/01 20:15:41 INFO InputInfoTracker: remove old batch metadata: 1522602930000 ms
18/04/01 20:15:45 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-0 to offset 719.
18/04/01 20:15:45 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-3 to offset 0.
18/04/01 20:15:45 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-4 to offset 0.
18/04/01 20:15:45 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-1 to offset 0.
18/04/01 20:15:45 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-2 to offset 0.
18/04/01 20:15:45 INFO JobScheduler: Added jobs for time 1522602945000 ms
18/04/01 20:15:45 INFO JobGenerator: Checkpointing graph for time 1522602945000 ms
18/04/01 20:15:45 INFO DStreamGraph: Updating checkpoint data for time 1522602945000 ms
18/04/01 20:15:45 INFO JobScheduler: Starting job streaming job 1522602945000 ms.0 from job set of time 1522602945000 ms
18/04/01 20:15:45 INFO DStreamGraph: Updated checkpoint data for time 1522602945000 ms
18/04/01 20:15:45 INFO CheckpointWriter: Submitted checkpoint of time 1522602945000 ms to writer queue
18/04/01 20:15:45 INFO CheckpointWriter: Saving checkpoint for time 1522602945000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602945000'
18/04/01 20:15:45 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:15:45 INFO DAGScheduler: Got job 50 (print at RefereeStats.scala:67) with 1 output partitions
18/04/01 20:15:45 INFO DAGScheduler: Final stage: ResultStage 80 (print at RefereeStats.scala:67)
18/04/01 20:15:45 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:15:45 INFO DAGScheduler: Missing parents: List()
18/04/01 20:15:45 INFO DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[71] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:45 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 3.0 KB, free 477.2 MB)
18/04/01 20:15:45 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602920000.bk
18/04/01 20:15:45 INFO CheckpointWriter: Checkpoint for time 1522602945000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602945000', took 5593 bytes and 31 ms
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1814
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1655
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1939
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1800
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1944
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1672
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1793
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1967
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1668
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1975
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1730
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1779
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1810
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1920
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1843
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1972
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1700
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1742
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1996
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1970
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1956
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1707
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1891
18/04/01 20:15:45 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.2 MB)
18/04/01 20:15:45 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 192.168.1.3:35449 in memory (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:15:45 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1826
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1942
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1750
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1899
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1695
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1706
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1954
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1773
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1851
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1650
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1860
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1660
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1715
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1994
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1909
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1674
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1919
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1890
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1828
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1815
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1895
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1759
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1806
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1789
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1835
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1995
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1943
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1735
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1697
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1745
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1787
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1812
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1652
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1987
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1767
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1804
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1667
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1973
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1882
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1915
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1902
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1774
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1856
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1616
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1799
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1884
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1978
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1604
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1952
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1916
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1827
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1613
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1960
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1654
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1728
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1620
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1908
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1704
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1719
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1658
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1946
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1662
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1621
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1670
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1966
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1802
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1761
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1635
18/04/01 20:15:45 INFO ContextCleaner: Cleaned shuffle 24
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1685
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1771
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1993
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1990
18/04/01 20:15:45 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 80 (MapPartitionsRDD[71] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0))
18/04/01 20:15:45 INFO TaskSchedulerImpl: Adding task set 80.0 with 1 tasks
18/04/01 20:15:45 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1912
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1869
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1625
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1736
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1659
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1720
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1901
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1947
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1714
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1883
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1770
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1642
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1825
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1614
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1914
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1897
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1969
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1794
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1744
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1721
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1893
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1991
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1689
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1611
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1644
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1649
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1880
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1957
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1778
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1889
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1961
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1747
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1727
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1783
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1832
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1743
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1988
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1983
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1999
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1964
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1666
18/04/01 20:15:45 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 260, localhost, executor driver, partition 0, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:45 INFO Executor: Running task 0.0 in stage 80.0 (TID 260)
18/04/01 20:15:45 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 192.168.1.3:35449 in memory (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1834
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1866
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1830
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1847
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1855
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1740
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1974
18/04/01 20:15:45 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:45 INFO Executor: Finished task 0.0 in stage 80.0 (TID 260). 704 bytes result sent to driver
18/04/01 20:15:45 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:45 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 260) in 7 ms on localhost (executor driver) (1/1)
18/04/01 20:15:45 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
18/04/01 20:15:45 INFO DAGScheduler: ResultStage 80 (print at RefereeStats.scala:67) finished in 0.037 s
18/04/01 20:15:45 INFO DAGScheduler: Job 50 finished: print at RefereeStats.scala:67, took 0.041872 s
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1853
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1755
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1738
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1896
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1624
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1607
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1716
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1723
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1633
18/04/01 20:15:45 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 192.168.1.3:35449 in memory (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1726
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1979
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1776
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1881
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1963
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1965
18/04/01 20:15:45 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 192.168.1.3:35449 in memory (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:15:45 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1731
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1953
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1821
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1657
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1998
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1863
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1933
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1858
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1817
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1708
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1702
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1605
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1930
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1601
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1809
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1615
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1711
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1980
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1643
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1603
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1985
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1690
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1922
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1905
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1910
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1734
18/04/01 20:15:45 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1688
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1629
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1634
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1873
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1911
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1898
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1790
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1610
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1680
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1693
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1746
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1926
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1698
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1940
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1854
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1839
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1927
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1976
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1797
18/04/01 20:15:45 INFO ContextCleaner: Cleaned shuffle 25
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1733
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1968
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1887
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1923
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1608
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1900
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1906
18/04/01 20:15:45 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:15:45 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1764
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1907
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1701
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1602
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1981
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1671
18/04/01 20:15:45 INFO DAGScheduler: Got job 51 (print at RefereeStats.scala:67) with 4 output partitions
18/04/01 20:15:45 INFO DAGScheduler: Final stage: ResultStage 81 (print at RefereeStats.scala:67)
18/04/01 20:15:45 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:15:45 INFO DAGScheduler: Missing parents: List()
18/04/01 20:15:45 INFO DAGScheduler: Submitting ResultStage 81 (MapPartitionsRDD[71] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:45 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1762
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1864
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1816
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1924
18/04/01 20:15:45 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 192.168.1.3:35449 in memory (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1848
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1786
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1785
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1753
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1673
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1618
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1675
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1841
18/04/01 20:15:45 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 3.0 KB, free 477.2 MB)
18/04/01 20:15:45 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1876
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1941
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1637
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1929
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1811
18/04/01 20:15:45 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.2 MB)
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1769
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1760
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1886
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1917
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1636
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1951
18/04/01 20:15:45 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:45 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:45 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:45 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 81 (MapPartitionsRDD[71] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
18/04/01 20:15:45 INFO TaskSchedulerImpl: Adding task set 81.0 with 4 tasks
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1936
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1656
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1725
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1729
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1938
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1833
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1717
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1852
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1829
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1820
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1754
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1874
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1640
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1837
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1962
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1772
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1653
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1749
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1768
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1798
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1949
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1646
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1903
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1932
18/04/01 20:15:45 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 261, localhost, executor driver, partition 1, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:45 INFO TaskSetManager: Starting task 1.0 in stage 81.0 (TID 262, localhost, executor driver, partition 2, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:45 INFO Executor: Running task 0.0 in stage 81.0 (TID 261)
18/04/01 20:15:45 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:45 INFO Executor: Finished task 0.0 in stage 81.0 (TID 261). 704 bytes result sent to driver
18/04/01 20:15:45 INFO Executor: Running task 1.0 in stage 81.0 (TID 262)
18/04/01 20:15:45 INFO TaskSetManager: Starting task 2.0 in stage 81.0 (TID 263, localhost, executor driver, partition 3, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:45 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:45 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 261) in 9 ms on localhost (executor driver) (1/4)
18/04/01 20:15:45 INFO Executor: Finished task 1.0 in stage 81.0 (TID 262). 704 bytes result sent to driver
18/04/01 20:15:45 INFO Executor: Running task 2.0 in stage 81.0 (TID 263)
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1959
18/04/01 20:15:45 INFO TaskSetManager: Finished task 1.0 in stage 81.0 (TID 262) in 11 ms on localhost (executor driver) (2/4)
18/04/01 20:15:45 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1622
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1872
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1752
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1631
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1857
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1756
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1870
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1888
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1865
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1751
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1885
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1918
18/04/01 20:15:45 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:45 INFO TaskSetManager: Starting task 3.0 in stage 81.0 (TID 264, localhost, executor driver, partition 4, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1781
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1934
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1782
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1663
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1868
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1958
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1862
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1748
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1678
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1877
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1838
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1664
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1950
18/04/01 20:15:45 INFO Executor: Finished task 2.0 in stage 81.0 (TID 263). 704 bytes result sent to driver
18/04/01 20:15:45 INFO Executor: Running task 3.0 in stage 81.0 (TID 264)
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1805
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1628
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1665
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1836
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1758
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1617
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1737
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1796
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1921
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1844
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1879
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1935
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1686
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1807
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1925
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1766
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1648
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1699
18/04/01 20:15:45 INFO TaskSetManager: Finished task 2.0 in stage 81.0 (TID 263) in 11 ms on localhost (executor driver) (3/4)
18/04/01 20:15:45 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 192.168.1.3:35449 in memory (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1741
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1679
18/04/01 20:15:45 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1931
18/04/01 20:15:45 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 718 -> 719
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1684
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1691
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1724
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1791
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1859
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1718
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1682
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1792
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1757
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1822
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1992
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1850
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1669
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1651
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1997
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1677
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1831
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1801
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1823
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1955
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1683
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1984
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1645
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1777
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1867
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1948
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1819
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1600
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1795
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1630
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1647
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1928
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1676
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1803
18/04/01 20:15:45 INFO ContextCleaner: Cleaned shuffle 21
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1687
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1808
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1861
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1606
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1982
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1892
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1849
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1712
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1986
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1813
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1824
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1780
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1977
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1709
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1681
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1784
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1845
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1705
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1632
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1775
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1722
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1878
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1846
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1641
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1875
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1619
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1894
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1713
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1609
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1763
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1945
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1818
18/04/01 20:15:45 INFO ContextCleaner: Cleaned shuffle 26
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1765
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1788
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1904
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1937
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1638
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1703
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1913
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1989
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1692
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1739
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1871
18/04/01 20:15:45 INFO Executor: Finished task 3.0 in stage 81.0 (TID 264). 867 bytes result sent to driver
18/04/01 20:15:45 INFO ContextCleaner: Cleaned shuffle 23
18/04/01 20:15:45 INFO TaskSetManager: Finished task 3.0 in stage 81.0 (TID 264) in 21 ms on localhost (executor driver) (4/4)
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1626
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1840
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1639
18/04/01 20:15:45 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
18/04/01 20:15:45 INFO DAGScheduler: ResultStage 81 (print at RefereeStats.scala:67) finished in 0.046 s
18/04/01 20:15:45 INFO DAGScheduler: Job 51 finished: print at RefereeStats.scala:67, took 0.057514 s
18/04/01 20:15:45 INFO JobScheduler: Finished job streaming job 1522602945000 ms.0 from job set of time 1522602945000 ms
18/04/01 20:15:45 INFO JobScheduler: Starting job streaming job 1522602945000 ms.1 from job set of time 1522602945000 ms
-------------------------------------------
Time: 1522602945000 ms
-------------------------------------------
(nextanalytics.com,8000)

18/04/01 20:15:45 INFO ContextCleaner: Cleaned shuffle 22
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1842
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1661
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1732
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1623
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1694
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1710
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1612
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1627
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1696
18/04/01 20:15:45 INFO ContextCleaner: Cleaned accumulator 1971
18/04/01 20:15:45 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:71
18/04/01 20:15:45 INFO DAGScheduler: Registering RDD 71 (map at RefereeStats.scala:53)
18/04/01 20:15:45 INFO DAGScheduler: Got job 52 (foreachPartition at RefereeStats.scala:71) with 2 output partitions
18/04/01 20:15:45 INFO DAGScheduler: Final stage: ResultStage 83 (foreachPartition at RefereeStats.scala:71)
18/04/01 20:15:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 82)
18/04/01 20:15:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 82)
18/04/01 20:15:45 INFO DAGScheduler: Submitting ShuffleMapStage 82 (MapPartitionsRDD[71] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:45 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 3.9 KB, free 477.3 MB)
18/04/01 20:15:45 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.3 MB)
18/04/01 20:15:45 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:45 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:45 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 82 (MapPartitionsRDD[71] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:45 INFO TaskSchedulerImpl: Adding task set 82.0 with 5 tasks
18/04/01 20:15:45 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 265, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:45 INFO TaskSetManager: Starting task 1.0 in stage 82.0 (TID 266, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:45 INFO Executor: Running task 1.0 in stage 82.0 (TID 266)
18/04/01 20:15:45 INFO Executor: Running task 0.0 in stage 82.0 (TID 265)
18/04/01 20:15:45 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:45 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:45 INFO Executor: Finished task 1.0 in stage 82.0 (TID 266). 938 bytes result sent to driver
18/04/01 20:15:45 INFO TaskSetManager: Starting task 2.0 in stage 82.0 (TID 267, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:45 INFO Executor: Running task 2.0 in stage 82.0 (TID 267)
18/04/01 20:15:45 INFO TaskSetManager: Finished task 1.0 in stage 82.0 (TID 266) in 10 ms on localhost (executor driver) (1/5)
18/04/01 20:15:45 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:45 INFO Executor: Finished task 2.0 in stage 82.0 (TID 267). 938 bytes result sent to driver
18/04/01 20:15:45 INFO TaskSetManager: Starting task 3.0 in stage 82.0 (TID 268, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:45 INFO TaskSetManager: Finished task 2.0 in stage 82.0 (TID 267) in 8 ms on localhost (executor driver) (2/5)
18/04/01 20:15:45 INFO Executor: Running task 3.0 in stage 82.0 (TID 268)
18/04/01 20:15:45 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:45 INFO Executor: Finished task 3.0 in stage 82.0 (TID 268). 981 bytes result sent to driver
18/04/01 20:15:45 INFO TaskSetManager: Starting task 4.0 in stage 82.0 (TID 269, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:45 INFO TaskSetManager: Finished task 3.0 in stage 82.0 (TID 268) in 7 ms on localhost (executor driver) (3/5)
18/04/01 20:15:45 INFO Executor: Running task 4.0 in stage 82.0 (TID 269)
18/04/01 20:15:45 INFO Executor: Finished task 0.0 in stage 82.0 (TID 265). 938 bytes result sent to driver
18/04/01 20:15:45 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 265) in 29 ms on localhost (executor driver) (4/5)
18/04/01 20:15:45 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 718 -> 719
18/04/01 20:15:45 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 718
18/04/01 20:15:45 INFO Executor: Finished task 4.0 in stage 82.0 (TID 269). 1024 bytes result sent to driver
18/04/01 20:15:45 INFO TaskSetManager: Finished task 4.0 in stage 82.0 (TID 269) in 329 ms on localhost (executor driver) (5/5)
18/04/01 20:15:45 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool 
18/04/01 20:15:45 INFO DAGScheduler: ShuffleMapStage 82 (map at RefereeStats.scala:53) finished in 0.364 s
18/04/01 20:15:45 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:45 INFO DAGScheduler: running: Set()
18/04/01 20:15:45 INFO DAGScheduler: waiting: Set(ResultStage 83)
18/04/01 20:15:45 INFO DAGScheduler: failed: Set()
18/04/01 20:15:45 INFO DAGScheduler: Submitting ResultStage 83 (ShuffledRDD[72] at reduceByKey at RefereeStats.scala:60), which has no missing parents
18/04/01 20:15:45 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 2.8 KB, free 477.3 MB)
18/04/01 20:15:45 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 1706.0 B, free 477.3 MB)
18/04/01 20:15:45 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 192.168.1.3:35449 (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:15:45 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 83 (ShuffledRDD[72] at reduceByKey at RefereeStats.scala:60) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:45 INFO TaskSchedulerImpl: Adding task set 83.0 with 2 tasks
18/04/01 20:15:45 INFO TaskSetManager: Starting task 1.0 in stage 83.0 (TID 270, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:15:45 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 271, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:15:45 INFO Executor: Running task 0.0 in stage 83.0 (TID 271)
18/04/01 20:15:45 INFO Executor: Running task 1.0 in stage 83.0 (TID 270)
18/04/01 20:15:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:15:45 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:45 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:15:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:45 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:45 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:45 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:45 INFO KafkaProducer: [Producer clientId=producer-62] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:45 INFO Executor: Finished task 1.0 in stage 83.0 (TID 270). 1138 bytes result sent to driver
18/04/01 20:15:45 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:45 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:45 INFO TaskSetManager: Finished task 1.0 in stage 83.0 (TID 270) in 18 ms on localhost (executor driver) (1/2)
18/04/01 20:15:45 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:45 INFO KafkaProducer: [Producer clientId=producer-61] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:45 INFO Executor: Finished task 0.0 in stage 83.0 (TID 271). 1138 bytes result sent to driver
18/04/01 20:15:45 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 271) in 38 ms on localhost (executor driver) (2/2)
18/04/01 20:15:45 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool 
18/04/01 20:15:45 INFO DAGScheduler: ResultStage 83 (foreachPartition at RefereeStats.scala:71) finished in 0.048 s
18/04/01 20:15:45 INFO DAGScheduler: Job 52 finished: foreachPartition at RefereeStats.scala:71, took 0.422942 s
18/04/01 20:15:45 INFO JobScheduler: Finished job streaming job 1522602945000 ms.1 from job set of time 1522602945000 ms
18/04/01 20:15:45 INFO JobScheduler: Starting job streaming job 1522602945000 ms.2 from job set of time 1522602945000 ms
18/04/01 20:15:45 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:89
18/04/01 20:15:45 INFO DAGScheduler: Registering RDD 73 (map at RefereeStats.scala:46)
18/04/01 20:15:45 INFO DAGScheduler: Got job 53 (foreachPartition at RefereeStats.scala:89) with 2 output partitions
18/04/01 20:15:45 INFO DAGScheduler: Final stage: ResultStage 85 (foreachPartition at RefereeStats.scala:89)
18/04/01 20:15:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 84)
18/04/01 20:15:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 84)
18/04/01 20:15:45 INFO DAGScheduler: Submitting ShuffleMapStage 84 (MapPartitionsRDD[73] at map at RefereeStats.scala:46), which has no missing parents
18/04/01 20:15:45 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 3.9 KB, free 477.3 MB)
18/04/01 20:15:45 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.3 MB)
18/04/01 20:15:45 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:45 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:45 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 84 (MapPartitionsRDD[73] at map at RefereeStats.scala:46) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:45 INFO TaskSchedulerImpl: Adding task set 84.0 with 5 tasks
18/04/01 20:15:45 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 272, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:45 INFO TaskSetManager: Starting task 1.0 in stage 84.0 (TID 273, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:45 INFO Executor: Running task 0.0 in stage 84.0 (TID 272)
18/04/01 20:15:45 INFO Executor: Running task 1.0 in stage 84.0 (TID 273)
18/04/01 20:15:45 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:45 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:45 INFO Executor: Finished task 1.0 in stage 84.0 (TID 273). 938 bytes result sent to driver
18/04/01 20:15:45 INFO Executor: Finished task 0.0 in stage 84.0 (TID 272). 938 bytes result sent to driver
18/04/01 20:15:45 INFO TaskSetManager: Starting task 2.0 in stage 84.0 (TID 274, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:45 INFO Executor: Running task 2.0 in stage 84.0 (TID 274)
18/04/01 20:15:45 INFO TaskSetManager: Starting task 3.0 in stage 84.0 (TID 275, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:45 INFO TaskSetManager: Finished task 1.0 in stage 84.0 (TID 273) in 9 ms on localhost (executor driver) (1/5)
18/04/01 20:15:45 INFO Executor: Running task 3.0 in stage 84.0 (TID 275)
18/04/01 20:15:45 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 272) in 10 ms on localhost (executor driver) (2/5)
18/04/01 20:15:45 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:45 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:45 INFO Executor: Finished task 2.0 in stage 84.0 (TID 274). 938 bytes result sent to driver
18/04/01 20:15:45 INFO TaskSetManager: Starting task 4.0 in stage 84.0 (TID 276, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:45 INFO Executor: Running task 4.0 in stage 84.0 (TID 276)
18/04/01 20:15:45 INFO TaskSetManager: Finished task 2.0 in stage 84.0 (TID 274) in 11 ms on localhost (executor driver) (3/5)
18/04/01 20:15:45 INFO Executor: Finished task 3.0 in stage 84.0 (TID 275). 938 bytes result sent to driver
18/04/01 20:15:45 INFO TaskSetManager: Finished task 3.0 in stage 84.0 (TID 275) in 12 ms on localhost (executor driver) (4/5)
18/04/01 20:15:45 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 718 -> 719
18/04/01 20:15:45 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 718
18/04/01 20:15:46 INFO Executor: Finished task 4.0 in stage 84.0 (TID 276). 1067 bytes result sent to driver
18/04/01 20:15:46 INFO TaskSetManager: Finished task 4.0 in stage 84.0 (TID 276) in 404 ms on localhost (executor driver) (5/5)
18/04/01 20:15:46 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
18/04/01 20:15:46 INFO DAGScheduler: ShuffleMapStage 84 (map at RefereeStats.scala:46) finished in 0.434 s
18/04/01 20:15:46 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:46 INFO DAGScheduler: running: Set()
18/04/01 20:15:46 INFO DAGScheduler: waiting: Set(ResultStage 85)
18/04/01 20:15:46 INFO DAGScheduler: failed: Set()
18/04/01 20:15:46 INFO DAGScheduler: Submitting ResultStage 85 (ShuffledRDD[74] at reduceByKey at RefereeStats.scala:51), which has no missing parents
18/04/01 20:15:46 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:15:46 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 1709.0 B, free 477.2 MB)
18/04/01 20:15:46 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 192.168.1.3:35449 (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:15:46 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 85 (ShuffledRDD[74] at reduceByKey at RefereeStats.scala:51) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:46 INFO TaskSchedulerImpl: Adding task set 85.0 with 2 tasks
18/04/01 20:15:46 INFO TaskSetManager: Starting task 1.0 in stage 85.0 (TID 277, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:15:46 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 278, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:15:46 INFO Executor: Running task 1.0 in stage 85.0 (TID 277)
18/04/01 20:15:46 INFO Executor: Running task 0.0 in stage 85.0 (TID 278)
18/04/01 20:15:46 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:15:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:15:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:15:46 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:46 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:46 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:46 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:46 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:46 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:46 INFO KafkaProducer: [Producer clientId=producer-63] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:46 INFO Executor: Finished task 1.0 in stage 85.0 (TID 277). 1138 bytes result sent to driver
18/04/01 20:15:46 INFO TaskSetManager: Finished task 1.0 in stage 85.0 (TID 277) in 23 ms on localhost (executor driver) (1/2)
18/04/01 20:15:46 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:46 INFO KafkaProducer: [Producer clientId=producer-64] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:46 INFO Executor: Finished task 0.0 in stage 85.0 (TID 278). 1138 bytes result sent to driver
18/04/01 20:15:46 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 278) in 39 ms on localhost (executor driver) (2/2)
18/04/01 20:15:46 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool 
18/04/01 20:15:46 INFO DAGScheduler: ResultStage 85 (foreachPartition at RefereeStats.scala:89) finished in 0.050 s
18/04/01 20:15:46 INFO DAGScheduler: Job 53 finished: foreachPartition at RefereeStats.scala:89, took 0.493024 s
18/04/01 20:15:46 INFO JobScheduler: Finished job streaming job 1522602945000 ms.2 from job set of time 1522602945000 ms
18/04/01 20:15:46 INFO JobScheduler: Starting job streaming job 1522602945000 ms.3 from job set of time 1522602945000 ms
18/04/01 20:15:46 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:106
18/04/01 20:15:46 INFO DAGScheduler: Registering RDD 75 (map at RefereeStats.scala:39)
18/04/01 20:15:46 INFO DAGScheduler: Got job 54 (foreachPartition at RefereeStats.scala:106) with 2 output partitions
18/04/01 20:15:46 INFO DAGScheduler: Final stage: ResultStage 87 (foreachPartition at RefereeStats.scala:106)
18/04/01 20:15:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 86)
18/04/01 20:15:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 86)
18/04/01 20:15:46 INFO DAGScheduler: Submitting ShuffleMapStage 86 (MapPartitionsRDD[75] at map at RefereeStats.scala:39), which has no missing parents
18/04/01 20:15:46 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:15:46 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:15:46 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:46 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:46 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 86 (MapPartitionsRDD[75] at map at RefereeStats.scala:39) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:46 INFO TaskSchedulerImpl: Adding task set 86.0 with 5 tasks
18/04/01 20:15:46 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 279, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:46 INFO TaskSetManager: Starting task 1.0 in stage 86.0 (TID 280, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:46 INFO Executor: Running task 1.0 in stage 86.0 (TID 280)
18/04/01 20:15:46 INFO Executor: Running task 0.0 in stage 86.0 (TID 279)
18/04/01 20:15:46 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:46 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:46 INFO Executor: Finished task 0.0 in stage 86.0 (TID 279). 938 bytes result sent to driver
18/04/01 20:15:46 INFO TaskSetManager: Starting task 2.0 in stage 86.0 (TID 281, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:46 INFO Executor: Running task 2.0 in stage 86.0 (TID 281)
18/04/01 20:15:46 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 279) in 15 ms on localhost (executor driver) (1/5)
18/04/01 20:15:46 INFO Executor: Finished task 1.0 in stage 86.0 (TID 280). 981 bytes result sent to driver
18/04/01 20:15:46 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:46 INFO Executor: Finished task 2.0 in stage 86.0 (TID 281). 938 bytes result sent to driver
18/04/01 20:15:46 INFO TaskSetManager: Starting task 3.0 in stage 86.0 (TID 282, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:46 INFO TaskSetManager: Finished task 2.0 in stage 86.0 (TID 281) in 9 ms on localhost (executor driver) (2/5)
18/04/01 20:15:46 INFO Executor: Running task 3.0 in stage 86.0 (TID 282)
18/04/01 20:15:46 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:46 INFO TaskSetManager: Starting task 4.0 in stage 86.0 (TID 283, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:46 INFO TaskSetManager: Finished task 1.0 in stage 86.0 (TID 280) in 31 ms on localhost (executor driver) (3/5)
18/04/01 20:15:46 INFO Executor: Running task 4.0 in stage 86.0 (TID 283)
18/04/01 20:15:46 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 718 -> 719
18/04/01 20:15:46 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 718
18/04/01 20:15:46 INFO Executor: Finished task 3.0 in stage 86.0 (TID 282). 938 bytes result sent to driver
18/04/01 20:15:46 INFO TaskSetManager: Finished task 3.0 in stage 86.0 (TID 282) in 20 ms on localhost (executor driver) (4/5)
18/04/01 20:15:46 INFO Executor: Finished task 4.0 in stage 86.0 (TID 283). 1024 bytes result sent to driver
18/04/01 20:15:46 INFO TaskSetManager: Finished task 4.0 in stage 86.0 (TID 283) in 391 ms on localhost (executor driver) (5/5)
18/04/01 20:15:46 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool 
18/04/01 20:15:46 INFO DAGScheduler: ShuffleMapStage 86 (map at RefereeStats.scala:39) finished in 0.433 s
18/04/01 20:15:46 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:46 INFO DAGScheduler: running: Set()
18/04/01 20:15:46 INFO DAGScheduler: waiting: Set(ResultStage 87)
18/04/01 20:15:46 INFO DAGScheduler: failed: Set()
18/04/01 20:15:46 INFO DAGScheduler: Submitting ResultStage 87 (ShuffledRDD[76] at reduceByKey at RefereeStats.scala:43), which has no missing parents
18/04/01 20:15:46 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:15:46 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 1704.0 B, free 477.2 MB)
18/04/01 20:15:46 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 192.168.1.3:35449 (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:15:46 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 87 (ShuffledRDD[76] at reduceByKey at RefereeStats.scala:43) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:46 INFO TaskSchedulerImpl: Adding task set 87.0 with 2 tasks
18/04/01 20:15:46 INFO TaskSetManager: Starting task 1.0 in stage 87.0 (TID 284, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:15:46 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 285, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:15:46 INFO Executor: Running task 0.0 in stage 87.0 (TID 285)
18/04/01 20:15:46 INFO Executor: Running task 1.0 in stage 87.0 (TID 284)
18/04/01 20:15:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:46 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:15:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:46 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:46 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:46 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:46 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:46 INFO KafkaProducer: [Producer clientId=producer-65] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:46 INFO Executor: Finished task 1.0 in stage 87.0 (TID 284). 1138 bytes result sent to driver
18/04/01 20:15:46 INFO TaskSetManager: Finished task 1.0 in stage 87.0 (TID 284) in 19 ms on localhost (executor driver) (1/2)
18/04/01 20:15:46 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:46 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:46 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:46 INFO KafkaProducer: [Producer clientId=producer-66] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:46 INFO Executor: Finished task 0.0 in stage 87.0 (TID 285). 1138 bytes result sent to driver
18/04/01 20:15:46 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 285) in 34 ms on localhost (executor driver) (2/2)
18/04/01 20:15:46 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool 
18/04/01 20:15:46 INFO DAGScheduler: ResultStage 87 (foreachPartition at RefereeStats.scala:106) finished in 0.044 s
18/04/01 20:15:46 INFO DAGScheduler: Job 54 finished: foreachPartition at RefereeStats.scala:106, took 0.487951 s
18/04/01 20:15:46 INFO JobScheduler: Finished job streaming job 1522602945000 ms.3 from job set of time 1522602945000 ms
18/04/01 20:15:46 INFO JobScheduler: Total delay: 1.612 s for time 1522602945000 ms (execution: 1.582 s)
18/04/01 20:15:46 INFO MapPartitionsRDD: Removing RDD 64 from persistence list
18/04/01 20:15:46 INFO BlockManager: Removing RDD 64
18/04/01 20:15:46 INFO KafkaRDD: Removing RDD 63 from persistence list
18/04/01 20:15:46 INFO BlockManager: Removing RDD 63
18/04/01 20:15:46 INFO ShuffledRDD: Removing RDD 65 from persistence list
18/04/01 20:15:46 INFO BlockManager: Removing RDD 65
18/04/01 20:15:46 INFO ShuffledRDD: Removing RDD 67 from persistence list
18/04/01 20:15:46 INFO BlockManager: Removing RDD 67
18/04/01 20:15:46 INFO MapPartitionsRDD: Removing RDD 66 from persistence list
18/04/01 20:15:46 INFO BlockManager: Removing RDD 66
18/04/01 20:15:46 INFO ShuffledRDD: Removing RDD 69 from persistence list
18/04/01 20:15:46 INFO BlockManager: Removing RDD 69
18/04/01 20:15:46 INFO MapPartitionsRDD: Removing RDD 68 from persistence list
18/04/01 20:15:46 INFO BlockManager: Removing RDD 68
18/04/01 20:15:46 INFO JobGenerator: Checkpointing graph for time 1522602945000 ms
18/04/01 20:15:46 INFO DStreamGraph: Updating checkpoint data for time 1522602945000 ms
18/04/01 20:15:46 INFO DStreamGraph: Updated checkpoint data for time 1522602945000 ms
18/04/01 20:15:46 INFO CheckpointWriter: Submitted checkpoint of time 1522602945000 ms to writer queue
18/04/01 20:15:46 INFO CheckpointWriter: Saving checkpoint for time 1522602945000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602945000'
18/04/01 20:15:46 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602920000
18/04/01 20:15:46 INFO CheckpointWriter: Checkpoint for time 1522602945000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602945000', took 5537 bytes and 21 ms
18/04/01 20:15:46 INFO DStreamGraph: Clearing checkpoint data for time 1522602945000 ms
18/04/01 20:15:46 INFO DStreamGraph: Cleared checkpoint data for time 1522602945000 ms
18/04/01 20:15:46 INFO ReceivedBlockTracker: Deleting batches: 
18/04/01 20:15:46 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/tmp/refs-xyzabb/receivedBlockMetadata older than 1522602940000: 
18/04/01 20:15:46 INFO InputInfoTracker: remove old batch metadata: 1522602935000 ms
18/04/01 20:15:50 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-0 to offset 721.
18/04/01 20:15:50 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-3 to offset 0.
18/04/01 20:15:50 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-4 to offset 0.
18/04/01 20:15:50 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-1 to offset 0.
18/04/01 20:15:50 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-2 to offset 0.
18/04/01 20:15:50 INFO JobScheduler: Starting job streaming job 1522602950000 ms.0 from job set of time 1522602950000 ms
18/04/01 20:15:50 INFO JobScheduler: Added jobs for time 1522602950000 ms
18/04/01 20:15:50 INFO JobGenerator: Checkpointing graph for time 1522602950000 ms
18/04/01 20:15:50 INFO DStreamGraph: Updating checkpoint data for time 1522602950000 ms
18/04/01 20:15:50 INFO DStreamGraph: Updated checkpoint data for time 1522602950000 ms
18/04/01 20:15:50 INFO CheckpointWriter: Submitted checkpoint of time 1522602950000 ms to writer queue
18/04/01 20:15:50 INFO CheckpointWriter: Saving checkpoint for time 1522602950000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602950000'
18/04/01 20:15:50 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:15:50 INFO DAGScheduler: Got job 55 (print at RefereeStats.scala:67) with 1 output partitions
18/04/01 20:15:50 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602925000.bk
18/04/01 20:15:50 INFO DAGScheduler: Final stage: ResultStage 88 (print at RefereeStats.scala:67)
18/04/01 20:15:50 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:15:50 INFO DAGScheduler: Missing parents: List()
18/04/01 20:15:50 INFO DAGScheduler: Submitting ResultStage 88 (MapPartitionsRDD[78] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:50 INFO CheckpointWriter: Checkpoint for time 1522602950000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602950000', took 5593 bytes and 19 ms
18/04/01 20:15:50 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 3.0 KB, free 477.2 MB)
18/04/01 20:15:50 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.2 MB)
18/04/01 20:15:50 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:50 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 88 (MapPartitionsRDD[78] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0))
18/04/01 20:15:50 INFO TaskSchedulerImpl: Adding task set 88.0 with 1 tasks
18/04/01 20:15:50 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 286, localhost, executor driver, partition 0, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:50 INFO Executor: Running task 0.0 in stage 88.0 (TID 286)
18/04/01 20:15:50 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:50 INFO Executor: Finished task 0.0 in stage 88.0 (TID 286). 747 bytes result sent to driver
18/04/01 20:15:50 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 286) in 6 ms on localhost (executor driver) (1/1)
18/04/01 20:15:50 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool 
18/04/01 20:15:50 INFO DAGScheduler: ResultStage 88 (print at RefereeStats.scala:67) finished in 0.020 s
18/04/01 20:15:50 INFO DAGScheduler: Job 55 finished: print at RefereeStats.scala:67, took 0.024347 s
18/04/01 20:15:50 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:15:50 INFO DAGScheduler: Got job 56 (print at RefereeStats.scala:67) with 4 output partitions
18/04/01 20:15:50 INFO DAGScheduler: Final stage: ResultStage 89 (print at RefereeStats.scala:67)
18/04/01 20:15:50 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:15:50 INFO DAGScheduler: Missing parents: List()
18/04/01 20:15:50 INFO DAGScheduler: Submitting ResultStage 89 (MapPartitionsRDD[78] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:50 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 3.0 KB, free 477.2 MB)
18/04/01 20:15:50 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.2 MB)
18/04/01 20:15:50 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:50 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:50 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 89 (MapPartitionsRDD[78] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
18/04/01 20:15:50 INFO TaskSchedulerImpl: Adding task set 89.0 with 4 tasks
18/04/01 20:15:50 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 287, localhost, executor driver, partition 1, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:50 INFO TaskSetManager: Starting task 1.0 in stage 89.0 (TID 288, localhost, executor driver, partition 2, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:50 INFO Executor: Running task 0.0 in stage 89.0 (TID 287)
18/04/01 20:15:50 INFO Executor: Running task 1.0 in stage 89.0 (TID 288)
18/04/01 20:15:50 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:50 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:50 INFO Executor: Finished task 1.0 in stage 89.0 (TID 288). 747 bytes result sent to driver
18/04/01 20:15:50 INFO Executor: Finished task 0.0 in stage 89.0 (TID 287). 704 bytes result sent to driver
18/04/01 20:15:50 INFO TaskSetManager: Starting task 2.0 in stage 89.0 (TID 289, localhost, executor driver, partition 3, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:50 INFO Executor: Running task 2.0 in stage 89.0 (TID 289)
18/04/01 20:15:50 INFO TaskSetManager: Starting task 3.0 in stage 89.0 (TID 290, localhost, executor driver, partition 4, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:50 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:50 INFO Executor: Finished task 2.0 in stage 89.0 (TID 289). 704 bytes result sent to driver
18/04/01 20:15:50 INFO TaskSetManager: Finished task 2.0 in stage 89.0 (TID 289) in 6 ms on localhost (executor driver) (1/4)
18/04/01 20:15:50 INFO Executor: Running task 3.0 in stage 89.0 (TID 290)
18/04/01 20:15:50 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 287) in 17 ms on localhost (executor driver) (2/4)
18/04/01 20:15:50 INFO TaskSetManager: Finished task 1.0 in stage 89.0 (TID 288) in 16 ms on localhost (executor driver) (3/4)
18/04/01 20:15:50 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 719 -> 721
18/04/01 20:15:50 INFO Executor: Finished task 3.0 in stage 89.0 (TID 290). 896 bytes result sent to driver
18/04/01 20:15:50 INFO TaskSetManager: Finished task 3.0 in stage 89.0 (TID 290) in 17 ms on localhost (executor driver) (4/4)
18/04/01 20:15:50 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool 
18/04/01 20:15:50 INFO DAGScheduler: ResultStage 89 (print at RefereeStats.scala:67) finished in 0.040 s
18/04/01 20:15:50 INFO DAGScheduler: Job 56 finished: print at RefereeStats.scala:67, took 0.046309 s
18/04/01 20:15:50 INFO JobScheduler: Finished job streaming job 1522602950000 ms.0 from job set of time 1522602950000 ms
18/04/01 20:15:50 INFO JobScheduler: Starting job streaming job 1522602950000 ms.1 from job set of time 1522602950000 ms
-------------------------------------------
Time: 1522602950000 ms
-------------------------------------------
(market.yandex.*,0)
(yandex.*,8000)

18/04/01 20:15:50 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:71
18/04/01 20:15:50 INFO DAGScheduler: Registering RDD 78 (map at RefereeStats.scala:53)
18/04/01 20:15:50 INFO DAGScheduler: Got job 57 (foreachPartition at RefereeStats.scala:71) with 2 output partitions
18/04/01 20:15:50 INFO DAGScheduler: Final stage: ResultStage 91 (foreachPartition at RefereeStats.scala:71)
18/04/01 20:15:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 90)
18/04/01 20:15:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 90)
18/04/01 20:15:50 INFO DAGScheduler: Submitting ShuffleMapStage 90 (MapPartitionsRDD[78] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:50 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:15:50 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:15:50 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:50 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:50 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 90 (MapPartitionsRDD[78] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:50 INFO TaskSchedulerImpl: Adding task set 90.0 with 5 tasks
18/04/01 20:15:50 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 291, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:50 INFO TaskSetManager: Starting task 1.0 in stage 90.0 (TID 292, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:50 INFO Executor: Running task 0.0 in stage 90.0 (TID 291)
18/04/01 20:15:50 INFO Executor: Running task 1.0 in stage 90.0 (TID 292)
18/04/01 20:15:50 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:50 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:50 INFO Executor: Finished task 0.0 in stage 90.0 (TID 291). 938 bytes result sent to driver
18/04/01 20:15:50 INFO TaskSetManager: Starting task 2.0 in stage 90.0 (TID 293, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:50 INFO Executor: Running task 2.0 in stage 90.0 (TID 293)
18/04/01 20:15:50 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 291) in 11 ms on localhost (executor driver) (1/5)
18/04/01 20:15:50 INFO Executor: Finished task 1.0 in stage 90.0 (TID 292). 938 bytes result sent to driver
18/04/01 20:15:50 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:50 INFO TaskSetManager: Starting task 3.0 in stage 90.0 (TID 294, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:50 INFO TaskSetManager: Finished task 1.0 in stage 90.0 (TID 292) in 15 ms on localhost (executor driver) (2/5)
18/04/01 20:15:50 INFO Executor: Running task 3.0 in stage 90.0 (TID 294)
18/04/01 20:15:50 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:50 INFO Executor: Finished task 2.0 in stage 90.0 (TID 293). 938 bytes result sent to driver
18/04/01 20:15:50 INFO TaskSetManager: Starting task 4.0 in stage 90.0 (TID 295, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:50 INFO TaskSetManager: Finished task 2.0 in stage 90.0 (TID 293) in 10 ms on localhost (executor driver) (3/5)
18/04/01 20:15:50 INFO Executor: Finished task 3.0 in stage 90.0 (TID 294). 938 bytes result sent to driver
18/04/01 20:15:50 INFO Executor: Running task 4.0 in stage 90.0 (TID 295)
18/04/01 20:15:50 INFO TaskSetManager: Finished task 3.0 in stage 90.0 (TID 294) in 11 ms on localhost (executor driver) (4/5)
18/04/01 20:15:50 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 719 -> 721
18/04/01 20:15:50 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 719
18/04/01 20:15:50 INFO Executor: Finished task 4.0 in stage 90.0 (TID 295). 1024 bytes result sent to driver
18/04/01 20:15:50 INFO TaskSetManager: Finished task 4.0 in stage 90.0 (TID 295) in 457 ms on localhost (executor driver) (5/5)
18/04/01 20:15:50 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool 
18/04/01 20:15:50 INFO DAGScheduler: ShuffleMapStage 90 (map at RefereeStats.scala:53) finished in 0.486 s
18/04/01 20:15:50 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:50 INFO DAGScheduler: running: Set()
18/04/01 20:15:50 INFO DAGScheduler: waiting: Set(ResultStage 91)
18/04/01 20:15:50 INFO DAGScheduler: failed: Set()
18/04/01 20:15:50 INFO DAGScheduler: Submitting ResultStage 91 (ShuffledRDD[79] at reduceByKey at RefereeStats.scala:60), which has no missing parents
18/04/01 20:15:50 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:15:50 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 1706.0 B, free 477.2 MB)
18/04/01 20:15:50 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 192.168.1.3:35449 (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:15:50 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 91 (ShuffledRDD[79] at reduceByKey at RefereeStats.scala:60) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:50 INFO TaskSchedulerImpl: Adding task set 91.0 with 2 tasks
18/04/01 20:15:50 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 296, localhost, executor driver, partition 0, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:15:50 INFO TaskSetManager: Starting task 1.0 in stage 91.0 (TID 297, localhost, executor driver, partition 1, ANY, 7649 bytes)
18/04/01 20:15:50 INFO Executor: Running task 0.0 in stage 91.0 (TID 296)
18/04/01 20:15:50 INFO Executor: Running task 1.0 in stage 91.0 (TID 297)
18/04/01 20:15:50 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:50 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:15:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:15:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:15:50 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:50 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:50 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:50 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:50 INFO KafkaProducer: [Producer clientId=producer-67] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:50 INFO Executor: Finished task 0.0 in stage 91.0 (TID 296). 1138 bytes result sent to driver
18/04/01 20:15:50 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 296) in 12 ms on localhost (executor driver) (1/2)
18/04/01 20:15:50 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:50 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:50 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:50 INFO KafkaProducer: [Producer clientId=producer-68] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:50 INFO Executor: Finished task 1.0 in stage 91.0 (TID 297). 1138 bytes result sent to driver
18/04/01 20:15:50 INFO TaskSetManager: Finished task 1.0 in stage 91.0 (TID 297) in 33 ms on localhost (executor driver) (2/2)
18/04/01 20:15:50 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool 
18/04/01 20:15:50 INFO DAGScheduler: ResultStage 91 (foreachPartition at RefereeStats.scala:71) finished in 0.042 s
18/04/01 20:15:50 INFO DAGScheduler: Job 57 finished: foreachPartition at RefereeStats.scala:71, took 0.537899 s
18/04/01 20:15:50 INFO JobScheduler: Finished job streaming job 1522602950000 ms.1 from job set of time 1522602950000 ms
18/04/01 20:15:50 INFO JobScheduler: Starting job streaming job 1522602950000 ms.2 from job set of time 1522602950000 ms
18/04/01 20:15:50 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:89
18/04/01 20:15:50 INFO DAGScheduler: Registering RDD 80 (map at RefereeStats.scala:46)
18/04/01 20:15:50 INFO DAGScheduler: Got job 58 (foreachPartition at RefereeStats.scala:89) with 2 output partitions
18/04/01 20:15:50 INFO DAGScheduler: Final stage: ResultStage 93 (foreachPartition at RefereeStats.scala:89)
18/04/01 20:15:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 92)
18/04/01 20:15:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 92)
18/04/01 20:15:50 INFO DAGScheduler: Submitting ShuffleMapStage 92 (MapPartitionsRDD[80] at map at RefereeStats.scala:46), which has no missing parents
18/04/01 20:15:50 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:15:50 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:15:50 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:50 INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:50 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 92 (MapPartitionsRDD[80] at map at RefereeStats.scala:46) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:50 INFO TaskSchedulerImpl: Adding task set 92.0 with 5 tasks
18/04/01 20:15:50 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 298, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:50 INFO TaskSetManager: Starting task 1.0 in stage 92.0 (TID 299, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:50 INFO Executor: Running task 0.0 in stage 92.0 (TID 298)
18/04/01 20:15:50 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:50 INFO Executor: Finished task 0.0 in stage 92.0 (TID 298). 938 bytes result sent to driver
18/04/01 20:15:50 INFO Executor: Running task 1.0 in stage 92.0 (TID 299)
18/04/01 20:15:50 INFO TaskSetManager: Starting task 2.0 in stage 92.0 (TID 300, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:50 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 298) in 8 ms on localhost (executor driver) (1/5)
18/04/01 20:15:50 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:50 INFO Executor: Finished task 1.0 in stage 92.0 (TID 299). 938 bytes result sent to driver
18/04/01 20:15:50 INFO Executor: Running task 2.0 in stage 92.0 (TID 300)
18/04/01 20:15:50 INFO TaskSetManager: Starting task 3.0 in stage 92.0 (TID 301, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:50 INFO TaskSetManager: Finished task 1.0 in stage 92.0 (TID 299) in 12 ms on localhost (executor driver) (2/5)
18/04/01 20:15:50 INFO Executor: Running task 3.0 in stage 92.0 (TID 301)
18/04/01 20:15:50 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:50 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:50 INFO Executor: Finished task 2.0 in stage 92.0 (TID 300). 938 bytes result sent to driver
18/04/01 20:15:50 INFO Executor: Finished task 3.0 in stage 92.0 (TID 301). 938 bytes result sent to driver
18/04/01 20:15:50 INFO TaskSetManager: Starting task 4.0 in stage 92.0 (TID 302, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:50 INFO Executor: Running task 4.0 in stage 92.0 (TID 302)
18/04/01 20:15:50 INFO TaskSetManager: Finished task 2.0 in stage 92.0 (TID 300) in 14 ms on localhost (executor driver) (3/5)
18/04/01 20:15:50 INFO TaskSetManager: Finished task 3.0 in stage 92.0 (TID 301) in 11 ms on localhost (executor driver) (4/5)
18/04/01 20:15:50 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 719 -> 721
18/04/01 20:15:50 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 719
18/04/01 20:15:51 INFO Executor: Finished task 4.0 in stage 92.0 (TID 302). 1024 bytes result sent to driver
18/04/01 20:15:51 INFO TaskSetManager: Finished task 4.0 in stage 92.0 (TID 302) in 408 ms on localhost (executor driver) (5/5)
18/04/01 20:15:51 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool 
18/04/01 20:15:51 INFO DAGScheduler: ShuffleMapStage 92 (map at RefereeStats.scala:46) finished in 0.441 s
18/04/01 20:15:51 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:51 INFO DAGScheduler: running: Set()
18/04/01 20:15:51 INFO DAGScheduler: waiting: Set(ResultStage 93)
18/04/01 20:15:51 INFO DAGScheduler: failed: Set()
18/04/01 20:15:51 INFO DAGScheduler: Submitting ResultStage 93 (ShuffledRDD[81] at reduceByKey at RefereeStats.scala:51), which has no missing parents
18/04/01 20:15:51 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:15:51 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 1709.0 B, free 477.2 MB)
18/04/01 20:15:51 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 192.168.1.3:35449 (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:15:51 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 93 (ShuffledRDD[81] at reduceByKey at RefereeStats.scala:51) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:51 INFO TaskSchedulerImpl: Adding task set 93.0 with 2 tasks
18/04/01 20:15:51 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 303, localhost, executor driver, partition 0, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:15:51 INFO TaskSetManager: Starting task 1.0 in stage 93.0 (TID 304, localhost, executor driver, partition 1, ANY, 7649 bytes)
18/04/01 20:15:51 INFO Executor: Running task 0.0 in stage 93.0 (TID 303)
18/04/01 20:15:51 INFO Executor: Running task 1.0 in stage 93.0 (TID 304)
18/04/01 20:15:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:15:51 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:15:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
18/04/01 20:15:51 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:51 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:51 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:51 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:51 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:51 INFO KafkaProducer: [Producer clientId=producer-69] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:51 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:51 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:51 INFO KafkaProducer: [Producer clientId=producer-70] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:51 INFO Executor: Finished task 0.0 in stage 93.0 (TID 303). 1138 bytes result sent to driver
18/04/01 20:15:51 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 303) in 27 ms on localhost (executor driver) (1/2)
18/04/01 20:15:51 INFO Executor: Finished task 1.0 in stage 93.0 (TID 304). 1138 bytes result sent to driver
18/04/01 20:15:51 INFO TaskSetManager: Finished task 1.0 in stage 93.0 (TID 304) in 37 ms on localhost (executor driver) (2/2)
18/04/01 20:15:51 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool 
18/04/01 20:15:51 INFO DAGScheduler: ResultStage 93 (foreachPartition at RefereeStats.scala:89) finished in 0.053 s
18/04/01 20:15:51 INFO DAGScheduler: Job 58 finished: foreachPartition at RefereeStats.scala:89, took 0.504304 s
18/04/01 20:15:51 INFO JobScheduler: Finished job streaming job 1522602950000 ms.2 from job set of time 1522602950000 ms
18/04/01 20:15:51 INFO JobScheduler: Starting job streaming job 1522602950000 ms.3 from job set of time 1522602950000 ms
18/04/01 20:15:51 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:106
18/04/01 20:15:51 INFO DAGScheduler: Registering RDD 82 (map at RefereeStats.scala:39)
18/04/01 20:15:51 INFO DAGScheduler: Got job 59 (foreachPartition at RefereeStats.scala:106) with 2 output partitions
18/04/01 20:15:51 INFO DAGScheduler: Final stage: ResultStage 95 (foreachPartition at RefereeStats.scala:106)
18/04/01 20:15:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 94)
18/04/01 20:15:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 94)
18/04/01 20:15:51 INFO DAGScheduler: Submitting ShuffleMapStage 94 (MapPartitionsRDD[82] at map at RefereeStats.scala:39), which has no missing parents
18/04/01 20:15:51 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:15:51 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:15:51 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:51 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:51 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 94 (MapPartitionsRDD[82] at map at RefereeStats.scala:39) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:51 INFO TaskSchedulerImpl: Adding task set 94.0 with 5 tasks
18/04/01 20:15:51 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 305, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:51 INFO TaskSetManager: Starting task 1.0 in stage 94.0 (TID 306, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:51 INFO Executor: Running task 1.0 in stage 94.0 (TID 306)
18/04/01 20:15:51 INFO Executor: Running task 0.0 in stage 94.0 (TID 305)
18/04/01 20:15:51 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:51 INFO Executor: Finished task 0.0 in stage 94.0 (TID 305). 938 bytes result sent to driver
18/04/01 20:15:51 INFO TaskSetManager: Starting task 2.0 in stage 94.0 (TID 307, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:51 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 305) in 8 ms on localhost (executor driver) (1/5)
18/04/01 20:15:51 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:51 INFO Executor: Finished task 1.0 in stage 94.0 (TID 306). 938 bytes result sent to driver
18/04/01 20:15:51 INFO Executor: Running task 2.0 in stage 94.0 (TID 307)
18/04/01 20:15:51 INFO TaskSetManager: Starting task 3.0 in stage 94.0 (TID 308, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:51 INFO TaskSetManager: Finished task 1.0 in stage 94.0 (TID 306) in 11 ms on localhost (executor driver) (2/5)
18/04/01 20:15:51 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:51 INFO Executor: Finished task 2.0 in stage 94.0 (TID 307). 981 bytes result sent to driver
18/04/01 20:15:51 INFO Executor: Running task 3.0 in stage 94.0 (TID 308)
18/04/01 20:15:51 INFO TaskSetManager: Starting task 4.0 in stage 94.0 (TID 309, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:51 INFO TaskSetManager: Finished task 2.0 in stage 94.0 (TID 307) in 10 ms on localhost (executor driver) (3/5)
18/04/01 20:15:51 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:51 INFO Executor: Finished task 3.0 in stage 94.0 (TID 308). 938 bytes result sent to driver
18/04/01 20:15:51 INFO TaskSetManager: Finished task 3.0 in stage 94.0 (TID 308) in 10 ms on localhost (executor driver) (4/5)
18/04/01 20:15:51 INFO Executor: Running task 4.0 in stage 94.0 (TID 309)
18/04/01 20:15:51 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 719 -> 721
18/04/01 20:15:51 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 719
18/04/01 20:15:51 INFO Executor: Finished task 4.0 in stage 94.0 (TID 309). 1024 bytes result sent to driver
18/04/01 20:15:51 INFO TaskSetManager: Finished task 4.0 in stage 94.0 (TID 309) in 191 ms on localhost (executor driver) (5/5)
18/04/01 20:15:51 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool 
18/04/01 20:15:51 INFO DAGScheduler: ShuffleMapStage 94 (map at RefereeStats.scala:39) finished in 0.224 s
18/04/01 20:15:51 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:51 INFO DAGScheduler: running: Set()
18/04/01 20:15:51 INFO DAGScheduler: waiting: Set(ResultStage 95)
18/04/01 20:15:51 INFO DAGScheduler: failed: Set()
18/04/01 20:15:51 INFO DAGScheduler: Submitting ResultStage 95 (ShuffledRDD[83] at reduceByKey at RefereeStats.scala:43), which has no missing parents
18/04/01 20:15:51 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:15:51 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 1704.0 B, free 477.2 MB)
18/04/01 20:15:51 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 192.168.1.3:35449 (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:15:51 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 95 (ShuffledRDD[83] at reduceByKey at RefereeStats.scala:43) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:51 INFO TaskSchedulerImpl: Adding task set 95.0 with 2 tasks
18/04/01 20:15:51 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 310, localhost, executor driver, partition 0, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:15:51 INFO TaskSetManager: Starting task 1.0 in stage 95.0 (TID 311, localhost, executor driver, partition 1, ANY, 7649 bytes)
18/04/01 20:15:51 INFO Executor: Running task 0.0 in stage 95.0 (TID 310)
18/04/01 20:15:51 INFO Executor: Running task 1.0 in stage 95.0 (TID 311)
18/04/01 20:15:51 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:15:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:15:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:15:51 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:51 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:51 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:51 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:51 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:51 INFO KafkaProducer: [Producer clientId=producer-72] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:51 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:51 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:51 INFO KafkaProducer: [Producer clientId=producer-71] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:51 INFO Executor: Finished task 0.0 in stage 95.0 (TID 310). 1138 bytes result sent to driver
18/04/01 20:15:51 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 310) in 25 ms on localhost (executor driver) (1/2)
18/04/01 20:15:51 INFO Executor: Finished task 1.0 in stage 95.0 (TID 311). 1138 bytes result sent to driver
18/04/01 20:15:51 INFO TaskSetManager: Finished task 1.0 in stage 95.0 (TID 311) in 29 ms on localhost (executor driver) (2/2)
18/04/01 20:15:51 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool 
18/04/01 20:15:51 INFO DAGScheduler: ResultStage 95 (foreachPartition at RefereeStats.scala:106) finished in 0.037 s
18/04/01 20:15:51 INFO DAGScheduler: Job 59 finished: foreachPartition at RefereeStats.scala:106, took 0.269952 s
18/04/01 20:15:51 INFO JobScheduler: Finished job streaming job 1522602950000 ms.3 from job set of time 1522602950000 ms
18/04/01 20:15:51 INFO MapPartitionsRDD: Removing RDD 71 from persistence list
18/04/01 20:15:51 INFO BlockManager: Removing RDD 71
18/04/01 20:15:51 INFO KafkaRDD: Removing RDD 70 from persistence list
18/04/01 20:15:51 INFO JobScheduler: Total delay: 1.515 s for time 1522602950000 ms (execution: 1.472 s)
18/04/01 20:15:51 INFO BlockManager: Removing RDD 70
18/04/01 20:15:51 INFO ShuffledRDD: Removing RDD 72 from persistence list
18/04/01 20:15:51 INFO BlockManager: Removing RDD 72
18/04/01 20:15:51 INFO ShuffledRDD: Removing RDD 74 from persistence list
18/04/01 20:15:51 INFO BlockManager: Removing RDD 74
18/04/01 20:15:51 INFO MapPartitionsRDD: Removing RDD 73 from persistence list
18/04/01 20:15:51 INFO BlockManager: Removing RDD 73
18/04/01 20:15:51 INFO ShuffledRDD: Removing RDD 76 from persistence list
18/04/01 20:15:51 INFO BlockManager: Removing RDD 76
18/04/01 20:15:51 INFO MapPartitionsRDD: Removing RDD 75 from persistence list
18/04/01 20:15:51 INFO JobGenerator: Checkpointing graph for time 1522602950000 ms
18/04/01 20:15:51 INFO DStreamGraph: Updating checkpoint data for time 1522602950000 ms
18/04/01 20:15:51 INFO BlockManager: Removing RDD 75
18/04/01 20:15:51 INFO DStreamGraph: Updated checkpoint data for time 1522602950000 ms
18/04/01 20:15:51 INFO CheckpointWriter: Submitted checkpoint of time 1522602950000 ms to writer queue
18/04/01 20:15:51 INFO CheckpointWriter: Saving checkpoint for time 1522602950000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602950000'
18/04/01 20:15:51 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602925000
18/04/01 20:15:51 INFO CheckpointWriter: Checkpoint for time 1522602950000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602950000', took 5537 bytes and 16 ms
18/04/01 20:15:51 INFO DStreamGraph: Clearing checkpoint data for time 1522602950000 ms
18/04/01 20:15:51 INFO DStreamGraph: Cleared checkpoint data for time 1522602950000 ms
18/04/01 20:15:51 INFO ReceivedBlockTracker: Deleting batches: 
18/04/01 20:15:51 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/tmp/refs-xyzabb/receivedBlockMetadata older than 1522602945000: 
18/04/01 20:15:51 INFO InputInfoTracker: remove old batch metadata: 1522602940000 ms
18/04/01 20:15:55 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-0 to offset 723.
18/04/01 20:15:55 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-3 to offset 0.
18/04/01 20:15:55 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-4 to offset 0.
18/04/01 20:15:55 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-1 to offset 0.
18/04/01 20:15:55 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-2 to offset 0.
18/04/01 20:15:55 INFO JobScheduler: Starting job streaming job 1522602955000 ms.0 from job set of time 1522602955000 ms
18/04/01 20:15:55 INFO JobScheduler: Added jobs for time 1522602955000 ms
18/04/01 20:15:55 INFO JobGenerator: Checkpointing graph for time 1522602955000 ms
18/04/01 20:15:55 INFO DStreamGraph: Updating checkpoint data for time 1522602955000 ms
18/04/01 20:15:55 INFO DStreamGraph: Updated checkpoint data for time 1522602955000 ms
18/04/01 20:15:55 INFO CheckpointWriter: Submitted checkpoint of time 1522602955000 ms to writer queue
18/04/01 20:15:55 INFO CheckpointWriter: Saving checkpoint for time 1522602955000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602955000'
18/04/01 20:15:55 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:15:55 INFO DAGScheduler: Got job 60 (print at RefereeStats.scala:67) with 1 output partitions
18/04/01 20:15:55 INFO DAGScheduler: Final stage: ResultStage 96 (print at RefereeStats.scala:67)
18/04/01 20:15:55 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:15:55 INFO DAGScheduler: Missing parents: List()
18/04/01 20:15:55 INFO DAGScheduler: Submitting ResultStage 96 (MapPartitionsRDD[85] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:55 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 3.0 KB, free 477.2 MB)
18/04/01 20:15:55 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602930000.bk
18/04/01 20:15:55 INFO CheckpointWriter: Checkpoint for time 1522602955000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602955000', took 5596 bytes and 19 ms
18/04/01 20:15:55 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.2 MB)
18/04/01 20:15:55 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:55 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 96 (MapPartitionsRDD[85] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0))
18/04/01 20:15:55 INFO TaskSchedulerImpl: Adding task set 96.0 with 1 tasks
18/04/01 20:15:55 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 312, localhost, executor driver, partition 0, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:55 INFO Executor: Running task 0.0 in stage 96.0 (TID 312)
18/04/01 20:15:55 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:55 INFO Executor: Finished task 0.0 in stage 96.0 (TID 312). 661 bytes result sent to driver
18/04/01 20:15:55 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 312) in 6 ms on localhost (executor driver) (1/1)
18/04/01 20:15:55 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool 
18/04/01 20:15:55 INFO DAGScheduler: ResultStage 96 (print at RefereeStats.scala:67) finished in 0.019 s
18/04/01 20:15:55 INFO DAGScheduler: Job 60 finished: print at RefereeStats.scala:67, took 0.023284 s
18/04/01 20:15:55 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:15:55 INFO DAGScheduler: Got job 61 (print at RefereeStats.scala:67) with 4 output partitions
18/04/01 20:15:55 INFO DAGScheduler: Final stage: ResultStage 97 (print at RefereeStats.scala:67)
18/04/01 20:15:55 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:15:55 INFO DAGScheduler: Missing parents: List()
18/04/01 20:15:55 INFO DAGScheduler: Submitting ResultStage 97 (MapPartitionsRDD[85] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:55 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 3.0 KB, free 477.2 MB)
18/04/01 20:15:55 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.2 MB)
18/04/01 20:15:55 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:55 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:55 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 97 (MapPartitionsRDD[85] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
18/04/01 20:15:55 INFO TaskSchedulerImpl: Adding task set 97.0 with 4 tasks
18/04/01 20:15:55 INFO TaskSetManager: Starting task 0.0 in stage 97.0 (TID 313, localhost, executor driver, partition 1, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:55 INFO TaskSetManager: Starting task 1.0 in stage 97.0 (TID 314, localhost, executor driver, partition 2, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:55 INFO Executor: Running task 0.0 in stage 97.0 (TID 313)
18/04/01 20:15:55 INFO Executor: Running task 1.0 in stage 97.0 (TID 314)
18/04/01 20:15:55 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:55 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:55 INFO Executor: Finished task 1.0 in stage 97.0 (TID 314). 704 bytes result sent to driver
18/04/01 20:15:55 INFO TaskSetManager: Starting task 2.0 in stage 97.0 (TID 315, localhost, executor driver, partition 3, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:55 INFO Executor: Running task 2.0 in stage 97.0 (TID 315)
18/04/01 20:15:55 INFO TaskSetManager: Finished task 1.0 in stage 97.0 (TID 314) in 7 ms on localhost (executor driver) (1/4)
18/04/01 20:15:55 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:55 INFO Executor: Finished task 0.0 in stage 97.0 (TID 313). 704 bytes result sent to driver
18/04/01 20:15:55 INFO Executor: Finished task 2.0 in stage 97.0 (TID 315). 704 bytes result sent to driver
18/04/01 20:15:55 INFO TaskSetManager: Starting task 3.0 in stage 97.0 (TID 316, localhost, executor driver, partition 4, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:15:55 INFO Executor: Running task 3.0 in stage 97.0 (TID 316)
18/04/01 20:15:55 INFO TaskSetManager: Finished task 0.0 in stage 97.0 (TID 313) in 12 ms on localhost (executor driver) (2/4)
18/04/01 20:15:55 INFO TaskSetManager: Finished task 2.0 in stage 97.0 (TID 315) in 7 ms on localhost (executor driver) (3/4)
18/04/01 20:15:55 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 721 -> 723
-------------------------------------------
Time: 1522602955000 ms
-------------------------------------------
(telegram.ru,0)
(instagram.*,0)

18/04/01 20:15:55 INFO Executor: Finished task 3.0 in stage 97.0 (TID 316). 886 bytes result sent to driver
18/04/01 20:15:55 INFO TaskSetManager: Finished task 3.0 in stage 97.0 (TID 316) in 17 ms on localhost (executor driver) (4/4)
18/04/01 20:15:55 INFO TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool 
18/04/01 20:15:55 INFO DAGScheduler: ResultStage 97 (print at RefereeStats.scala:67) finished in 0.043 s
18/04/01 20:15:55 INFO DAGScheduler: Job 61 finished: print at RefereeStats.scala:67, took 0.050625 s
18/04/01 20:15:55 INFO JobScheduler: Finished job streaming job 1522602955000 ms.0 from job set of time 1522602955000 ms
18/04/01 20:15:55 INFO JobScheduler: Starting job streaming job 1522602955000 ms.1 from job set of time 1522602955000 ms
18/04/01 20:15:55 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:71
18/04/01 20:15:55 INFO DAGScheduler: Registering RDD 85 (map at RefereeStats.scala:53)
18/04/01 20:15:55 INFO DAGScheduler: Got job 62 (foreachPartition at RefereeStats.scala:71) with 2 output partitions
18/04/01 20:15:55 INFO DAGScheduler: Final stage: ResultStage 99 (foreachPartition at RefereeStats.scala:71)
18/04/01 20:15:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 98)
18/04/01 20:15:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 98)
18/04/01 20:15:55 INFO DAGScheduler: Submitting ShuffleMapStage 98 (MapPartitionsRDD[85] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:15:55 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:15:55 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:15:55 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:55 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:55 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 98 (MapPartitionsRDD[85] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:55 INFO TaskSchedulerImpl: Adding task set 98.0 with 5 tasks
18/04/01 20:15:55 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 317, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:55 INFO TaskSetManager: Starting task 1.0 in stage 98.0 (TID 318, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:55 INFO Executor: Running task 0.0 in stage 98.0 (TID 317)
18/04/01 20:15:55 INFO Executor: Running task 1.0 in stage 98.0 (TID 318)
18/04/01 20:15:55 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:55 INFO Executor: Finished task 0.0 in stage 98.0 (TID 317). 938 bytes result sent to driver
18/04/01 20:15:55 INFO TaskSetManager: Starting task 2.0 in stage 98.0 (TID 319, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2254
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2174
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2310
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2364
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2229
18/04/01 20:15:55 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 317) in 20 ms on localhost (executor driver) (1/5)
18/04/01 20:15:55 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:55 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2068
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2355
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2028
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2086
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2428
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2060
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2138
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2107
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2159
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2030
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2184
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2309
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2113
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2042
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2144
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2181
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2051
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2449
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2258
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2124
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2225
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2236
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2061
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2220
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2313
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2131
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2070
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2161
18/04/01 20:15:55 INFO Executor: Finished task 1.0 in stage 98.0 (TID 318). 981 bytes result sent to driver
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2038
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2132
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2099
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2365
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2204
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2341
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2262
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2062
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2304
18/04/01 20:15:55 INFO TaskSetManager: Starting task 3.0 in stage 98.0 (TID 320, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:55 INFO TaskSetManager: Finished task 1.0 in stage 98.0 (TID 318) in 23 ms on localhost (executor driver) (2/5)
18/04/01 20:15:55 INFO Executor: Running task 3.0 in stage 98.0 (TID 320)
18/04/01 20:15:55 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 192.168.1.3:35449 in memory (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:15:55 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2093
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2121
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2176
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2052
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2274
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2264
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2363
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2430
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2273
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2116
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2191
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2406
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2240
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2331
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2007
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2108
18/04/01 20:15:55 INFO Executor: Running task 2.0 in stage 98.0 (TID 319)
18/04/01 20:15:55 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2416
18/04/01 20:15:55 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:55 INFO ContextCleaner: Cleaned shuffle 32
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2405
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2327
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2373
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2339
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2130
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2344
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2436
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2358
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2034
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2414
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2432
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2336
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2223
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2360
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2408
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2413
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2173
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2186
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2434
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2352
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2066
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2419
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2069
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2137
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2046
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2111
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2011
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2441
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2234
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2301
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2333
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2122
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2243
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2321
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2320
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2203
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2345
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2397
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2443
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2154
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2307
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2303
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2153
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2375
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2409
18/04/01 20:15:55 INFO ContextCleaner: Cleaned shuffle 29
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2188
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2209
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2231
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2216
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2140
18/04/01 20:15:55 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 192.168.1.3:35449 in memory (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2083
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2074
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2237
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2158
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2193
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2064
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2277
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2103
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2015
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2292
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2370
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2438
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2232
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2354
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2142
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2047
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2114
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2156
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2330
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2097
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2323
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2284
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2420
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2017
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2009
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2218
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2392
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2368
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2359
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2127
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2106
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2246
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2247
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2401
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2091
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2332
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2278
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2202
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2351
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2376
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2374
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2398
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2040
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2217
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2324
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2268
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2076
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2172
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2212
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2311
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2043
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2135
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2267
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2012
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2249
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2078
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2281
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2178
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2342
18/04/01 20:15:55 INFO Executor: Finished task 2.0 in stage 98.0 (TID 319). 938 bytes result sent to driver
18/04/01 20:15:55 INFO ContextCleaner: Cleaned shuffle 30
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2194
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2385
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2380
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2072
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2139
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2224
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2205
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2383
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2348
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2109
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2054
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2433
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2445
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2353
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2032
18/04/01 20:15:55 INFO Executor: Finished task 3.0 in stage 98.0 (TID 320). 938 bytes result sent to driver
18/04/01 20:15:55 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:55 INFO TaskSetManager: Starting task 4.0 in stage 98.0 (TID 321, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:55 INFO TaskSetManager: Finished task 2.0 in stage 98.0 (TID 319) in 25 ms on localhost (executor driver) (3/5)
18/04/01 20:15:55 INFO TaskSetManager: Finished task 3.0 in stage 98.0 (TID 320) in 19 ms on localhost (executor driver) (4/5)
18/04/01 20:15:55 INFO Executor: Running task 4.0 in stage 98.0 (TID 321)
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2244
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2362
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2037
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2021
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2077
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2382
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2045
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2289
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2426
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2442
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2179
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2257
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2294
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2123
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2245
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2104
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2448
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2424
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2422
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2162
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2314
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2239
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2261
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2418
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2328
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2306
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2381
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2126
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2088
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2192
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2287
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2329
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2031
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2446
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2079
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2242
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2276
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2013
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2402
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2008
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2169
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2185
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2145
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2230
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2119
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2283
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2057
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2291
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2096
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2367
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2444
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2395
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2090
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2386
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2210
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2018
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2356
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2396
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2280
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2036
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2417
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2063
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2343
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2326
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2250
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2404
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2020
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2371
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2361
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2219
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2319
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2067
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2226
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2053
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2300
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2260
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2041
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2215
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2006
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2221
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2136
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2269
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2157
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2316
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2206
18/04/01 20:15:55 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 721 -> 723
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2293
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2299
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2056
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2003
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2196
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2163
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2211
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2055
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2098
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2265
18/04/01 20:15:55 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 721
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2427
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2233
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2058
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2129
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2180
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2027
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2049
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2325
18/04/01 20:15:55 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 192.168.1.3:35449 in memory (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2378
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2297
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2001
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2275
18/04/01 20:15:55 INFO ContextCleaner: Cleaned shuffle 28
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2279
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2149
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2255
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2146
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2338
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2165
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2075
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2002
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2270
18/04/01 20:15:55 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 192.168.1.3:35449 in memory (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2228
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2166
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2087
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2026
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2147
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2412
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2340
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2296
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2035
18/04/01 20:15:55 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2155
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2197
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2102
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2133
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2298
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2010
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2143
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2168
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2272
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2089
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2025
18/04/01 20:15:55 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2337
18/04/01 20:15:55 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2349
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2198
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2101
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2208
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2312
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2071
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2177
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2095
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2005
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2175
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2308
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2024
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2207
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2044
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2000
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2120
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2295
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2251
18/04/01 20:15:55 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2366
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2252
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2253
18/04/01 20:15:55 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2282
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2421
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2388
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2110
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2447
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2084
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2128
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2105
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2227
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2335
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2222
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2199
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2377
18/04/01 20:15:55 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 192.168.1.3:35449 in memory (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2152
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2141
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2171
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2016
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2437
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2334
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2200
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2410
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2118
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2393
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2429
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2369
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2023
18/04/01 20:15:55 INFO ContextCleaner: Cleaned shuffle 31
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2389
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2346
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2347
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2285
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2112
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2411
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2394
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2081
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2148
18/04/01 20:15:55 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2235
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2073
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2167
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2187
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2164
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2213
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2117
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2004
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2423
18/04/01 20:15:55 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2039
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2214
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2092
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2288
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2286
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2022
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2399
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2425
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2201
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2379
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2350
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2085
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2256
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2305
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2431
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2190
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2259
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2033
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2372
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2094
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2384
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2082
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2059
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2387
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2195
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2014
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2263
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2407
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2065
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2248
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2160
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2322
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2390
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2029
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2182
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2241
18/04/01 20:15:55 INFO ContextCleaner: Cleaned shuffle 27
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2151
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2290
18/04/01 20:15:55 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2391
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2050
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2415
18/04/01 20:15:55 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2238
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2400
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2100
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2125
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2080
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2170
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2271
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2440
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2150
18/04/01 20:15:55 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 192.168.1.3:35449 in memory (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2435
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2266
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2403
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2115
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2439
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2357
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2315
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2189
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2019
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2134
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2317
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2183
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2048
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2318
18/04/01 20:15:55 INFO ContextCleaner: Cleaned accumulator 2302
18/04/01 20:15:55 INFO Executor: Finished task 4.0 in stage 98.0 (TID 321). 1024 bytes result sent to driver
18/04/01 20:15:55 INFO TaskSetManager: Finished task 4.0 in stage 98.0 (TID 321) in 438 ms on localhost (executor driver) (5/5)
18/04/01 20:15:55 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool 
18/04/01 20:15:55 INFO DAGScheduler: ShuffleMapStage 98 (map at RefereeStats.scala:53) finished in 0.491 s
18/04/01 20:15:55 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:55 INFO DAGScheduler: running: Set()
18/04/01 20:15:55 INFO DAGScheduler: waiting: Set(ResultStage 99)
18/04/01 20:15:55 INFO DAGScheduler: failed: Set()
18/04/01 20:15:55 INFO DAGScheduler: Submitting ResultStage 99 (ShuffledRDD[86] at reduceByKey at RefereeStats.scala:60), which has no missing parents
18/04/01 20:15:55 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 2.8 KB, free 477.3 MB)
18/04/01 20:15:55 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 1706.0 B, free 477.3 MB)
18/04/01 20:15:55 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 192.168.1.3:35449 (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:15:55 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:55 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 99 (ShuffledRDD[86] at reduceByKey at RefereeStats.scala:60) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:55 INFO TaskSchedulerImpl: Adding task set 99.0 with 2 tasks
18/04/01 20:15:55 INFO TaskSetManager: Starting task 1.0 in stage 99.0 (TID 322, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:15:55 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 323, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:15:55 INFO Executor: Running task 0.0 in stage 99.0 (TID 323)
18/04/01 20:15:55 INFO Executor: Running task 1.0 in stage 99.0 (TID 322)
18/04/01 20:15:55 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:55 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:15:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:55 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:55 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:55 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:55 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:55 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:55 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:55 INFO KafkaProducer: [Producer clientId=producer-73] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:55 INFO Executor: Finished task 1.0 in stage 99.0 (TID 322). 1138 bytes result sent to driver
18/04/01 20:15:55 INFO TaskSetManager: Finished task 1.0 in stage 99.0 (TID 322) in 16 ms on localhost (executor driver) (1/2)
18/04/01 20:15:55 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:55 INFO KafkaProducer: [Producer clientId=producer-74] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:55 INFO Executor: Finished task 0.0 in stage 99.0 (TID 323). 1138 bytes result sent to driver
18/04/01 20:15:55 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 323) in 31 ms on localhost (executor driver) (2/2)
18/04/01 20:15:55 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool 
18/04/01 20:15:55 INFO DAGScheduler: ResultStage 99 (foreachPartition at RefereeStats.scala:71) finished in 0.041 s
18/04/01 20:15:55 INFO DAGScheduler: Job 62 finished: foreachPartition at RefereeStats.scala:71, took 0.540366 s
18/04/01 20:15:55 INFO JobScheduler: Finished job streaming job 1522602955000 ms.1 from job set of time 1522602955000 ms
18/04/01 20:15:55 INFO JobScheduler: Starting job streaming job 1522602955000 ms.2 from job set of time 1522602955000 ms
18/04/01 20:15:55 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:89
18/04/01 20:15:55 INFO DAGScheduler: Registering RDD 87 (map at RefereeStats.scala:46)
18/04/01 20:15:55 INFO DAGScheduler: Got job 63 (foreachPartition at RefereeStats.scala:89) with 2 output partitions
18/04/01 20:15:55 INFO DAGScheduler: Final stage: ResultStage 101 (foreachPartition at RefereeStats.scala:89)
18/04/01 20:15:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 100)
18/04/01 20:15:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 100)
18/04/01 20:15:55 INFO DAGScheduler: Submitting ShuffleMapStage 100 (MapPartitionsRDD[87] at map at RefereeStats.scala:46), which has no missing parents
18/04/01 20:15:55 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 3.9 KB, free 477.3 MB)
18/04/01 20:15:55 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.3 MB)
18/04/01 20:15:55 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:55 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:55 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 100 (MapPartitionsRDD[87] at map at RefereeStats.scala:46) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:55 INFO TaskSchedulerImpl: Adding task set 100.0 with 5 tasks
18/04/01 20:15:55 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 324, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:55 INFO TaskSetManager: Starting task 1.0 in stage 100.0 (TID 325, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:55 INFO Executor: Running task 0.0 in stage 100.0 (TID 324)
18/04/01 20:15:55 INFO Executor: Running task 1.0 in stage 100.0 (TID 325)
18/04/01 20:15:55 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:55 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:55 INFO Executor: Finished task 1.0 in stage 100.0 (TID 325). 938 bytes result sent to driver
18/04/01 20:15:55 INFO Executor: Finished task 0.0 in stage 100.0 (TID 324). 938 bytes result sent to driver
18/04/01 20:15:55 INFO TaskSetManager: Starting task 2.0 in stage 100.0 (TID 326, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:55 INFO Executor: Running task 2.0 in stage 100.0 (TID 326)
18/04/01 20:15:55 INFO TaskSetManager: Starting task 3.0 in stage 100.0 (TID 327, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:55 INFO TaskSetManager: Finished task 1.0 in stage 100.0 (TID 325) in 8 ms on localhost (executor driver) (1/5)
18/04/01 20:15:55 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 324) in 8 ms on localhost (executor driver) (2/5)
18/04/01 20:15:55 INFO Executor: Running task 3.0 in stage 100.0 (TID 327)
18/04/01 20:15:55 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:55 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:55 INFO Executor: Finished task 2.0 in stage 100.0 (TID 326). 938 bytes result sent to driver
18/04/01 20:15:55 INFO TaskSetManager: Starting task 4.0 in stage 100.0 (TID 328, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:55 INFO TaskSetManager: Finished task 2.0 in stage 100.0 (TID 326) in 8 ms on localhost (executor driver) (3/5)
18/04/01 20:15:55 INFO Executor: Finished task 3.0 in stage 100.0 (TID 327). 938 bytes result sent to driver
18/04/01 20:15:55 INFO Executor: Running task 4.0 in stage 100.0 (TID 328)
18/04/01 20:15:55 INFO TaskSetManager: Finished task 3.0 in stage 100.0 (TID 327) in 9 ms on localhost (executor driver) (4/5)
18/04/01 20:15:55 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 721 -> 723
18/04/01 20:15:55 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 721
18/04/01 20:15:56 INFO Executor: Finished task 4.0 in stage 100.0 (TID 328). 1024 bytes result sent to driver
18/04/01 20:15:56 INFO TaskSetManager: Finished task 4.0 in stage 100.0 (TID 328) in 423 ms on localhost (executor driver) (5/5)
18/04/01 20:15:56 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool 
18/04/01 20:15:56 INFO DAGScheduler: ShuffleMapStage 100 (map at RefereeStats.scala:46) finished in 0.448 s
18/04/01 20:15:56 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:56 INFO DAGScheduler: running: Set()
18/04/01 20:15:56 INFO DAGScheduler: waiting: Set(ResultStage 101)
18/04/01 20:15:56 INFO DAGScheduler: failed: Set()
18/04/01 20:15:56 INFO DAGScheduler: Submitting ResultStage 101 (ShuffledRDD[88] at reduceByKey at RefereeStats.scala:51), which has no missing parents
18/04/01 20:15:56 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 2.8 KB, free 477.3 MB)
18/04/01 20:15:56 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 1709.0 B, free 477.3 MB)
18/04/01 20:15:56 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 192.168.1.3:35449 (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:15:56 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:56 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 101 (ShuffledRDD[88] at reduceByKey at RefereeStats.scala:51) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:56 INFO TaskSchedulerImpl: Adding task set 101.0 with 2 tasks
18/04/01 20:15:56 INFO TaskSetManager: Starting task 1.0 in stage 101.0 (TID 329, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:15:56 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 330, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:15:56 INFO Executor: Running task 1.0 in stage 101.0 (TID 329)
18/04/01 20:15:56 INFO Executor: Running task 0.0 in stage 101.0 (TID 330)
18/04/01 20:15:56 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:15:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:56 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:56 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:15:56 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:56 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:56 INFO KafkaProducer: [Producer clientId=producer-75] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:56 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:56 INFO Executor: Finished task 1.0 in stage 101.0 (TID 329). 1138 bytes result sent to driver
18/04/01 20:15:56 INFO TaskSetManager: Finished task 1.0 in stage 101.0 (TID 329) in 14 ms on localhost (executor driver) (1/2)
18/04/01 20:15:56 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:56 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:56 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:56 INFO KafkaProducer: [Producer clientId=producer-76] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:56 INFO Executor: Finished task 0.0 in stage 101.0 (TID 330). 1138 bytes result sent to driver
18/04/01 20:15:56 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 330) in 43 ms on localhost (executor driver) (2/2)
18/04/01 20:15:56 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool 
18/04/01 20:15:56 INFO DAGScheduler: ResultStage 101 (foreachPartition at RefereeStats.scala:89) finished in 0.054 s
18/04/01 20:15:56 INFO DAGScheduler: Job 63 finished: foreachPartition at RefereeStats.scala:89, took 0.510667 s
18/04/01 20:15:56 INFO JobScheduler: Finished job streaming job 1522602955000 ms.2 from job set of time 1522602955000 ms
18/04/01 20:15:56 INFO JobScheduler: Starting job streaming job 1522602955000 ms.3 from job set of time 1522602955000 ms
18/04/01 20:15:56 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:106
18/04/01 20:15:56 INFO DAGScheduler: Registering RDD 89 (map at RefereeStats.scala:39)
18/04/01 20:15:56 INFO DAGScheduler: Got job 64 (foreachPartition at RefereeStats.scala:106) with 2 output partitions
18/04/01 20:15:56 INFO DAGScheduler: Final stage: ResultStage 103 (foreachPartition at RefereeStats.scala:106)
18/04/01 20:15:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 102)
18/04/01 20:15:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 102)
18/04/01 20:15:56 INFO DAGScheduler: Submitting ShuffleMapStage 102 (MapPartitionsRDD[89] at map at RefereeStats.scala:39), which has no missing parents
18/04/01 20:15:56 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 3.9 KB, free 477.3 MB)
18/04/01 20:15:56 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.3 MB)
18/04/01 20:15:56 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:15:56 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:56 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 102 (MapPartitionsRDD[89] at map at RefereeStats.scala:39) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:15:56 INFO TaskSchedulerImpl: Adding task set 102.0 with 5 tasks
18/04/01 20:15:56 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 331, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:56 INFO TaskSetManager: Starting task 1.0 in stage 102.0 (TID 332, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:56 INFO Executor: Running task 1.0 in stage 102.0 (TID 332)
18/04/01 20:15:56 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:15:56 INFO Executor: Running task 0.0 in stage 102.0 (TID 331)
18/04/01 20:15:56 INFO Executor: Finished task 1.0 in stage 102.0 (TID 332). 938 bytes result sent to driver
18/04/01 20:15:56 INFO TaskSetManager: Starting task 2.0 in stage 102.0 (TID 333, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:56 INFO Executor: Running task 2.0 in stage 102.0 (TID 333)
18/04/01 20:15:56 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:15:56 INFO TaskSetManager: Finished task 1.0 in stage 102.0 (TID 332) in 23 ms on localhost (executor driver) (1/5)
18/04/01 20:15:56 INFO Executor: Finished task 2.0 in stage 102.0 (TID 333). 938 bytes result sent to driver
18/04/01 20:15:56 INFO TaskSetManager: Starting task 3.0 in stage 102.0 (TID 334, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:56 INFO TaskSetManager: Finished task 2.0 in stage 102.0 (TID 333) in 9 ms on localhost (executor driver) (2/5)
18/04/01 20:15:56 INFO Executor: Running task 3.0 in stage 102.0 (TID 334)
18/04/01 20:15:56 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:15:56 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:15:56 INFO Executor: Finished task 0.0 in stage 102.0 (TID 331). 938 bytes result sent to driver
18/04/01 20:15:56 INFO Executor: Finished task 3.0 in stage 102.0 (TID 334). 938 bytes result sent to driver
18/04/01 20:15:56 INFO TaskSetManager: Starting task 4.0 in stage 102.0 (TID 335, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:15:56 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 331) in 34 ms on localhost (executor driver) (3/5)
18/04/01 20:15:56 INFO Executor: Running task 4.0 in stage 102.0 (TID 335)
18/04/01 20:15:56 INFO TaskSetManager: Finished task 3.0 in stage 102.0 (TID 334) in 10 ms on localhost (executor driver) (4/5)
18/04/01 20:15:56 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 721 -> 723
18/04/01 20:15:56 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 721
18/04/01 20:15:56 INFO Executor: Finished task 4.0 in stage 102.0 (TID 335). 1024 bytes result sent to driver
18/04/01 20:15:56 INFO TaskSetManager: Finished task 4.0 in stage 102.0 (TID 335) in 383 ms on localhost (executor driver) (5/5)
18/04/01 20:15:56 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool 
18/04/01 20:15:56 INFO DAGScheduler: ShuffleMapStage 102 (map at RefereeStats.scala:39) finished in 0.427 s
18/04/01 20:15:56 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:15:56 INFO DAGScheduler: running: Set()
18/04/01 20:15:56 INFO DAGScheduler: waiting: Set(ResultStage 103)
18/04/01 20:15:56 INFO DAGScheduler: failed: Set()
18/04/01 20:15:56 INFO DAGScheduler: Submitting ResultStage 103 (ShuffledRDD[90] at reduceByKey at RefereeStats.scala:43), which has no missing parents
18/04/01 20:15:56 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:15:56 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 1704.0 B, free 477.2 MB)
18/04/01 20:15:56 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 192.168.1.3:35449 (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:15:56 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1039
18/04/01 20:15:56 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 103 (ShuffledRDD[90] at reduceByKey at RefereeStats.scala:43) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:15:56 INFO TaskSchedulerImpl: Adding task set 103.0 with 2 tasks
18/04/01 20:15:56 INFO TaskSetManager: Starting task 1.0 in stage 103.0 (TID 336, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:15:56 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 337, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:15:56 INFO Executor: Running task 0.0 in stage 103.0 (TID 337)
18/04/01 20:15:56 INFO Executor: Running task 1.0 in stage 103.0 (TID 336)
18/04/01 20:15:56 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:15:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:15:56 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:56 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:15:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:15:56 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:15:56 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:56 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:56 INFO KafkaProducer: [Producer clientId=producer-78] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:56 INFO Executor: Finished task 1.0 in stage 103.0 (TID 336). 1138 bytes result sent to driver
18/04/01 20:15:56 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:15:56 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:15:56 INFO TaskSetManager: Finished task 1.0 in stage 103.0 (TID 336) in 31 ms on localhost (executor driver) (1/2)
18/04/01 20:15:56 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:15:56 INFO KafkaProducer: [Producer clientId=producer-77] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:15:56 INFO Executor: Finished task 0.0 in stage 103.0 (TID 337). 1138 bytes result sent to driver
18/04/01 20:15:56 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 337) in 50 ms on localhost (executor driver) (2/2)
18/04/01 20:15:56 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool 
18/04/01 20:15:56 INFO DAGScheduler: ResultStage 103 (foreachPartition at RefereeStats.scala:106) finished in 0.065 s
18/04/01 20:15:56 INFO DAGScheduler: Job 64 finished: foreachPartition at RefereeStats.scala:106, took 0.504446 s
18/04/01 20:15:56 INFO JobScheduler: Finished job streaming job 1522602955000 ms.3 from job set of time 1522602955000 ms
18/04/01 20:15:56 INFO JobScheduler: Total delay: 1.725 s for time 1522602955000 ms (execution: 1.693 s)
18/04/01 20:15:56 INFO MapPartitionsRDD: Removing RDD 78 from persistence list
18/04/01 20:15:56 INFO BlockManager: Removing RDD 78
18/04/01 20:15:56 INFO KafkaRDD: Removing RDD 77 from persistence list
18/04/01 20:15:56 INFO BlockManager: Removing RDD 77
18/04/01 20:15:56 INFO ShuffledRDD: Removing RDD 79 from persistence list
18/04/01 20:15:56 INFO BlockManager: Removing RDD 79
18/04/01 20:15:56 INFO ShuffledRDD: Removing RDD 81 from persistence list
18/04/01 20:15:56 INFO BlockManager: Removing RDD 81
18/04/01 20:15:56 INFO MapPartitionsRDD: Removing RDD 80 from persistence list
18/04/01 20:15:56 INFO BlockManager: Removing RDD 80
18/04/01 20:15:56 INFO ShuffledRDD: Removing RDD 83 from persistence list
18/04/01 20:15:56 INFO BlockManager: Removing RDD 83
18/04/01 20:15:56 INFO MapPartitionsRDD: Removing RDD 82 from persistence list
18/04/01 20:15:56 INFO BlockManager: Removing RDD 82
18/04/01 20:15:56 INFO JobGenerator: Checkpointing graph for time 1522602955000 ms
18/04/01 20:15:56 INFO DStreamGraph: Updating checkpoint data for time 1522602955000 ms
18/04/01 20:15:56 INFO DStreamGraph: Updated checkpoint data for time 1522602955000 ms
18/04/01 20:15:56 INFO CheckpointWriter: Submitted checkpoint of time 1522602955000 ms to writer queue
18/04/01 20:15:56 INFO CheckpointWriter: Saving checkpoint for time 1522602955000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602955000'
18/04/01 20:15:56 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602930000
18/04/01 20:15:56 INFO CheckpointWriter: Checkpoint for time 1522602955000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602955000', took 5538 bytes and 19 ms
18/04/01 20:15:56 INFO DStreamGraph: Clearing checkpoint data for time 1522602955000 ms
18/04/01 20:15:56 INFO DStreamGraph: Cleared checkpoint data for time 1522602955000 ms
18/04/01 20:15:56 INFO ReceivedBlockTracker: Deleting batches: 
18/04/01 20:15:56 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/tmp/refs-xyzabb/receivedBlockMetadata older than 1522602950000: 
18/04/01 20:15:56 INFO InputInfoTracker: remove old batch metadata: 1522602945000 ms
18/04/01 20:16:00 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-0 to offset 724.
18/04/01 20:16:00 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-3 to offset 0.
18/04/01 20:16:00 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-4 to offset 0.
18/04/01 20:16:00 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-1 to offset 0.
18/04/01 20:16:00 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-2 to offset 0.
18/04/01 20:16:00 INFO JobScheduler: Added jobs for time 1522602960000 ms
18/04/01 20:16:00 INFO JobGenerator: Checkpointing graph for time 1522602960000 ms
18/04/01 20:16:00 INFO DStreamGraph: Updating checkpoint data for time 1522602960000 ms
18/04/01 20:16:00 INFO JobScheduler: Starting job streaming job 1522602960000 ms.0 from job set of time 1522602960000 ms
18/04/01 20:16:00 INFO DStreamGraph: Updated checkpoint data for time 1522602960000 ms
18/04/01 20:16:00 INFO CheckpointWriter: Submitted checkpoint of time 1522602960000 ms to writer queue
18/04/01 20:16:00 INFO CheckpointWriter: Saving checkpoint for time 1522602960000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602960000'
18/04/01 20:16:00 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:16:00 INFO DAGScheduler: Got job 65 (print at RefereeStats.scala:67) with 1 output partitions
18/04/01 20:16:00 INFO DAGScheduler: Final stage: ResultStage 104 (print at RefereeStats.scala:67)
18/04/01 20:16:00 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:16:00 INFO DAGScheduler: Missing parents: List()
18/04/01 20:16:00 INFO DAGScheduler: Submitting ResultStage 104 (MapPartitionsRDD[92] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:16:00 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602935000.bk
18/04/01 20:16:00 INFO CheckpointWriter: Checkpoint for time 1522602960000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602960000', took 5596 bytes and 17 ms
18/04/01 20:16:00 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 3.0 KB, free 477.2 MB)
18/04/01 20:16:00 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.2 MB)
18/04/01 20:16:00 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:00 INFO SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 104 (MapPartitionsRDD[92] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0))
18/04/01 20:16:00 INFO TaskSchedulerImpl: Adding task set 104.0 with 1 tasks
18/04/01 20:16:00 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 338, localhost, executor driver, partition 0, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:00 INFO Executor: Running task 0.0 in stage 104.0 (TID 338)
18/04/01 20:16:00 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:00 INFO Executor: Finished task 0.0 in stage 104.0 (TID 338). 704 bytes result sent to driver
18/04/01 20:16:00 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 338) in 5 ms on localhost (executor driver) (1/1)
18/04/01 20:16:00 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool 
18/04/01 20:16:00 INFO DAGScheduler: ResultStage 104 (print at RefereeStats.scala:67) finished in 0.014 s
18/04/01 20:16:00 INFO DAGScheduler: Job 65 finished: print at RefereeStats.scala:67, took 0.017735 s
18/04/01 20:16:00 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:16:00 INFO DAGScheduler: Got job 66 (print at RefereeStats.scala:67) with 4 output partitions
18/04/01 20:16:00 INFO DAGScheduler: Final stage: ResultStage 105 (print at RefereeStats.scala:67)
18/04/01 20:16:00 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:16:00 INFO DAGScheduler: Missing parents: List()
18/04/01 20:16:00 INFO DAGScheduler: Submitting ResultStage 105 (MapPartitionsRDD[92] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:16:00 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 3.0 KB, free 477.2 MB)
18/04/01 20:16:00 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.2 MB)
18/04/01 20:16:00 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:00 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:00 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 105 (MapPartitionsRDD[92] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
18/04/01 20:16:00 INFO TaskSchedulerImpl: Adding task set 105.0 with 4 tasks
18/04/01 20:16:00 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 339, localhost, executor driver, partition 1, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:00 INFO TaskSetManager: Starting task 1.0 in stage 105.0 (TID 340, localhost, executor driver, partition 2, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:00 INFO Executor: Running task 0.0 in stage 105.0 (TID 339)
18/04/01 20:16:00 INFO Executor: Running task 1.0 in stage 105.0 (TID 340)
18/04/01 20:16:00 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:00 INFO Executor: Finished task 0.0 in stage 105.0 (TID 339). 704 bytes result sent to driver
18/04/01 20:16:00 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:00 INFO TaskSetManager: Starting task 2.0 in stage 105.0 (TID 341, localhost, executor driver, partition 3, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:00 INFO Executor: Running task 2.0 in stage 105.0 (TID 341)
18/04/01 20:16:00 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 339) in 6 ms on localhost (executor driver) (1/4)
18/04/01 20:16:00 INFO Executor: Finished task 1.0 in stage 105.0 (TID 340). 704 bytes result sent to driver
18/04/01 20:16:00 INFO TaskSetManager: Starting task 3.0 in stage 105.0 (TID 342, localhost, executor driver, partition 4, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:00 INFO TaskSetManager: Finished task 1.0 in stage 105.0 (TID 340) in 6 ms on localhost (executor driver) (2/4)
18/04/01 20:16:00 INFO Executor: Running task 3.0 in stage 105.0 (TID 342)
18/04/01 20:16:00 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:00 INFO Executor: Finished task 2.0 in stage 105.0 (TID 341). 661 bytes result sent to driver
18/04/01 20:16:00 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 723 -> 724
18/04/01 20:16:00 INFO TaskSetManager: Finished task 2.0 in stage 105.0 (TID 341) in 7 ms on localhost (executor driver) (3/4)
18/04/01 20:16:00 INFO Executor: Finished task 3.0 in stage 105.0 (TID 342). 856 bytes result sent to driver
18/04/01 20:16:00 INFO TaskSetManager: Finished task 3.0 in stage 105.0 (TID 342) in 9 ms on localhost (executor driver) (4/4)
18/04/01 20:16:00 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool 
18/04/01 20:16:00 INFO DAGScheduler: ResultStage 105 (print at RefereeStats.scala:67) finished in 0.024 s
-------------------------------------------
Time: 1522602960000 ms
-------------------------------------------
(vk.com,12000)

18/04/01 20:16:00 INFO DAGScheduler: Job 66 finished: print at RefereeStats.scala:67, took 0.028063 s
18/04/01 20:16:00 INFO JobScheduler: Finished job streaming job 1522602960000 ms.0 from job set of time 1522602960000 ms
18/04/01 20:16:00 INFO JobScheduler: Starting job streaming job 1522602960000 ms.1 from job set of time 1522602960000 ms
18/04/01 20:16:00 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:71
18/04/01 20:16:00 INFO DAGScheduler: Registering RDD 92 (map at RefereeStats.scala:53)
18/04/01 20:16:00 INFO DAGScheduler: Got job 67 (foreachPartition at RefereeStats.scala:71) with 2 output partitions
18/04/01 20:16:00 INFO DAGScheduler: Final stage: ResultStage 107 (foreachPartition at RefereeStats.scala:71)
18/04/01 20:16:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 106)
18/04/01 20:16:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 106)
18/04/01 20:16:00 INFO DAGScheduler: Submitting ShuffleMapStage 106 (MapPartitionsRDD[92] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:16:00 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:16:00 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:16:00 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:00 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:00 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 106 (MapPartitionsRDD[92] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:16:00 INFO TaskSchedulerImpl: Adding task set 106.0 with 5 tasks
18/04/01 20:16:00 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 343, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:00 INFO TaskSetManager: Starting task 1.0 in stage 106.0 (TID 344, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:00 INFO Executor: Running task 0.0 in stage 106.0 (TID 343)
18/04/01 20:16:00 INFO Executor: Running task 1.0 in stage 106.0 (TID 344)
18/04/01 20:16:00 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:00 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:00 INFO Executor: Finished task 1.0 in stage 106.0 (TID 344). 938 bytes result sent to driver
18/04/01 20:16:00 INFO Executor: Finished task 0.0 in stage 106.0 (TID 343). 938 bytes result sent to driver
18/04/01 20:16:00 INFO TaskSetManager: Starting task 2.0 in stage 106.0 (TID 345, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:00 INFO Executor: Running task 2.0 in stage 106.0 (TID 345)
18/04/01 20:16:00 INFO TaskSetManager: Starting task 3.0 in stage 106.0 (TID 346, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:00 INFO Executor: Running task 3.0 in stage 106.0 (TID 346)
18/04/01 20:16:00 INFO TaskSetManager: Finished task 1.0 in stage 106.0 (TID 344) in 8 ms on localhost (executor driver) (1/5)
18/04/01 20:16:00 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 343) in 8 ms on localhost (executor driver) (2/5)
18/04/01 20:16:00 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:00 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:00 INFO Executor: Finished task 3.0 in stage 106.0 (TID 346). 938 bytes result sent to driver
18/04/01 20:16:00 INFO Executor: Finished task 2.0 in stage 106.0 (TID 345). 938 bytes result sent to driver
18/04/01 20:16:00 INFO TaskSetManager: Starting task 4.0 in stage 106.0 (TID 347, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:00 INFO Executor: Running task 4.0 in stage 106.0 (TID 347)
18/04/01 20:16:00 INFO TaskSetManager: Finished task 3.0 in stage 106.0 (TID 346) in 7 ms on localhost (executor driver) (3/5)
18/04/01 20:16:00 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 723 -> 724
18/04/01 20:16:00 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 723
18/04/01 20:16:00 INFO TaskSetManager: Finished task 2.0 in stage 106.0 (TID 345) in 12 ms on localhost (executor driver) (4/5)
18/04/01 20:16:00 INFO Executor: Finished task 4.0 in stage 106.0 (TID 347). 1024 bytes result sent to driver
18/04/01 20:16:00 INFO TaskSetManager: Finished task 4.0 in stage 106.0 (TID 347) in 474 ms on localhost (executor driver) (5/5)
18/04/01 20:16:00 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool 
18/04/01 20:16:00 INFO DAGScheduler: ShuffleMapStage 106 (map at RefereeStats.scala:53) finished in 0.496 s
18/04/01 20:16:00 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:16:00 INFO DAGScheduler: running: Set()
18/04/01 20:16:00 INFO DAGScheduler: waiting: Set(ResultStage 107)
18/04/01 20:16:00 INFO DAGScheduler: failed: Set()
18/04/01 20:16:00 INFO DAGScheduler: Submitting ResultStage 107 (ShuffledRDD[93] at reduceByKey at RefereeStats.scala:60), which has no missing parents
18/04/01 20:16:00 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:16:00 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 1706.0 B, free 477.2 MB)
18/04/01 20:16:00 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 192.168.1.3:35449 (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:16:00 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 107 (ShuffledRDD[93] at reduceByKey at RefereeStats.scala:60) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:16:00 INFO TaskSchedulerImpl: Adding task set 107.0 with 2 tasks
18/04/01 20:16:00 INFO TaskSetManager: Starting task 1.0 in stage 107.0 (TID 348, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:00 INFO TaskSetManager: Starting task 0.0 in stage 107.0 (TID 349, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:16:00 INFO Executor: Running task 0.0 in stage 107.0 (TID 349)
18/04/01 20:16:00 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:16:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:00 INFO Executor: Running task 1.0 in stage 107.0 (TID 348)
18/04/01 20:16:00 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:00 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:16:00 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:00 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:00 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:00 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:00 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:00 INFO KafkaProducer: [Producer clientId=producer-80] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:00 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:16:00 INFO KafkaProducer: [Producer clientId=producer-79] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:00 INFO Executor: Finished task 1.0 in stage 107.0 (TID 348). 1138 bytes result sent to driver
18/04/01 20:16:00 INFO TaskSetManager: Finished task 1.0 in stage 107.0 (TID 348) in 31 ms on localhost (executor driver) (1/2)
18/04/01 20:16:00 INFO Executor: Finished task 0.0 in stage 107.0 (TID 349). 1138 bytes result sent to driver
18/04/01 20:16:00 INFO TaskSetManager: Finished task 0.0 in stage 107.0 (TID 349) in 40 ms on localhost (executor driver) (2/2)
18/04/01 20:16:00 INFO TaskSchedulerImpl: Removed TaskSet 107.0, whose tasks have all completed, from pool 
18/04/01 20:16:00 INFO DAGScheduler: ResultStage 107 (foreachPartition at RefereeStats.scala:71) finished in 0.053 s
18/04/01 20:16:00 INFO DAGScheduler: Job 67 finished: foreachPartition at RefereeStats.scala:71, took 0.555819 s
18/04/01 20:16:00 INFO JobScheduler: Finished job streaming job 1522602960000 ms.1 from job set of time 1522602960000 ms
18/04/01 20:16:00 INFO JobScheduler: Starting job streaming job 1522602960000 ms.2 from job set of time 1522602960000 ms
18/04/01 20:16:00 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:89
18/04/01 20:16:00 INFO DAGScheduler: Registering RDD 94 (map at RefereeStats.scala:46)
18/04/01 20:16:00 INFO DAGScheduler: Got job 68 (foreachPartition at RefereeStats.scala:89) with 2 output partitions
18/04/01 20:16:00 INFO DAGScheduler: Final stage: ResultStage 109 (foreachPartition at RefereeStats.scala:89)
18/04/01 20:16:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 108)
18/04/01 20:16:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 108)
18/04/01 20:16:00 INFO DAGScheduler: Submitting ShuffleMapStage 108 (MapPartitionsRDD[94] at map at RefereeStats.scala:46), which has no missing parents
18/04/01 20:16:00 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:16:00 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:16:00 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:00 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:00 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 108 (MapPartitionsRDD[94] at map at RefereeStats.scala:46) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:16:00 INFO TaskSchedulerImpl: Adding task set 108.0 with 5 tasks
18/04/01 20:16:00 INFO TaskSetManager: Starting task 0.0 in stage 108.0 (TID 350, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:00 INFO TaskSetManager: Starting task 1.0 in stage 108.0 (TID 351, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:00 INFO Executor: Running task 0.0 in stage 108.0 (TID 350)
18/04/01 20:16:00 INFO Executor: Running task 1.0 in stage 108.0 (TID 351)
18/04/01 20:16:00 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:00 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:00 INFO Executor: Finished task 1.0 in stage 108.0 (TID 351). 938 bytes result sent to driver
18/04/01 20:16:00 INFO TaskSetManager: Starting task 2.0 in stage 108.0 (TID 352, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:00 INFO TaskSetManager: Finished task 1.0 in stage 108.0 (TID 351) in 7 ms on localhost (executor driver) (1/5)
18/04/01 20:16:00 INFO Executor: Running task 2.0 in stage 108.0 (TID 352)
18/04/01 20:16:00 INFO Executor: Finished task 0.0 in stage 108.0 (TID 350). 938 bytes result sent to driver
18/04/01 20:16:00 INFO TaskSetManager: Starting task 3.0 in stage 108.0 (TID 353, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:00 INFO TaskSetManager: Finished task 0.0 in stage 108.0 (TID 350) in 11 ms on localhost (executor driver) (2/5)
18/04/01 20:16:00 INFO Executor: Running task 3.0 in stage 108.0 (TID 353)
18/04/01 20:16:00 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:00 INFO Executor: Finished task 3.0 in stage 108.0 (TID 353). 938 bytes result sent to driver
18/04/01 20:16:00 INFO TaskSetManager: Starting task 4.0 in stage 108.0 (TID 354, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:00 INFO Executor: Running task 4.0 in stage 108.0 (TID 354)
18/04/01 20:16:00 INFO TaskSetManager: Finished task 3.0 in stage 108.0 (TID 353) in 7 ms on localhost (executor driver) (3/5)
18/04/01 20:16:00 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 723 -> 724
18/04/01 20:16:00 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 723
18/04/01 20:16:00 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:00 INFO Executor: Finished task 2.0 in stage 108.0 (TID 352). 938 bytes result sent to driver
18/04/01 20:16:00 INFO TaskSetManager: Finished task 2.0 in stage 108.0 (TID 352) in 19 ms on localhost (executor driver) (4/5)
18/04/01 20:16:00 INFO Executor: Finished task 4.0 in stage 108.0 (TID 354). 1024 bytes result sent to driver
18/04/01 20:16:00 INFO TaskSetManager: Finished task 4.0 in stage 108.0 (TID 354) in 40 ms on localhost (executor driver) (5/5)
18/04/01 20:16:00 INFO TaskSchedulerImpl: Removed TaskSet 108.0, whose tasks have all completed, from pool 
18/04/01 20:16:00 INFO DAGScheduler: ShuffleMapStage 108 (map at RefereeStats.scala:46) finished in 0.067 s
18/04/01 20:16:00 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:16:00 INFO DAGScheduler: running: Set()
18/04/01 20:16:00 INFO DAGScheduler: waiting: Set(ResultStage 109)
18/04/01 20:16:00 INFO DAGScheduler: failed: Set()
18/04/01 20:16:00 INFO DAGScheduler: Submitting ResultStage 109 (ShuffledRDD[95] at reduceByKey at RefereeStats.scala:51), which has no missing parents
18/04/01 20:16:00 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:16:00 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 1709.0 B, free 477.2 MB)
18/04/01 20:16:00 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 192.168.1.3:35449 (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:16:00 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 109 (ShuffledRDD[95] at reduceByKey at RefereeStats.scala:51) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:16:00 INFO TaskSchedulerImpl: Adding task set 109.0 with 2 tasks
18/04/01 20:16:00 INFO TaskSetManager: Starting task 1.0 in stage 109.0 (TID 355, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:00 INFO TaskSetManager: Starting task 0.0 in stage 109.0 (TID 356, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:16:00 INFO Executor: Running task 0.0 in stage 109.0 (TID 356)
18/04/01 20:16:00 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:16:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:00 INFO Executor: Running task 1.0 in stage 109.0 (TID 355)
18/04/01 20:16:00 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:00 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:00 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:00 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:00 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:00 INFO KafkaProducer: [Producer clientId=producer-81] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:00 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:00 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:00 INFO Executor: Finished task 1.0 in stage 109.0 (TID 355). 1138 bytes result sent to driver
18/04/01 20:16:00 INFO TaskSetManager: Finished task 1.0 in stage 109.0 (TID 355) in 20 ms on localhost (executor driver) (1/2)
18/04/01 20:16:00 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:16:00 INFO KafkaProducer: [Producer clientId=producer-82] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:00 INFO Executor: Finished task 0.0 in stage 109.0 (TID 356). 1138 bytes result sent to driver
18/04/01 20:16:00 INFO TaskSetManager: Finished task 0.0 in stage 109.0 (TID 356) in 36 ms on localhost (executor driver) (2/2)
18/04/01 20:16:00 INFO TaskSchedulerImpl: Removed TaskSet 109.0, whose tasks have all completed, from pool 
18/04/01 20:16:00 INFO DAGScheduler: ResultStage 109 (foreachPartition at RefereeStats.scala:89) finished in 0.048 s
18/04/01 20:16:00 INFO DAGScheduler: Job 68 finished: foreachPartition at RefereeStats.scala:89, took 0.126650 s
18/04/01 20:16:00 INFO JobScheduler: Finished job streaming job 1522602960000 ms.2 from job set of time 1522602960000 ms
18/04/01 20:16:00 INFO JobScheduler: Starting job streaming job 1522602960000 ms.3 from job set of time 1522602960000 ms
18/04/01 20:16:00 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:106
18/04/01 20:16:00 INFO DAGScheduler: Registering RDD 96 (map at RefereeStats.scala:39)
18/04/01 20:16:00 INFO DAGScheduler: Got job 69 (foreachPartition at RefereeStats.scala:106) with 2 output partitions
18/04/01 20:16:00 INFO DAGScheduler: Final stage: ResultStage 111 (foreachPartition at RefereeStats.scala:106)
18/04/01 20:16:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 110)
18/04/01 20:16:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 110)
18/04/01 20:16:00 INFO DAGScheduler: Submitting ShuffleMapStage 110 (MapPartitionsRDD[96] at map at RefereeStats.scala:39), which has no missing parents
18/04/01 20:16:00 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:16:00 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:16:00 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:00 INFO SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:00 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 110 (MapPartitionsRDD[96] at map at RefereeStats.scala:39) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:16:00 INFO TaskSchedulerImpl: Adding task set 110.0 with 5 tasks
18/04/01 20:16:00 INFO TaskSetManager: Starting task 0.0 in stage 110.0 (TID 357, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:00 INFO TaskSetManager: Starting task 1.0 in stage 110.0 (TID 358, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:00 INFO Executor: Running task 0.0 in stage 110.0 (TID 357)
18/04/01 20:16:00 INFO Executor: Running task 1.0 in stage 110.0 (TID 358)
18/04/01 20:16:00 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:00 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:00 INFO Executor: Finished task 0.0 in stage 110.0 (TID 357). 938 bytes result sent to driver
18/04/01 20:16:00 INFO Executor: Finished task 1.0 in stage 110.0 (TID 358). 938 bytes result sent to driver
18/04/01 20:16:00 INFO TaskSetManager: Starting task 2.0 in stage 110.0 (TID 359, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:00 INFO Executor: Running task 2.0 in stage 110.0 (TID 359)
18/04/01 20:16:00 INFO TaskSetManager: Finished task 0.0 in stage 110.0 (TID 357) in 7 ms on localhost (executor driver) (1/5)
18/04/01 20:16:00 INFO TaskSetManager: Starting task 3.0 in stage 110.0 (TID 360, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:00 INFO Executor: Running task 3.0 in stage 110.0 (TID 360)
18/04/01 20:16:00 INFO TaskSetManager: Finished task 1.0 in stage 110.0 (TID 358) in 10 ms on localhost (executor driver) (2/5)
18/04/01 20:16:00 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:00 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:00 INFO Executor: Finished task 2.0 in stage 110.0 (TID 359). 938 bytes result sent to driver
18/04/01 20:16:00 INFO Executor: Finished task 3.0 in stage 110.0 (TID 360). 938 bytes result sent to driver
18/04/01 20:16:00 INFO TaskSetManager: Starting task 4.0 in stage 110.0 (TID 361, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:00 INFO TaskSetManager: Finished task 2.0 in stage 110.0 (TID 359) in 11 ms on localhost (executor driver) (3/5)
18/04/01 20:16:00 INFO Executor: Running task 4.0 in stage 110.0 (TID 361)
18/04/01 20:16:00 INFO TaskSetManager: Finished task 3.0 in stage 110.0 (TID 360) in 8 ms on localhost (executor driver) (4/5)
18/04/01 20:16:00 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 723 -> 724
18/04/01 20:16:00 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 723
18/04/01 20:16:01 INFO Executor: Finished task 4.0 in stage 110.0 (TID 361). 1024 bytes result sent to driver
18/04/01 20:16:01 INFO TaskSetManager: Finished task 4.0 in stage 110.0 (TID 361) in 413 ms on localhost (executor driver) (5/5)
18/04/01 20:16:01 INFO TaskSchedulerImpl: Removed TaskSet 110.0, whose tasks have all completed, from pool 
18/04/01 20:16:01 INFO DAGScheduler: ShuffleMapStage 110 (map at RefereeStats.scala:39) finished in 0.438 s
18/04/01 20:16:01 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:16:01 INFO DAGScheduler: running: Set()
18/04/01 20:16:01 INFO DAGScheduler: waiting: Set(ResultStage 111)
18/04/01 20:16:01 INFO DAGScheduler: failed: Set()
18/04/01 20:16:01 INFO DAGScheduler: Submitting ResultStage 111 (ShuffledRDD[97] at reduceByKey at RefereeStats.scala:43), which has no missing parents
18/04/01 20:16:01 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:16:01 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 1704.0 B, free 477.2 MB)
18/04/01 20:16:01 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 192.168.1.3:35449 (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:16:01 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:01 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 111 (ShuffledRDD[97] at reduceByKey at RefereeStats.scala:43) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:16:01 INFO TaskSchedulerImpl: Adding task set 111.0 with 2 tasks
18/04/01 20:16:01 INFO TaskSetManager: Starting task 1.0 in stage 111.0 (TID 362, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:01 INFO TaskSetManager: Starting task 0.0 in stage 111.0 (TID 363, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:16:01 INFO Executor: Running task 1.0 in stage 111.0 (TID 362)
18/04/01 20:16:01 INFO Executor: Running task 0.0 in stage 111.0 (TID 363)
18/04/01 20:16:01 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:01 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:16:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:16:01 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:01 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:01 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:01 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:01 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:01 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:01 INFO KafkaProducer: [Producer clientId=producer-83] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:01 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:16:01 INFO KafkaProducer: [Producer clientId=producer-84] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:01 INFO Executor: Finished task 1.0 in stage 111.0 (TID 362). 1138 bytes result sent to driver
18/04/01 20:16:01 INFO TaskSetManager: Finished task 1.0 in stage 111.0 (TID 362) in 27 ms on localhost (executor driver) (1/2)
18/04/01 20:16:01 INFO Executor: Finished task 0.0 in stage 111.0 (TID 363). 1138 bytes result sent to driver
18/04/01 20:16:01 INFO TaskSetManager: Finished task 0.0 in stage 111.0 (TID 363) in 41 ms on localhost (executor driver) (2/2)
18/04/01 20:16:01 INFO TaskSchedulerImpl: Removed TaskSet 111.0, whose tasks have all completed, from pool 
18/04/01 20:16:01 INFO DAGScheduler: ResultStage 111 (foreachPartition at RefereeStats.scala:106) finished in 0.056 s
18/04/01 20:16:01 INFO DAGScheduler: Job 69 finished: foreachPartition at RefereeStats.scala:106, took 0.503223 s
18/04/01 20:16:01 INFO JobScheduler: Finished job streaming job 1522602960000 ms.3 from job set of time 1522602960000 ms
18/04/01 20:16:01 INFO JobScheduler: Total delay: 1.319 s for time 1522602960000 ms (execution: 1.290 s)
18/04/01 20:16:01 INFO MapPartitionsRDD: Removing RDD 85 from persistence list
18/04/01 20:16:01 INFO BlockManager: Removing RDD 85
18/04/01 20:16:01 INFO KafkaRDD: Removing RDD 84 from persistence list
18/04/01 20:16:01 INFO BlockManager: Removing RDD 84
18/04/01 20:16:01 INFO ShuffledRDD: Removing RDD 86 from persistence list
18/04/01 20:16:01 INFO BlockManager: Removing RDD 86
18/04/01 20:16:01 INFO ShuffledRDD: Removing RDD 88 from persistence list
18/04/01 20:16:01 INFO BlockManager: Removing RDD 88
18/04/01 20:16:01 INFO MapPartitionsRDD: Removing RDD 87 from persistence list
18/04/01 20:16:01 INFO BlockManager: Removing RDD 87
18/04/01 20:16:01 INFO ShuffledRDD: Removing RDD 90 from persistence list
18/04/01 20:16:01 INFO BlockManager: Removing RDD 90
18/04/01 20:16:01 INFO MapPartitionsRDD: Removing RDD 89 from persistence list
18/04/01 20:16:01 INFO BlockManager: Removing RDD 89
18/04/01 20:16:01 INFO JobGenerator: Checkpointing graph for time 1522602960000 ms
18/04/01 20:16:01 INFO DStreamGraph: Updating checkpoint data for time 1522602960000 ms
18/04/01 20:16:01 INFO DStreamGraph: Updated checkpoint data for time 1522602960000 ms
18/04/01 20:16:01 INFO CheckpointWriter: Submitted checkpoint of time 1522602960000 ms to writer queue
18/04/01 20:16:01 INFO CheckpointWriter: Saving checkpoint for time 1522602960000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602960000'
18/04/01 20:16:01 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602935000
18/04/01 20:16:01 INFO CheckpointWriter: Checkpoint for time 1522602960000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602960000', took 5537 bytes and 23 ms
18/04/01 20:16:01 INFO DStreamGraph: Clearing checkpoint data for time 1522602960000 ms
18/04/01 20:16:01 INFO DStreamGraph: Cleared checkpoint data for time 1522602960000 ms
18/04/01 20:16:01 INFO ReceivedBlockTracker: Deleting batches: 
18/04/01 20:16:01 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/tmp/refs-xyzabb/receivedBlockMetadata older than 1522602955000: 
18/04/01 20:16:01 INFO InputInfoTracker: remove old batch metadata: 1522602950000 ms
18/04/01 20:16:05 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-0 to offset 726.
18/04/01 20:16:05 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-3 to offset 0.
18/04/01 20:16:05 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-4 to offset 0.
18/04/01 20:16:05 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-1 to offset 0.
18/04/01 20:16:05 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-2 to offset 0.
18/04/01 20:16:05 INFO JobScheduler: Added jobs for time 1522602965000 ms
18/04/01 20:16:05 INFO JobGenerator: Checkpointing graph for time 1522602965000 ms
18/04/01 20:16:05 INFO DStreamGraph: Updating checkpoint data for time 1522602965000 ms
18/04/01 20:16:05 INFO DStreamGraph: Updated checkpoint data for time 1522602965000 ms
18/04/01 20:16:05 INFO CheckpointWriter: Submitted checkpoint of time 1522602965000 ms to writer queue
18/04/01 20:16:05 INFO CheckpointWriter: Saving checkpoint for time 1522602965000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602965000'
18/04/01 20:16:05 INFO JobScheduler: Starting job streaming job 1522602965000 ms.0 from job set of time 1522602965000 ms
18/04/01 20:16:05 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:16:05 INFO DAGScheduler: Got job 70 (print at RefereeStats.scala:67) with 1 output partitions
18/04/01 20:16:05 INFO DAGScheduler: Final stage: ResultStage 112 (print at RefereeStats.scala:67)
18/04/01 20:16:05 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:16:05 INFO DAGScheduler: Missing parents: List()
18/04/01 20:16:05 INFO DAGScheduler: Submitting ResultStage 112 (MapPartitionsRDD[99] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:16:05 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 3.0 KB, free 477.2 MB)
18/04/01 20:16:05 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.2 MB)
18/04/01 20:16:05 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:05 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 112 (MapPartitionsRDD[99] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0))
18/04/01 20:16:05 INFO TaskSchedulerImpl: Adding task set 112.0 with 1 tasks
18/04/01 20:16:05 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602940000.bk
18/04/01 20:16:05 INFO TaskSetManager: Starting task 0.0 in stage 112.0 (TID 364, localhost, executor driver, partition 0, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:05 INFO CheckpointWriter: Checkpoint for time 1522602965000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602965000', took 5605 bytes and 31 ms
18/04/01 20:16:05 INFO Executor: Running task 0.0 in stage 112.0 (TID 364)
18/04/01 20:16:05 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:05 INFO Executor: Finished task 0.0 in stage 112.0 (TID 364). 704 bytes result sent to driver
18/04/01 20:16:05 INFO TaskSetManager: Finished task 0.0 in stage 112.0 (TID 364) in 5 ms on localhost (executor driver) (1/1)
18/04/01 20:16:05 INFO TaskSchedulerImpl: Removed TaskSet 112.0, whose tasks have all completed, from pool 
18/04/01 20:16:05 INFO DAGScheduler: ResultStage 112 (print at RefereeStats.scala:67) finished in 0.022 s
18/04/01 20:16:05 INFO DAGScheduler: Job 70 finished: print at RefereeStats.scala:67, took 0.026007 s
18/04/01 20:16:05 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:16:05 INFO DAGScheduler: Got job 71 (print at RefereeStats.scala:67) with 4 output partitions
18/04/01 20:16:05 INFO DAGScheduler: Final stage: ResultStage 113 (print at RefereeStats.scala:67)
18/04/01 20:16:05 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:16:05 INFO DAGScheduler: Missing parents: List()
18/04/01 20:16:05 INFO DAGScheduler: Submitting ResultStage 113 (MapPartitionsRDD[99] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:16:05 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 3.0 KB, free 477.2 MB)
18/04/01 20:16:05 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.2 MB)
18/04/01 20:16:05 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:05 INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:05 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 113 (MapPartitionsRDD[99] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
18/04/01 20:16:05 INFO TaskSchedulerImpl: Adding task set 113.0 with 4 tasks
18/04/01 20:16:05 INFO TaskSetManager: Starting task 0.0 in stage 113.0 (TID 365, localhost, executor driver, partition 1, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:05 INFO TaskSetManager: Starting task 1.0 in stage 113.0 (TID 366, localhost, executor driver, partition 2, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:05 INFO Executor: Running task 0.0 in stage 113.0 (TID 365)
18/04/01 20:16:05 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:05 INFO Executor: Finished task 0.0 in stage 113.0 (TID 365). 704 bytes result sent to driver
18/04/01 20:16:05 INFO Executor: Running task 1.0 in stage 113.0 (TID 366)
18/04/01 20:16:05 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:05 INFO Executor: Finished task 1.0 in stage 113.0 (TID 366). 661 bytes result sent to driver
18/04/01 20:16:05 INFO TaskSetManager: Starting task 2.0 in stage 113.0 (TID 367, localhost, executor driver, partition 3, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:05 INFO TaskSetManager: Finished task 0.0 in stage 113.0 (TID 365) in 9 ms on localhost (executor driver) (1/4)
18/04/01 20:16:05 INFO Executor: Running task 2.0 in stage 113.0 (TID 367)
18/04/01 20:16:05 INFO TaskSetManager: Finished task 1.0 in stage 113.0 (TID 366) in 8 ms on localhost (executor driver) (2/4)
18/04/01 20:16:05 INFO TaskSetManager: Starting task 3.0 in stage 113.0 (TID 368, localhost, executor driver, partition 4, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:05 INFO Executor: Running task 3.0 in stage 113.0 (TID 368)
18/04/01 20:16:05 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:05 INFO Executor: Finished task 2.0 in stage 113.0 (TID 367). 704 bytes result sent to driver
18/04/01 20:16:05 INFO TaskSetManager: Finished task 2.0 in stage 113.0 (TID 367) in 6 ms on localhost (executor driver) (3/4)
18/04/01 20:16:05 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 724 -> 726
18/04/01 20:16:05 INFO Executor: Finished task 3.0 in stage 113.0 (TID 368). 890 bytes result sent to driver
18/04/01 20:16:05 INFO TaskSetManager: Finished task 3.0 in stage 113.0 (TID 368) in 13 ms on localhost (executor driver) (4/4)
18/04/01 20:16:05 INFO TaskSchedulerImpl: Removed TaskSet 113.0, whose tasks have all completed, from pool 
18/04/01 20:16:05 INFO DAGScheduler: ResultStage 113 (print at RefereeStats.scala:67) finished in 0.029 s
18/04/01 20:16:05 INFO DAGScheduler: Job 71 finished: print at RefereeStats.scala:67, took 0.034314 s
18/04/01 20:16:05 INFO JobScheduler: Finished job streaming job 1522602965000 ms.0 from job set of time 1522602965000 ms
18/04/01 20:16:05 INFO JobScheduler: Starting job streaming job 1522602965000 ms.1 from job set of time 1522602965000 ms
-------------------------------------------
Time: 1522602965000 ms
-------------------------------------------
(instagram.*,0)
(vk.com,20000)

18/04/01 20:16:05 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:71
18/04/01 20:16:05 INFO DAGScheduler: Registering RDD 99 (map at RefereeStats.scala:53)
18/04/01 20:16:05 INFO DAGScheduler: Got job 72 (foreachPartition at RefereeStats.scala:71) with 2 output partitions
18/04/01 20:16:05 INFO DAGScheduler: Final stage: ResultStage 115 (foreachPartition at RefereeStats.scala:71)
18/04/01 20:16:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 114)
18/04/01 20:16:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 114)
18/04/01 20:16:05 INFO DAGScheduler: Submitting ShuffleMapStage 114 (MapPartitionsRDD[99] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:16:05 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:16:05 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:16:05 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:05 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:05 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 114 (MapPartitionsRDD[99] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:16:05 INFO TaskSchedulerImpl: Adding task set 114.0 with 5 tasks
18/04/01 20:16:05 INFO TaskSetManager: Starting task 0.0 in stage 114.0 (TID 369, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:05 INFO TaskSetManager: Starting task 1.0 in stage 114.0 (TID 370, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:05 INFO Executor: Running task 0.0 in stage 114.0 (TID 369)
18/04/01 20:16:05 INFO Executor: Running task 1.0 in stage 114.0 (TID 370)
18/04/01 20:16:05 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:05 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:05 INFO Executor: Finished task 0.0 in stage 114.0 (TID 369). 938 bytes result sent to driver
18/04/01 20:16:05 INFO Executor: Finished task 1.0 in stage 114.0 (TID 370). 938 bytes result sent to driver
18/04/01 20:16:05 INFO TaskSetManager: Starting task 2.0 in stage 114.0 (TID 371, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:05 INFO Executor: Running task 2.0 in stage 114.0 (TID 371)
18/04/01 20:16:05 INFO TaskSetManager: Starting task 3.0 in stage 114.0 (TID 372, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:05 INFO TaskSetManager: Finished task 1.0 in stage 114.0 (TID 370) in 7 ms on localhost (executor driver) (1/5)
18/04/01 20:16:05 INFO TaskSetManager: Finished task 0.0 in stage 114.0 (TID 369) in 8 ms on localhost (executor driver) (2/5)
18/04/01 20:16:05 INFO Executor: Running task 3.0 in stage 114.0 (TID 372)
18/04/01 20:16:05 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:05 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:05 INFO Executor: Finished task 2.0 in stage 114.0 (TID 371). 938 bytes result sent to driver
18/04/01 20:16:05 INFO Executor: Finished task 3.0 in stage 114.0 (TID 372). 938 bytes result sent to driver
18/04/01 20:16:05 INFO TaskSetManager: Starting task 4.0 in stage 114.0 (TID 373, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:05 INFO Executor: Running task 4.0 in stage 114.0 (TID 373)
18/04/01 20:16:05 INFO TaskSetManager: Finished task 2.0 in stage 114.0 (TID 371) in 7 ms on localhost (executor driver) (3/5)
18/04/01 20:16:05 INFO TaskSetManager: Finished task 3.0 in stage 114.0 (TID 372) in 6 ms on localhost (executor driver) (4/5)
18/04/01 20:16:05 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 724 -> 726
18/04/01 20:16:05 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 724
18/04/01 20:16:05 INFO Executor: Finished task 4.0 in stage 114.0 (TID 373). 1024 bytes result sent to driver
18/04/01 20:16:05 INFO TaskSetManager: Finished task 4.0 in stage 114.0 (TID 373) in 470 ms on localhost (executor driver) (5/5)
18/04/01 20:16:05 INFO TaskSchedulerImpl: Removed TaskSet 114.0, whose tasks have all completed, from pool 
18/04/01 20:16:05 INFO DAGScheduler: ShuffleMapStage 114 (map at RefereeStats.scala:53) finished in 0.490 s
18/04/01 20:16:05 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:16:05 INFO DAGScheduler: running: Set()
18/04/01 20:16:05 INFO DAGScheduler: waiting: Set(ResultStage 115)
18/04/01 20:16:05 INFO DAGScheduler: failed: Set()
18/04/01 20:16:05 INFO DAGScheduler: Submitting ResultStage 115 (ShuffledRDD[100] at reduceByKey at RefereeStats.scala:60), which has no missing parents
18/04/01 20:16:05 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:16:05 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 1704.0 B, free 477.2 MB)
18/04/01 20:16:05 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 192.168.1.3:35449 (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:16:05 INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 115 (ShuffledRDD[100] at reduceByKey at RefereeStats.scala:60) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:16:05 INFO TaskSchedulerImpl: Adding task set 115.0 with 2 tasks
18/04/01 20:16:05 INFO TaskSetManager: Starting task 1.0 in stage 115.0 (TID 374, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:05 INFO TaskSetManager: Starting task 0.0 in stage 115.0 (TID 375, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:16:05 INFO Executor: Running task 1.0 in stage 115.0 (TID 374)
18/04/01 20:16:05 INFO Executor: Running task 0.0 in stage 115.0 (TID 375)
18/04/01 20:16:05 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:05 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:16:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:05 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:05 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:05 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:05 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:05 INFO KafkaProducer: [Producer clientId=producer-85] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:05 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:05 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:05 INFO Executor: Finished task 1.0 in stage 115.0 (TID 374). 1138 bytes result sent to driver
18/04/01 20:16:05 INFO TaskSetManager: Finished task 1.0 in stage 115.0 (TID 374) in 13 ms on localhost (executor driver) (1/2)
18/04/01 20:16:05 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:16:05 INFO KafkaProducer: [Producer clientId=producer-86] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:05 INFO Executor: Finished task 0.0 in stage 115.0 (TID 375). 1138 bytes result sent to driver
18/04/01 20:16:05 INFO TaskSetManager: Finished task 0.0 in stage 115.0 (TID 375) in 27 ms on localhost (executor driver) (2/2)
18/04/01 20:16:05 INFO TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool 
18/04/01 20:16:05 INFO DAGScheduler: ResultStage 115 (foreachPartition at RefereeStats.scala:71) finished in 0.036 s
18/04/01 20:16:05 INFO DAGScheduler: Job 72 finished: foreachPartition at RefereeStats.scala:71, took 0.533951 s
18/04/01 20:16:05 INFO JobScheduler: Finished job streaming job 1522602965000 ms.1 from job set of time 1522602965000 ms
18/04/01 20:16:05 INFO JobScheduler: Starting job streaming job 1522602965000 ms.2 from job set of time 1522602965000 ms
18/04/01 20:16:05 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:89
18/04/01 20:16:05 INFO DAGScheduler: Registering RDD 101 (map at RefereeStats.scala:46)
18/04/01 20:16:05 INFO DAGScheduler: Got job 73 (foreachPartition at RefereeStats.scala:89) with 2 output partitions
18/04/01 20:16:05 INFO DAGScheduler: Final stage: ResultStage 117 (foreachPartition at RefereeStats.scala:89)
18/04/01 20:16:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 116)
18/04/01 20:16:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 116)
18/04/01 20:16:05 INFO DAGScheduler: Submitting ShuffleMapStage 116 (MapPartitionsRDD[101] at map at RefereeStats.scala:46), which has no missing parents
18/04/01 20:16:05 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:16:05 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:16:05 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:05 INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:05 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 116 (MapPartitionsRDD[101] at map at RefereeStats.scala:46) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:16:05 INFO TaskSchedulerImpl: Adding task set 116.0 with 5 tasks
18/04/01 20:16:05 INFO TaskSetManager: Starting task 0.0 in stage 116.0 (TID 376, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:05 INFO TaskSetManager: Starting task 1.0 in stage 116.0 (TID 377, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:05 INFO Executor: Running task 1.0 in stage 116.0 (TID 377)
18/04/01 20:16:05 INFO Executor: Running task 0.0 in stage 116.0 (TID 376)
18/04/01 20:16:05 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:05 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:05 INFO Executor: Finished task 1.0 in stage 116.0 (TID 377). 938 bytes result sent to driver
18/04/01 20:16:05 INFO Executor: Finished task 0.0 in stage 116.0 (TID 376). 938 bytes result sent to driver
18/04/01 20:16:05 INFO TaskSetManager: Starting task 2.0 in stage 116.0 (TID 378, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:05 INFO Executor: Running task 2.0 in stage 116.0 (TID 378)
18/04/01 20:16:05 INFO TaskSetManager: Starting task 3.0 in stage 116.0 (TID 379, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:05 INFO TaskSetManager: Finished task 1.0 in stage 116.0 (TID 377) in 8 ms on localhost (executor driver) (1/5)
18/04/01 20:16:05 INFO TaskSetManager: Finished task 0.0 in stage 116.0 (TID 376) in 8 ms on localhost (executor driver) (2/5)
18/04/01 20:16:05 INFO Executor: Running task 3.0 in stage 116.0 (TID 379)
18/04/01 20:16:05 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:05 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:05 INFO Executor: Finished task 2.0 in stage 116.0 (TID 378). 938 bytes result sent to driver
18/04/01 20:16:05 INFO TaskSetManager: Starting task 4.0 in stage 116.0 (TID 380, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:05 INFO TaskSetManager: Finished task 2.0 in stage 116.0 (TID 378) in 7 ms on localhost (executor driver) (3/5)
18/04/01 20:16:05 INFO Executor: Finished task 3.0 in stage 116.0 (TID 379). 938 bytes result sent to driver
18/04/01 20:16:05 INFO Executor: Running task 4.0 in stage 116.0 (TID 380)
18/04/01 20:16:05 INFO TaskSetManager: Finished task 3.0 in stage 116.0 (TID 379) in 9 ms on localhost (executor driver) (4/5)
18/04/01 20:16:05 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 724 -> 726
18/04/01 20:16:05 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 724
18/04/01 20:16:06 INFO Executor: Finished task 4.0 in stage 116.0 (TID 380). 1024 bytes result sent to driver
18/04/01 20:16:06 INFO TaskSetManager: Finished task 4.0 in stage 116.0 (TID 380) in 433 ms on localhost (executor driver) (5/5)
18/04/01 20:16:06 INFO TaskSchedulerImpl: Removed TaskSet 116.0, whose tasks have all completed, from pool 
18/04/01 20:16:06 INFO DAGScheduler: ShuffleMapStage 116 (map at RefereeStats.scala:46) finished in 0.454 s
18/04/01 20:16:06 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:16:06 INFO DAGScheduler: running: Set()
18/04/01 20:16:06 INFO DAGScheduler: waiting: Set(ResultStage 117)
18/04/01 20:16:06 INFO DAGScheduler: failed: Set()
18/04/01 20:16:06 INFO DAGScheduler: Submitting ResultStage 117 (ShuffledRDD[102] at reduceByKey at RefereeStats.scala:51), which has no missing parents
18/04/01 20:16:06 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:16:06 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 1709.0 B, free 477.2 MB)
18/04/01 20:16:06 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 192.168.1.3:35449 (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:16:06 INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 117 (ShuffledRDD[102] at reduceByKey at RefereeStats.scala:51) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:16:06 INFO TaskSchedulerImpl: Adding task set 117.0 with 2 tasks
18/04/01 20:16:06 INFO TaskSetManager: Starting task 1.0 in stage 117.0 (TID 381, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:06 INFO TaskSetManager: Starting task 0.0 in stage 117.0 (TID 382, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:16:06 INFO Executor: Running task 0.0 in stage 117.0 (TID 382)
18/04/01 20:16:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:16:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:16:06 INFO Executor: Running task 1.0 in stage 117.0 (TID 381)
18/04/01 20:16:06 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:06 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:06 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:06 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:06 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:06 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:06 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:06 INFO KafkaProducer: [Producer clientId=producer-88] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:06 INFO Executor: Finished task 1.0 in stage 117.0 (TID 381). 1138 bytes result sent to driver
18/04/01 20:16:06 INFO TaskSetManager: Finished task 1.0 in stage 117.0 (TID 381) in 20 ms on localhost (executor driver) (1/2)
18/04/01 20:16:06 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:16:06 INFO KafkaProducer: [Producer clientId=producer-87] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:06 INFO Executor: Finished task 0.0 in stage 117.0 (TID 382). 1138 bytes result sent to driver
18/04/01 20:16:06 INFO TaskSetManager: Finished task 0.0 in stage 117.0 (TID 382) in 33 ms on localhost (executor driver) (2/2)
18/04/01 20:16:06 INFO TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool 
18/04/01 20:16:06 INFO DAGScheduler: ResultStage 117 (foreachPartition at RefereeStats.scala:89) finished in 0.043 s
18/04/01 20:16:06 INFO DAGScheduler: Job 73 finished: foreachPartition at RefereeStats.scala:89, took 0.505552 s
18/04/01 20:16:06 INFO JobScheduler: Finished job streaming job 1522602965000 ms.2 from job set of time 1522602965000 ms
18/04/01 20:16:06 INFO JobScheduler: Starting job streaming job 1522602965000 ms.3 from job set of time 1522602965000 ms
18/04/01 20:16:06 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:106
18/04/01 20:16:06 INFO DAGScheduler: Registering RDD 103 (map at RefereeStats.scala:39)
18/04/01 20:16:06 INFO DAGScheduler: Got job 74 (foreachPartition at RefereeStats.scala:106) with 2 output partitions
18/04/01 20:16:06 INFO DAGScheduler: Final stage: ResultStage 119 (foreachPartition at RefereeStats.scala:106)
18/04/01 20:16:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 118)
18/04/01 20:16:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 118)
18/04/01 20:16:06 INFO DAGScheduler: Submitting ShuffleMapStage 118 (MapPartitionsRDD[103] at map at RefereeStats.scala:39), which has no missing parents
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2759
18/04/01 20:16:06 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2799
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2623
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2858
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2931
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2583
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2921
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2465
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2538
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2481
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2601
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2688
18/04/01 20:16:06 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:16:06 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:16:06 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:06 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2822
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2805
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2460
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2695
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2525
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2736
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2547
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2602
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2845
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2824
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2658
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2466
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2850
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2715
18/04/01 20:16:06 INFO SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2456
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2719
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2535
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2740
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2621
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2530
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2718
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2809
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2618
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2672
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2501
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2758
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2735
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2532
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2634
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2818
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2694
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2942
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2764
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2911
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2613
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2730
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2904
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2540
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2487
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2923
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2524
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2584
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2762
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2837
18/04/01 20:16:06 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 118 (MapPartitionsRDD[103] at map at RefereeStats.scala:39) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2866
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2864
18/04/01 20:16:06 INFO TaskSchedulerImpl: Adding task set 118.0 with 5 tasks
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2855
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2870
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2823
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2506
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2705
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2808
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2591
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2531
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2946
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2523
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2679
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2763
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2772
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2605
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2473
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2675
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2452
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2699
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2717
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2549
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2771
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2568
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2478
18/04/01 20:16:06 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 192.168.1.3:35449 in memory (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:16:06 INFO TaskSetManager: Starting task 0.0 in stage 118.0 (TID 383, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:06 INFO TaskSetManager: Starting task 1.0 in stage 118.0 (TID 384, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:06 INFO Executor: Running task 0.0 in stage 118.0 (TID 383)
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2792
18/04/01 20:16:06 INFO Executor: Running task 1.0 in stage 118.0 (TID 384)
18/04/01 20:16:06 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:06 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:06 INFO Executor: Finished task 0.0 in stage 118.0 (TID 383). 938 bytes result sent to driver
18/04/01 20:16:06 INFO TaskSetManager: Starting task 2.0 in stage 118.0 (TID 385, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:06 INFO Executor: Running task 2.0 in stage 118.0 (TID 385)
18/04/01 20:16:06 INFO TaskSetManager: Finished task 0.0 in stage 118.0 (TID 383) in 9 ms on localhost (executor driver) (1/5)
18/04/01 20:16:06 INFO ContextCleaner: Cleaned shuffle 37
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2746
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2492
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2578
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2848
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2878
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2891
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2510
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2816
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2519
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2562
18/04/01 20:16:06 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:06 INFO Executor: Finished task 2.0 in stage 118.0 (TID 385). 938 bytes result sent to driver
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2450
18/04/01 20:16:06 INFO TaskSetManager: Starting task 3.0 in stage 118.0 (TID 386, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:06 INFO Executor: Running task 3.0 in stage 118.0 (TID 386)
18/04/01 20:16:06 INFO TaskSetManager: Finished task 2.0 in stage 118.0 (TID 385) in 7 ms on localhost (executor driver) (2/5)
18/04/01 20:16:06 INFO Executor: Finished task 1.0 in stage 118.0 (TID 384). 938 bytes result sent to driver
18/04/01 20:16:06 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:06 INFO TaskSetManager: Finished task 1.0 in stage 118.0 (TID 384) in 17 ms on localhost (executor driver) (3/5)
18/04/01 20:16:06 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:06 INFO TaskSetManager: Starting task 4.0 in stage 118.0 (TID 387, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:06 INFO Executor: Finished task 3.0 in stage 118.0 (TID 386). 938 bytes result sent to driver
18/04/01 20:16:06 INFO Executor: Running task 4.0 in stage 118.0 (TID 387)
18/04/01 20:16:06 INFO TaskSetManager: Finished task 3.0 in stage 118.0 (TID 386) in 7 ms on localhost (executor driver) (4/5)
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2587
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2480
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2631
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2925
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2490
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2813
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2518
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2876
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2747
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2884
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2498
18/04/01 20:16:06 INFO BlockManagerInfo: Removed broadcast_109_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2909
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2833
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2853
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2862
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2607
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2780
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2937
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2875
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2928
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2526
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2600
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2865
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2626
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2782
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2663
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2637
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2455
18/04/01 20:16:06 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 724 -> 726
18/04/01 20:16:06 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 724
18/04/01 20:16:06 INFO ContextCleaner: Cleaned shuffle 34
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2499
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2620
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2683
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2924
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2486
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2652
18/04/01 20:16:06 INFO BlockManagerInfo: Removed broadcast_105_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2569
18/04/01 20:16:06 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2655
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2817
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2534
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2831
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2915
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2550
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2779
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2687
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2760
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2664
18/04/01 20:16:06 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:06 INFO Executor: Finished task 4.0 in stage 118.0 (TID 387). 1024 bytes result sent to driver
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2646
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2838
18/04/01 20:16:06 INFO TaskSetManager: Finished task 4.0 in stage 118.0 (TID 387) in 24 ms on localhost (executor driver) (5/5)
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2521
18/04/01 20:16:06 INFO TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool 
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2926
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2517
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2750
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2885
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2564
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2781
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2537
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2847
18/04/01 20:16:06 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 192.168.1.3:35449 in memory (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:16:06 INFO DAGScheduler: ShuffleMapStage 118 (map at RefereeStats.scala:39) finished in 0.053 s
18/04/01 20:16:06 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:16:06 INFO DAGScheduler: running: Set()
18/04/01 20:16:06 INFO DAGScheduler: waiting: Set(ResultStage 119)
18/04/01 20:16:06 INFO DAGScheduler: failed: Set()
18/04/01 20:16:06 INFO DAGScheduler: Submitting ResultStage 119 (ShuffledRDD[104] at reduceByKey at RefereeStats.scala:43), which has no missing parents
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2888
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2471
18/04/01 20:16:06 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:16:06 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 192.168.1.3:35449 in memory (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2916
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2552
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2882
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2900
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2821
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2622
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2586
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2725
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2791
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2886
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2493
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2596
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2710
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2944
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2811
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2475
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2828
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2470
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2505
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2617
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2576
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2773
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2649
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2539
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2776
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2777
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2633
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2721
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2594
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2629
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2872
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2653
18/04/01 20:16:06 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 1704.0 B, free 477.2 MB)
18/04/01 20:16:06 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 192.168.1.3:35449 (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:16:06 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 192.168.1.3:35449 in memory (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2905
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2661
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2935
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2761
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2508
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2483
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2701
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2797
18/04/01 20:16:06 INFO SparkContext: Created broadcast 120 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2616
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2497
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2752
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2515
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2790
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2577
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2728
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2732
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2844
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2939
18/04/01 20:16:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 119 (ShuffledRDD[104] at reduceByKey at RefereeStats.scala:43) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:16:06 INFO TaskSchedulerImpl: Adding task set 119.0 with 2 tasks
18/04/01 20:16:06 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 192.168.1.3:35449 in memory (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:16:06 INFO TaskSetManager: Starting task 1.0 in stage 119.0 (TID 388, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:06 INFO TaskSetManager: Starting task 0.0 in stage 119.0 (TID 389, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2720
18/04/01 20:16:06 INFO Executor: Running task 1.0 in stage 119.0 (TID 388)
18/04/01 20:16:06 INFO Executor: Running task 0.0 in stage 119.0 (TID 389)
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2785
18/04/01 20:16:06 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:16:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:16:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:16:06 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:06 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:06 INFO BlockManagerInfo: Removed broadcast_118_piece0 on 192.168.1.3:35449 in memory (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2738
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2814
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2756
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2580
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2775
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2635
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2691
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2693
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2496
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2666
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2795
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2685
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2474
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2520
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2825
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2644
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2561
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2662
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2554
18/04/01 20:16:06 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:06 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2714
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2774
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2852
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2873
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2555
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2711
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2794
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2871
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2595
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2514
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2933
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2826
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2482
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2544
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2704
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2698
18/04/01 20:16:06 INFO KafkaProducer: [Producer clientId=producer-89] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2914
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2608
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2690
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2880
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2488
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2489
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2890
18/04/01 20:16:06 INFO BlockManagerInfo: Removed broadcast_116_piece0 on 192.168.1.3:35449 in memory (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2702
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2484
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2533
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2457
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2861
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2599
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2543
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2863
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2836
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2575
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2895
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2751
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2686
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2559
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2590
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2941
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2684
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2766
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2648
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2753
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2624
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2454
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2807
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2572
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2671
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2892
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2667
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2913
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2918
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2849
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2516
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2603
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2651
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2898
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2729
18/04/01 20:16:06 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:06 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:06 INFO Executor: Finished task 1.0 in stage 119.0 (TID 388). 1138 bytes result sent to driver
18/04/01 20:16:06 INFO ContextCleaner: Cleaned shuffle 36
18/04/01 20:16:06 INFO TaskSetManager: Finished task 1.0 in stage 119.0 (TID 388) in 22 ms on localhost (executor driver) (1/2)
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2612
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2503
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2737
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2453
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2906
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2598
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2881
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2839
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2560
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2638
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2597
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2708
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2707
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2896
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2741
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2778
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2804
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2879
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2627
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2536
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2563
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2570
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2678
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2585
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2713
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2734
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2901
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2462
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2731
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2680
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2553
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2868
18/04/01 20:16:06 INFO ContextCleaner: Cleaned shuffle 38
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2744
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2783
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2513
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2755
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2512
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2696
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2495
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2842
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2860
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2843
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2899
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2917
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2919
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2659
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2883
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2574
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2733
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2834
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2645
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2689
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2579
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2565
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2800
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2887
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2770
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2893
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2706
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2739
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2469
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2459
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2643
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2464
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2945
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2829
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2810
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2894
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2727
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2625
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2948
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2757
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2558
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2614
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2541
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2819
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2835
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2769
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2592
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2669
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2709
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2857
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2682
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2859
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2697
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2654
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2458
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2500
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2930
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2840
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2889
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2754
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2527
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2463
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2502
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2692
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2656
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2907
18/04/01 20:16:06 INFO BlockManagerInfo: Removed broadcast_117_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2677
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2934
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2806
18/04/01 20:16:06 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2851
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2581
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2784
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2567
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2798
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2566
18/04/01 20:16:06 INFO KafkaProducer: [Producer clientId=producer-90] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:06 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2606
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2927
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2472
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2742
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2611
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2897
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2604
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2670
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2477
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2619
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2929
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2571
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2528
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2789
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2940
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2801
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2647
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2856
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2920
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2542
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2908
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2507
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2932
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2551
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2748
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2903
18/04/01 20:16:06 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 192.168.1.3:35449 in memory (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2703
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2468
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2812
18/04/01 20:16:06 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2467
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2485
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2936
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2548
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2573
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2832
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2504
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2902
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2830
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2827
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2673
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2681
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2724
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2877
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2609
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2938
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2745
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2546
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2593
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2712
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2582
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2657
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2815
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2674
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2765
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2841
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2476
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2793
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2509
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2665
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2479
18/04/01 20:16:06 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2676
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2491
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2632
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2628
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2640
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2642
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2630
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2743
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2867
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2788
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2854
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2947
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2874
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2650
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2660
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2556
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2723
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2668
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2726
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2494
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2588
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2912
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2949
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2749
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2589
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2910
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2451
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2786
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2787
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2869
18/04/01 20:16:06 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2557
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2846
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2716
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2615
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2636
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2461
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2722
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2768
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2610
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2545
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2529
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2922
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2943
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2641
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2796
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2820
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2700
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2767
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2639
18/04/01 20:16:06 INFO ContextCleaner: Cleaned shuffle 33
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2522
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2803
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2511
18/04/01 20:16:06 INFO ContextCleaner: Cleaned shuffle 35
18/04/01 20:16:06 INFO ContextCleaner: Cleaned accumulator 2802
18/04/01 20:16:06 INFO Executor: Finished task 0.0 in stage 119.0 (TID 389). 1138 bytes result sent to driver
18/04/01 20:16:06 INFO TaskSetManager: Finished task 0.0 in stage 119.0 (TID 389) in 77 ms on localhost (executor driver) (2/2)
18/04/01 20:16:06 INFO TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool 
18/04/01 20:16:06 INFO DAGScheduler: ResultStage 119 (foreachPartition at RefereeStats.scala:106) finished in 0.092 s
18/04/01 20:16:06 INFO DAGScheduler: Job 74 finished: foreachPartition at RefereeStats.scala:106, took 0.178086 s
18/04/01 20:16:06 INFO JobScheduler: Finished job streaming job 1522602965000 ms.3 from job set of time 1522602965000 ms
18/04/01 20:16:06 INFO JobScheduler: Total delay: 1.369 s for time 1522602965000 ms (execution: 1.337 s)
18/04/01 20:16:06 INFO MapPartitionsRDD: Removing RDD 92 from persistence list
18/04/01 20:16:06 INFO BlockManager: Removing RDD 92
18/04/01 20:16:06 INFO KafkaRDD: Removing RDD 91 from persistence list
18/04/01 20:16:06 INFO ShuffledRDD: Removing RDD 93 from persistence list
18/04/01 20:16:06 INFO BlockManager: Removing RDD 91
18/04/01 20:16:06 INFO ShuffledRDD: Removing RDD 95 from persistence list
18/04/01 20:16:06 INFO BlockManager: Removing RDD 93
18/04/01 20:16:06 INFO BlockManager: Removing RDD 95
18/04/01 20:16:06 INFO MapPartitionsRDD: Removing RDD 94 from persistence list
18/04/01 20:16:06 INFO BlockManager: Removing RDD 94
18/04/01 20:16:06 INFO ShuffledRDD: Removing RDD 97 from persistence list
18/04/01 20:16:06 INFO BlockManager: Removing RDD 97
18/04/01 20:16:06 INFO MapPartitionsRDD: Removing RDD 96 from persistence list
18/04/01 20:16:06 INFO BlockManager: Removing RDD 96
18/04/01 20:16:06 INFO JobGenerator: Checkpointing graph for time 1522602965000 ms
18/04/01 20:16:06 INFO DStreamGraph: Updating checkpoint data for time 1522602965000 ms
18/04/01 20:16:06 INFO DStreamGraph: Updated checkpoint data for time 1522602965000 ms
18/04/01 20:16:06 INFO CheckpointWriter: Saving checkpoint for time 1522602965000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602965000'
18/04/01 20:16:06 INFO CheckpointWriter: Submitted checkpoint of time 1522602965000 ms to writer queue
18/04/01 20:16:06 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602940000
18/04/01 20:16:06 INFO CheckpointWriter: Checkpoint for time 1522602965000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602965000', took 5544 bytes and 36 ms
18/04/01 20:16:06 INFO DStreamGraph: Clearing checkpoint data for time 1522602965000 ms
18/04/01 20:16:06 INFO DStreamGraph: Cleared checkpoint data for time 1522602965000 ms
18/04/01 20:16:06 INFO ReceivedBlockTracker: Deleting batches: 
18/04/01 20:16:06 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 1 old log files in file:/tmp/refs-xyzabb/receivedBlockMetadata older than 1522602960000: file:/tmp/refs-xyzabb/receivedBlockMetadata/log-1522602899636-1522602959636
18/04/01 20:16:06 INFO InputInfoTracker: remove old batch metadata: 1522602955000 ms
18/04/01 20:16:06 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Cleared log files in file:/tmp/refs-xyzabb/receivedBlockMetadata older than 1522602960000
18/04/01 20:16:10 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-0 to offset 728.
18/04/01 20:16:10 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-3 to offset 0.
18/04/01 20:16:10 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-4 to offset 0.
18/04/01 20:16:10 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-1 to offset 0.
18/04/01 20:16:10 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-2 to offset 0.
18/04/01 20:16:10 INFO JobScheduler: Added jobs for time 1522602970000 ms
18/04/01 20:16:10 INFO JobGenerator: Checkpointing graph for time 1522602970000 ms
18/04/01 20:16:10 INFO DStreamGraph: Updating checkpoint data for time 1522602970000 ms
18/04/01 20:16:10 INFO JobScheduler: Starting job streaming job 1522602970000 ms.0 from job set of time 1522602970000 ms
18/04/01 20:16:10 INFO DStreamGraph: Updated checkpoint data for time 1522602970000 ms
18/04/01 20:16:10 INFO CheckpointWriter: Submitted checkpoint of time 1522602970000 ms to writer queue
18/04/01 20:16:10 INFO CheckpointWriter: Saving checkpoint for time 1522602970000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602970000'
18/04/01 20:16:10 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:16:10 INFO DAGScheduler: Got job 75 (print at RefereeStats.scala:67) with 1 output partitions
18/04/01 20:16:10 INFO DAGScheduler: Final stage: ResultStage 120 (print at RefereeStats.scala:67)
18/04/01 20:16:10 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:16:10 INFO DAGScheduler: Missing parents: List()
18/04/01 20:16:10 INFO DAGScheduler: Submitting ResultStage 120 (MapPartitionsRDD[106] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:16:10 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 3.0 KB, free 477.3 MB)
18/04/01 20:16:10 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.3 MB)
18/04/01 20:16:10 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:10 INFO SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 120 (MapPartitionsRDD[106] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0))
18/04/01 20:16:10 INFO TaskSchedulerImpl: Adding task set 120.0 with 1 tasks
18/04/01 20:16:10 INFO TaskSetManager: Starting task 0.0 in stage 120.0 (TID 390, localhost, executor driver, partition 0, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:10 INFO Executor: Running task 0.0 in stage 120.0 (TID 390)
18/04/01 20:16:10 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602945000.bk
18/04/01 20:16:10 INFO CheckpointWriter: Checkpoint for time 1522602970000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602970000', took 5593 bytes and 26 ms
18/04/01 20:16:10 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:10 INFO Executor: Finished task 0.0 in stage 120.0 (TID 390). 704 bytes result sent to driver
18/04/01 20:16:10 INFO TaskSetManager: Finished task 0.0 in stage 120.0 (TID 390) in 6 ms on localhost (executor driver) (1/1)
18/04/01 20:16:10 INFO TaskSchedulerImpl: Removed TaskSet 120.0, whose tasks have all completed, from pool 
18/04/01 20:16:10 INFO DAGScheduler: ResultStage 120 (print at RefereeStats.scala:67) finished in 0.016 s
18/04/01 20:16:10 INFO DAGScheduler: Job 75 finished: print at RefereeStats.scala:67, took 0.019919 s
18/04/01 20:16:10 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:16:10 INFO DAGScheduler: Got job 76 (print at RefereeStats.scala:67) with 4 output partitions
18/04/01 20:16:10 INFO DAGScheduler: Final stage: ResultStage 121 (print at RefereeStats.scala:67)
18/04/01 20:16:10 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:16:10 INFO DAGScheduler: Missing parents: List()
18/04/01 20:16:10 INFO DAGScheduler: Submitting ResultStage 121 (MapPartitionsRDD[106] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:16:10 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 3.0 KB, free 477.3 MB)
18/04/01 20:16:10 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.3 MB)
18/04/01 20:16:10 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:10 INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:10 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 121 (MapPartitionsRDD[106] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
18/04/01 20:16:10 INFO TaskSchedulerImpl: Adding task set 121.0 with 4 tasks
18/04/01 20:16:10 INFO TaskSetManager: Starting task 0.0 in stage 121.0 (TID 391, localhost, executor driver, partition 1, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:10 INFO TaskSetManager: Starting task 1.0 in stage 121.0 (TID 392, localhost, executor driver, partition 2, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:10 INFO Executor: Running task 1.0 in stage 121.0 (TID 392)
18/04/01 20:16:10 INFO Executor: Running task 0.0 in stage 121.0 (TID 391)
18/04/01 20:16:10 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:10 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:10 INFO Executor: Finished task 1.0 in stage 121.0 (TID 392). 704 bytes result sent to driver
18/04/01 20:16:10 INFO Executor: Finished task 0.0 in stage 121.0 (TID 391). 704 bytes result sent to driver
18/04/01 20:16:10 INFO TaskSetManager: Starting task 2.0 in stage 121.0 (TID 393, localhost, executor driver, partition 3, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:10 INFO TaskSetManager: Finished task 1.0 in stage 121.0 (TID 392) in 5 ms on localhost (executor driver) (1/4)
18/04/01 20:16:10 INFO Executor: Running task 2.0 in stage 121.0 (TID 393)
18/04/01 20:16:10 INFO TaskSetManager: Starting task 3.0 in stage 121.0 (TID 394, localhost, executor driver, partition 4, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:10 INFO TaskSetManager: Finished task 0.0 in stage 121.0 (TID 391) in 7 ms on localhost (executor driver) (2/4)
18/04/01 20:16:10 INFO Executor: Running task 3.0 in stage 121.0 (TID 394)
18/04/01 20:16:10 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:10 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 726 -> 728
18/04/01 20:16:10 INFO Executor: Finished task 2.0 in stage 121.0 (TID 393). 704 bytes result sent to driver
18/04/01 20:16:10 INFO TaskSetManager: Finished task 2.0 in stage 121.0 (TID 393) in 6 ms on localhost (executor driver) (3/4)
18/04/01 20:16:10 INFO Executor: Finished task 3.0 in stage 121.0 (TID 394). 856 bytes result sent to driver
18/04/01 20:16:10 INFO TaskSetManager: Finished task 3.0 in stage 121.0 (TID 394) in 11 ms on localhost (executor driver) (4/4)
18/04/01 20:16:10 INFO TaskSchedulerImpl: Removed TaskSet 121.0, whose tasks have all completed, from pool 
18/04/01 20:16:10 INFO DAGScheduler: ResultStage 121 (print at RefereeStats.scala:67) finished in 0.030 s
18/04/01 20:16:10 INFO DAGScheduler: Job 76 finished: print at RefereeStats.scala:67, took 0.033977 s
18/04/01 20:16:10 INFO JobScheduler: Finished job streaming job 1522602970000 ms.0 from job set of time 1522602970000 ms
18/04/01 20:16:10 INFO JobScheduler: Starting job streaming job 1522602970000 ms.1 from job set of time 1522602970000 ms
-------------------------------------------
Time: 1522602970000 ms
-------------------------------------------
(twitter.*,0)
(nextanalytics.com,28000)

18/04/01 20:16:10 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:71
18/04/01 20:16:10 INFO DAGScheduler: Registering RDD 106 (map at RefereeStats.scala:53)
18/04/01 20:16:10 INFO DAGScheduler: Got job 77 (foreachPartition at RefereeStats.scala:71) with 2 output partitions
18/04/01 20:16:10 INFO DAGScheduler: Final stage: ResultStage 123 (foreachPartition at RefereeStats.scala:71)
18/04/01 20:16:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 122)
18/04/01 20:16:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 122)
18/04/01 20:16:10 INFO DAGScheduler: Submitting ShuffleMapStage 122 (MapPartitionsRDD[106] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:16:10 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 3.9 KB, free 477.3 MB)
18/04/01 20:16:10 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.3 MB)
18/04/01 20:16:10 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:10 INFO SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:10 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 122 (MapPartitionsRDD[106] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:16:10 INFO TaskSchedulerImpl: Adding task set 122.0 with 5 tasks
18/04/01 20:16:10 INFO TaskSetManager: Starting task 0.0 in stage 122.0 (TID 395, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:10 INFO TaskSetManager: Starting task 1.0 in stage 122.0 (TID 396, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:10 INFO Executor: Running task 0.0 in stage 122.0 (TID 395)
18/04/01 20:16:10 INFO Executor: Running task 1.0 in stage 122.0 (TID 396)
18/04/01 20:16:10 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:10 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:10 INFO Executor: Finished task 1.0 in stage 122.0 (TID 396). 938 bytes result sent to driver
18/04/01 20:16:10 INFO TaskSetManager: Starting task 2.0 in stage 122.0 (TID 397, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:10 INFO TaskSetManager: Finished task 1.0 in stage 122.0 (TID 396) in 7 ms on localhost (executor driver) (1/5)
18/04/01 20:16:10 INFO Executor: Running task 2.0 in stage 122.0 (TID 397)
18/04/01 20:16:10 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:10 INFO Executor: Finished task 0.0 in stage 122.0 (TID 395). 938 bytes result sent to driver
18/04/01 20:16:10 INFO Executor: Finished task 2.0 in stage 122.0 (TID 397). 938 bytes result sent to driver
18/04/01 20:16:10 INFO TaskSetManager: Starting task 3.0 in stage 122.0 (TID 398, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:10 INFO TaskSetManager: Starting task 4.0 in stage 122.0 (TID 399, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:10 INFO TaskSetManager: Finished task 0.0 in stage 122.0 (TID 395) in 17 ms on localhost (executor driver) (2/5)
18/04/01 20:16:10 INFO Executor: Running task 3.0 in stage 122.0 (TID 398)
18/04/01 20:16:10 INFO TaskSetManager: Finished task 2.0 in stage 122.0 (TID 397) in 10 ms on localhost (executor driver) (3/5)
18/04/01 20:16:10 INFO Executor: Running task 4.0 in stage 122.0 (TID 399)
18/04/01 20:16:10 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 726 -> 728
18/04/01 20:16:10 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:10 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 726
18/04/01 20:16:10 INFO Executor: Finished task 3.0 in stage 122.0 (TID 398). 938 bytes result sent to driver
18/04/01 20:16:10 INFO TaskSetManager: Finished task 3.0 in stage 122.0 (TID 398) in 7 ms on localhost (executor driver) (4/5)
18/04/01 20:16:10 INFO Executor: Finished task 4.0 in stage 122.0 (TID 399). 1024 bytes result sent to driver
18/04/01 20:16:10 INFO TaskSetManager: Finished task 4.0 in stage 122.0 (TID 399) in 514 ms on localhost (executor driver) (5/5)
18/04/01 20:16:10 INFO TaskSchedulerImpl: Removed TaskSet 122.0, whose tasks have all completed, from pool 
18/04/01 20:16:10 INFO DAGScheduler: ShuffleMapStage 122 (map at RefereeStats.scala:53) finished in 0.538 s
18/04/01 20:16:10 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:16:10 INFO DAGScheduler: running: Set()
18/04/01 20:16:10 INFO DAGScheduler: waiting: Set(ResultStage 123)
18/04/01 20:16:10 INFO DAGScheduler: failed: Set()
18/04/01 20:16:10 INFO DAGScheduler: Submitting ResultStage 123 (ShuffledRDD[107] at reduceByKey at RefereeStats.scala:60), which has no missing parents
18/04/01 20:16:10 INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:16:10 INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 1706.0 B, free 477.2 MB)
18/04/01 20:16:10 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on 192.168.1.3:35449 (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:16:10 INFO SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 123 (ShuffledRDD[107] at reduceByKey at RefereeStats.scala:60) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:16:10 INFO TaskSchedulerImpl: Adding task set 123.0 with 2 tasks
18/04/01 20:16:10 INFO TaskSetManager: Starting task 0.0 in stage 123.0 (TID 400, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:16:10 INFO TaskSetManager: Starting task 1.0 in stage 123.0 (TID 401, localhost, executor driver, partition 1, ANY, 7649 bytes)
18/04/01 20:16:10 INFO Executor: Running task 1.0 in stage 123.0 (TID 401)
18/04/01 20:16:10 INFO Executor: Running task 0.0 in stage 123.0 (TID 400)
18/04/01 20:16:10 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:16:10 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:16:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:10 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:10 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:10 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:10 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:10 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:10 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:10 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:16:10 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:16:10 INFO KafkaProducer: [Producer clientId=producer-92] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:10 INFO KafkaProducer: [Producer clientId=producer-91] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:10 INFO Executor: Finished task 0.0 in stage 123.0 (TID 400). 1138 bytes result sent to driver
18/04/01 20:16:10 INFO TaskSetManager: Finished task 0.0 in stage 123.0 (TID 400) in 48 ms on localhost (executor driver) (1/2)
18/04/01 20:16:10 INFO Executor: Finished task 1.0 in stage 123.0 (TID 401). 1138 bytes result sent to driver
18/04/01 20:16:10 INFO TaskSetManager: Finished task 1.0 in stage 123.0 (TID 401) in 63 ms on localhost (executor driver) (2/2)
18/04/01 20:16:10 INFO TaskSchedulerImpl: Removed TaskSet 123.0, whose tasks have all completed, from pool 
18/04/01 20:16:10 INFO DAGScheduler: ResultStage 123 (foreachPartition at RefereeStats.scala:71) finished in 0.072 s
18/04/01 20:16:10 INFO DAGScheduler: Job 77 finished: foreachPartition at RefereeStats.scala:71, took 0.617865 s
18/04/01 20:16:10 INFO JobScheduler: Finished job streaming job 1522602970000 ms.1 from job set of time 1522602970000 ms
18/04/01 20:16:10 INFO JobScheduler: Starting job streaming job 1522602970000 ms.2 from job set of time 1522602970000 ms
18/04/01 20:16:10 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:89
18/04/01 20:16:10 INFO DAGScheduler: Registering RDD 108 (map at RefereeStats.scala:46)
18/04/01 20:16:10 INFO DAGScheduler: Got job 78 (foreachPartition at RefereeStats.scala:89) with 2 output partitions
18/04/01 20:16:10 INFO DAGScheduler: Final stage: ResultStage 125 (foreachPartition at RefereeStats.scala:89)
18/04/01 20:16:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 124)
18/04/01 20:16:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 124)
18/04/01 20:16:10 INFO DAGScheduler: Submitting ShuffleMapStage 124 (MapPartitionsRDD[108] at map at RefereeStats.scala:46), which has no missing parents
18/04/01 20:16:10 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:16:10 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:16:10 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:10 INFO SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:10 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 124 (MapPartitionsRDD[108] at map at RefereeStats.scala:46) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:16:10 INFO TaskSchedulerImpl: Adding task set 124.0 with 5 tasks
18/04/01 20:16:10 INFO TaskSetManager: Starting task 0.0 in stage 124.0 (TID 402, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:10 INFO TaskSetManager: Starting task 1.0 in stage 124.0 (TID 403, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:10 INFO Executor: Running task 0.0 in stage 124.0 (TID 402)
18/04/01 20:16:10 INFO Executor: Running task 1.0 in stage 124.0 (TID 403)
18/04/01 20:16:10 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:10 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:10 INFO Executor: Finished task 0.0 in stage 124.0 (TID 402). 938 bytes result sent to driver
18/04/01 20:16:10 INFO Executor: Finished task 1.0 in stage 124.0 (TID 403). 938 bytes result sent to driver
18/04/01 20:16:10 INFO TaskSetManager: Starting task 2.0 in stage 124.0 (TID 404, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:10 INFO Executor: Running task 2.0 in stage 124.0 (TID 404)
18/04/01 20:16:10 INFO TaskSetManager: Finished task 0.0 in stage 124.0 (TID 402) in 8 ms on localhost (executor driver) (1/5)
18/04/01 20:16:10 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:10 INFO Executor: Finished task 2.0 in stage 124.0 (TID 404). 938 bytes result sent to driver
18/04/01 20:16:10 INFO TaskSetManager: Starting task 3.0 in stage 124.0 (TID 405, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:10 INFO Executor: Running task 3.0 in stage 124.0 (TID 405)
18/04/01 20:16:10 INFO TaskSetManager: Starting task 4.0 in stage 124.0 (TID 406, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:10 INFO Executor: Running task 4.0 in stage 124.0 (TID 406)
18/04/01 20:16:10 INFO TaskSetManager: Finished task 2.0 in stage 124.0 (TID 404) in 8 ms on localhost (executor driver) (2/5)
18/04/01 20:16:10 INFO TaskSetManager: Finished task 1.0 in stage 124.0 (TID 403) in 14 ms on localhost (executor driver) (3/5)
18/04/01 20:16:10 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:10 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 726 -> 728
18/04/01 20:16:10 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 726
18/04/01 20:16:10 INFO Executor: Finished task 3.0 in stage 124.0 (TID 405). 938 bytes result sent to driver
18/04/01 20:16:10 INFO TaskSetManager: Finished task 3.0 in stage 124.0 (TID 405) in 9 ms on localhost (executor driver) (4/5)
18/04/01 20:16:11 INFO Executor: Finished task 4.0 in stage 124.0 (TID 406). 1024 bytes result sent to driver
18/04/01 20:16:11 INFO TaskSetManager: Finished task 4.0 in stage 124.0 (TID 406) in 396 ms on localhost (executor driver) (5/5)
18/04/01 20:16:11 INFO TaskSchedulerImpl: Removed TaskSet 124.0, whose tasks have all completed, from pool 
18/04/01 20:16:11 INFO DAGScheduler: ShuffleMapStage 124 (map at RefereeStats.scala:46) finished in 0.419 s
18/04/01 20:16:11 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:16:11 INFO DAGScheduler: running: Set()
18/04/01 20:16:11 INFO DAGScheduler: waiting: Set(ResultStage 125)
18/04/01 20:16:11 INFO DAGScheduler: failed: Set()
18/04/01 20:16:11 INFO DAGScheduler: Submitting ResultStage 125 (ShuffledRDD[109] at reduceByKey at RefereeStats.scala:51), which has no missing parents
18/04/01 20:16:11 INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:16:11 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 1709.0 B, free 477.2 MB)
18/04/01 20:16:11 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 192.168.1.3:35449 (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:16:11 INFO SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:11 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 125 (ShuffledRDD[109] at reduceByKey at RefereeStats.scala:51) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:16:11 INFO TaskSchedulerImpl: Adding task set 125.0 with 2 tasks
18/04/01 20:16:11 INFO TaskSetManager: Starting task 0.0 in stage 125.0 (TID 407, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:16:11 INFO TaskSetManager: Starting task 1.0 in stage 125.0 (TID 408, localhost, executor driver, partition 1, ANY, 7649 bytes)
18/04/01 20:16:11 INFO Executor: Running task 0.0 in stage 125.0 (TID 407)
18/04/01 20:16:11 INFO Executor: Running task 1.0 in stage 125.0 (TID 408)
18/04/01 20:16:11 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:16:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:11 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:11 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:16:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:16:11 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:11 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:11 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:11 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:16:11 INFO KafkaProducer: [Producer clientId=producer-93] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:11 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:11 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:11 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:16:11 INFO KafkaProducer: [Producer clientId=producer-94] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:11 INFO Executor: Finished task 0.0 in stage 125.0 (TID 407). 1138 bytes result sent to driver
18/04/01 20:16:11 INFO TaskSetManager: Finished task 0.0 in stage 125.0 (TID 407) in 28 ms on localhost (executor driver) (1/2)
18/04/01 20:16:11 INFO Executor: Finished task 1.0 in stage 125.0 (TID 408). 1138 bytes result sent to driver
18/04/01 20:16:11 INFO TaskSetManager: Finished task 1.0 in stage 125.0 (TID 408) in 33 ms on localhost (executor driver) (2/2)
18/04/01 20:16:11 INFO TaskSchedulerImpl: Removed TaskSet 125.0, whose tasks have all completed, from pool 
18/04/01 20:16:11 INFO DAGScheduler: ResultStage 125 (foreachPartition at RefereeStats.scala:89) finished in 0.041 s
18/04/01 20:16:11 INFO DAGScheduler: Job 78 finished: foreachPartition at RefereeStats.scala:89, took 0.467816 s
18/04/01 20:16:11 INFO JobScheduler: Finished job streaming job 1522602970000 ms.2 from job set of time 1522602970000 ms
18/04/01 20:16:11 INFO JobScheduler: Starting job streaming job 1522602970000 ms.3 from job set of time 1522602970000 ms
18/04/01 20:16:11 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:106
18/04/01 20:16:11 INFO DAGScheduler: Registering RDD 110 (map at RefereeStats.scala:39)
18/04/01 20:16:11 INFO DAGScheduler: Got job 79 (foreachPartition at RefereeStats.scala:106) with 2 output partitions
18/04/01 20:16:11 INFO DAGScheduler: Final stage: ResultStage 127 (foreachPartition at RefereeStats.scala:106)
18/04/01 20:16:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 126)
18/04/01 20:16:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 126)
18/04/01 20:16:11 INFO DAGScheduler: Submitting ShuffleMapStage 126 (MapPartitionsRDD[110] at map at RefereeStats.scala:39), which has no missing parents
18/04/01 20:16:11 INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:16:11 INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:16:11 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:11 INFO SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:11 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 126 (MapPartitionsRDD[110] at map at RefereeStats.scala:39) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:16:11 INFO TaskSchedulerImpl: Adding task set 126.0 with 5 tasks
18/04/01 20:16:11 INFO TaskSetManager: Starting task 0.0 in stage 126.0 (TID 409, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:11 INFO TaskSetManager: Starting task 1.0 in stage 126.0 (TID 410, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:11 INFO Executor: Running task 0.0 in stage 126.0 (TID 409)
18/04/01 20:16:11 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:11 INFO Executor: Running task 1.0 in stage 126.0 (TID 410)
18/04/01 20:16:11 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:11 INFO Executor: Finished task 0.0 in stage 126.0 (TID 409). 938 bytes result sent to driver
18/04/01 20:16:11 INFO Executor: Finished task 1.0 in stage 126.0 (TID 410). 938 bytes result sent to driver
18/04/01 20:16:11 INFO TaskSetManager: Starting task 2.0 in stage 126.0 (TID 411, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:11 INFO TaskSetManager: Finished task 0.0 in stage 126.0 (TID 409) in 16 ms on localhost (executor driver) (1/5)
18/04/01 20:16:11 INFO Executor: Running task 2.0 in stage 126.0 (TID 411)
18/04/01 20:16:11 INFO TaskSetManager: Starting task 3.0 in stage 126.0 (TID 412, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:11 INFO Executor: Running task 3.0 in stage 126.0 (TID 412)
18/04/01 20:16:11 INFO TaskSetManager: Finished task 1.0 in stage 126.0 (TID 410) in 16 ms on localhost (executor driver) (2/5)
18/04/01 20:16:11 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:11 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:11 INFO Executor: Finished task 3.0 in stage 126.0 (TID 412). 938 bytes result sent to driver
18/04/01 20:16:11 INFO Executor: Finished task 2.0 in stage 126.0 (TID 411). 938 bytes result sent to driver
18/04/01 20:16:11 INFO TaskSetManager: Starting task 4.0 in stage 126.0 (TID 413, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:11 INFO Executor: Running task 4.0 in stage 126.0 (TID 413)
18/04/01 20:16:11 INFO TaskSetManager: Finished task 3.0 in stage 126.0 (TID 412) in 10 ms on localhost (executor driver) (3/5)
18/04/01 20:16:11 INFO TaskSetManager: Finished task 2.0 in stage 126.0 (TID 411) in 13 ms on localhost (executor driver) (4/5)
18/04/01 20:16:11 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 726 -> 728
18/04/01 20:16:11 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 726
18/04/01 20:16:11 INFO Executor: Finished task 4.0 in stage 126.0 (TID 413). 1024 bytes result sent to driver
18/04/01 20:16:11 INFO TaskSetManager: Finished task 4.0 in stage 126.0 (TID 413) in 410 ms on localhost (executor driver) (5/5)
18/04/01 20:16:11 INFO TaskSchedulerImpl: Removed TaskSet 126.0, whose tasks have all completed, from pool 
18/04/01 20:16:11 INFO DAGScheduler: ShuffleMapStage 126 (map at RefereeStats.scala:39) finished in 0.447 s
18/04/01 20:16:11 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:16:11 INFO DAGScheduler: running: Set()
18/04/01 20:16:11 INFO DAGScheduler: waiting: Set(ResultStage 127)
18/04/01 20:16:11 INFO DAGScheduler: failed: Set()
18/04/01 20:16:11 INFO DAGScheduler: Submitting ResultStage 127 (ShuffledRDD[111] at reduceByKey at RefereeStats.scala:43), which has no missing parents
18/04/01 20:16:11 INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:16:11 INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 1704.0 B, free 477.2 MB)
18/04/01 20:16:11 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 192.168.1.3:35449 (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:16:11 INFO SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:11 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 127 (ShuffledRDD[111] at reduceByKey at RefereeStats.scala:43) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:16:11 INFO TaskSchedulerImpl: Adding task set 127.0 with 2 tasks
18/04/01 20:16:11 INFO TaskSetManager: Starting task 0.0 in stage 127.0 (TID 414, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:16:11 INFO TaskSetManager: Starting task 1.0 in stage 127.0 (TID 415, localhost, executor driver, partition 1, ANY, 7649 bytes)
18/04/01 20:16:11 INFO Executor: Running task 0.0 in stage 127.0 (TID 414)
18/04/01 20:16:11 INFO Executor: Running task 1.0 in stage 127.0 (TID 415)
18/04/01 20:16:11 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:16:11 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:16:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:16:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:16:11 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:11 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:11 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:11 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:11 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:16:11 INFO KafkaProducer: [Producer clientId=producer-95] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:11 INFO Executor: Finished task 1.0 in stage 127.0 (TID 415). 1138 bytes result sent to driver
18/04/01 20:16:11 INFO TaskSetManager: Finished task 1.0 in stage 127.0 (TID 415) in 29 ms on localhost (executor driver) (1/2)
18/04/01 20:16:11 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:11 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:11 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:16:11 INFO KafkaProducer: [Producer clientId=producer-96] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:11 INFO Executor: Finished task 0.0 in stage 127.0 (TID 414). 1138 bytes result sent to driver
18/04/01 20:16:11 INFO TaskSetManager: Finished task 0.0 in stage 127.0 (TID 414) in 52 ms on localhost (executor driver) (2/2)
18/04/01 20:16:11 INFO TaskSchedulerImpl: Removed TaskSet 127.0, whose tasks have all completed, from pool 
18/04/01 20:16:11 INFO DAGScheduler: ResultStage 127 (foreachPartition at RefereeStats.scala:106) finished in 0.060 s
18/04/01 20:16:11 INFO DAGScheduler: Job 79 finished: foreachPartition at RefereeStats.scala:106, took 0.516198 s
18/04/01 20:16:11 INFO JobScheduler: Finished job streaming job 1522602970000 ms.3 from job set of time 1522602970000 ms
18/04/01 20:16:11 INFO JobScheduler: Total delay: 1.746 s for time 1522602970000 ms (execution: 1.714 s)
18/04/01 20:16:11 INFO MapPartitionsRDD: Removing RDD 99 from persistence list
18/04/01 20:16:11 INFO BlockManager: Removing RDD 99
18/04/01 20:16:11 INFO KafkaRDD: Removing RDD 98 from persistence list
18/04/01 20:16:11 INFO BlockManager: Removing RDD 98
18/04/01 20:16:11 INFO ShuffledRDD: Removing RDD 100 from persistence list
18/04/01 20:16:11 INFO BlockManager: Removing RDD 100
18/04/01 20:16:11 INFO ShuffledRDD: Removing RDD 102 from persistence list
18/04/01 20:16:11 INFO BlockManager: Removing RDD 102
18/04/01 20:16:11 INFO MapPartitionsRDD: Removing RDD 101 from persistence list
18/04/01 20:16:11 INFO BlockManager: Removing RDD 101
18/04/01 20:16:11 INFO ShuffledRDD: Removing RDD 104 from persistence list
18/04/01 20:16:11 INFO BlockManager: Removing RDD 104
18/04/01 20:16:11 INFO MapPartitionsRDD: Removing RDD 103 from persistence list
18/04/01 20:16:11 INFO BlockManager: Removing RDD 103
18/04/01 20:16:11 INFO JobGenerator: Checkpointing graph for time 1522602970000 ms
18/04/01 20:16:11 INFO DStreamGraph: Updating checkpoint data for time 1522602970000 ms
18/04/01 20:16:11 INFO DStreamGraph: Updated checkpoint data for time 1522602970000 ms
18/04/01 20:16:11 INFO CheckpointWriter: Submitted checkpoint of time 1522602970000 ms to writer queue
18/04/01 20:16:11 INFO CheckpointWriter: Saving checkpoint for time 1522602970000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602970000'
18/04/01 20:16:11 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602945000
18/04/01 20:16:11 INFO CheckpointWriter: Checkpoint for time 1522602970000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602970000', took 5535 bytes and 20 ms
18/04/01 20:16:11 INFO DStreamGraph: Clearing checkpoint data for time 1522602970000 ms
18/04/01 20:16:11 INFO DStreamGraph: Cleared checkpoint data for time 1522602970000 ms
18/04/01 20:16:11 INFO ReceivedBlockTracker: Deleting batches: 
18/04/01 20:16:11 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/tmp/refs-xyzabb/receivedBlockMetadata older than 1522602965000: 
18/04/01 20:16:11 INFO InputInfoTracker: remove old batch metadata: 1522602960000 ms
18/04/01 20:16:15 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-0 to offset 729.
18/04/01 20:16:15 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-3 to offset 0.
18/04/01 20:16:15 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-4 to offset 0.
18/04/01 20:16:15 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-1 to offset 0.
18/04/01 20:16:15 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-2 to offset 0.
18/04/01 20:16:15 INFO JobScheduler: Added jobs for time 1522602975000 ms
18/04/01 20:16:15 INFO JobGenerator: Checkpointing graph for time 1522602975000 ms
18/04/01 20:16:15 INFO DStreamGraph: Updating checkpoint data for time 1522602975000 ms
18/04/01 20:16:15 INFO JobScheduler: Starting job streaming job 1522602975000 ms.0 from job set of time 1522602975000 ms
18/04/01 20:16:15 INFO DStreamGraph: Updated checkpoint data for time 1522602975000 ms
18/04/01 20:16:15 INFO CheckpointWriter: Submitted checkpoint of time 1522602975000 ms to writer queue
18/04/01 20:16:15 INFO CheckpointWriter: Saving checkpoint for time 1522602975000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602975000'
18/04/01 20:16:15 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:16:15 INFO DAGScheduler: Got job 80 (print at RefereeStats.scala:67) with 1 output partitions
18/04/01 20:16:15 INFO DAGScheduler: Final stage: ResultStage 128 (print at RefereeStats.scala:67)
18/04/01 20:16:15 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:16:15 INFO DAGScheduler: Missing parents: List()
18/04/01 20:16:15 INFO DAGScheduler: Submitting ResultStage 128 (MapPartitionsRDD[113] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:16:15 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602950000.bk
18/04/01 20:16:15 INFO CheckpointWriter: Checkpoint for time 1522602975000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602975000', took 5593 bytes and 16 ms
18/04/01 20:16:15 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 3.0 KB, free 477.2 MB)
18/04/01 20:16:15 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 1988.0 B, free 477.2 MB)
18/04/01 20:16:15 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on 192.168.1.3:35449 (size: 1988.0 B, free: 477.3 MB)
18/04/01 20:16:15 INFO SparkContext: Created broadcast 129 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 128 (MapPartitionsRDD[113] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0))
18/04/01 20:16:15 INFO TaskSchedulerImpl: Adding task set 128.0 with 1 tasks
18/04/01 20:16:15 INFO TaskSetManager: Starting task 0.0 in stage 128.0 (TID 416, localhost, executor driver, partition 0, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:15 INFO Executor: Running task 0.0 in stage 128.0 (TID 416)
18/04/01 20:16:15 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:15 INFO Executor: Finished task 0.0 in stage 128.0 (TID 416). 704 bytes result sent to driver
18/04/01 20:16:15 INFO TaskSetManager: Finished task 0.0 in stage 128.0 (TID 416) in 5 ms on localhost (executor driver) (1/1)
18/04/01 20:16:15 INFO TaskSchedulerImpl: Removed TaskSet 128.0, whose tasks have all completed, from pool 
18/04/01 20:16:15 INFO DAGScheduler: ResultStage 128 (print at RefereeStats.scala:67) finished in 0.015 s
18/04/01 20:16:15 INFO DAGScheduler: Job 80 finished: print at RefereeStats.scala:67, took 0.018057 s
18/04/01 20:16:15 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:16:15 INFO DAGScheduler: Got job 81 (print at RefereeStats.scala:67) with 4 output partitions
18/04/01 20:16:15 INFO DAGScheduler: Final stage: ResultStage 129 (print at RefereeStats.scala:67)
18/04/01 20:16:15 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:16:15 INFO DAGScheduler: Missing parents: List()
18/04/01 20:16:15 INFO DAGScheduler: Submitting ResultStage 129 (MapPartitionsRDD[113] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:16:15 INFO MemoryStore: Block broadcast_130 stored as values in memory (estimated size 3.0 KB, free 477.2 MB)
18/04/01 20:16:15 INFO MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 1988.0 B, free 477.2 MB)
18/04/01 20:16:15 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on 192.168.1.3:35449 (size: 1988.0 B, free: 477.3 MB)
18/04/01 20:16:15 INFO SparkContext: Created broadcast 130 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:15 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 129 (MapPartitionsRDD[113] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
18/04/01 20:16:15 INFO TaskSchedulerImpl: Adding task set 129.0 with 4 tasks
18/04/01 20:16:15 INFO TaskSetManager: Starting task 0.0 in stage 129.0 (TID 417, localhost, executor driver, partition 1, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:15 INFO TaskSetManager: Starting task 1.0 in stage 129.0 (TID 418, localhost, executor driver, partition 2, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:15 INFO Executor: Running task 0.0 in stage 129.0 (TID 417)
18/04/01 20:16:15 INFO Executor: Running task 1.0 in stage 129.0 (TID 418)
18/04/01 20:16:15 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:15 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:15 INFO Executor: Finished task 1.0 in stage 129.0 (TID 418). 704 bytes result sent to driver
18/04/01 20:16:15 INFO Executor: Finished task 0.0 in stage 129.0 (TID 417). 704 bytes result sent to driver
18/04/01 20:16:15 INFO TaskSetManager: Starting task 2.0 in stage 129.0 (TID 419, localhost, executor driver, partition 3, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:15 INFO Executor: Running task 2.0 in stage 129.0 (TID 419)
18/04/01 20:16:15 INFO TaskSetManager: Starting task 3.0 in stage 129.0 (TID 420, localhost, executor driver, partition 4, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:15 INFO TaskSetManager: Finished task 1.0 in stage 129.0 (TID 418) in 8 ms on localhost (executor driver) (1/4)
18/04/01 20:16:15 INFO Executor: Running task 3.0 in stage 129.0 (TID 420)
18/04/01 20:16:15 INFO TaskSetManager: Finished task 0.0 in stage 129.0 (TID 417) in 8 ms on localhost (executor driver) (2/4)
18/04/01 20:16:15 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:15 INFO Executor: Finished task 2.0 in stage 129.0 (TID 419). 704 bytes result sent to driver
18/04/01 20:16:15 INFO TaskSetManager: Finished task 2.0 in stage 129.0 (TID 419) in 6 ms on localhost (executor driver) (3/4)
18/04/01 20:16:15 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 728 -> 729
18/04/01 20:16:15 INFO Executor: Finished task 3.0 in stage 129.0 (TID 420). 867 bytes result sent to driver
18/04/01 20:16:15 INFO TaskSetManager: Finished task 3.0 in stage 129.0 (TID 420) in 12 ms on localhost (executor driver) (4/4)
18/04/01 20:16:15 INFO TaskSchedulerImpl: Removed TaskSet 129.0, whose tasks have all completed, from pool 
18/04/01 20:16:15 INFO DAGScheduler: ResultStage 129 (print at RefereeStats.scala:67) finished in 0.027 s
18/04/01 20:16:15 INFO DAGScheduler: Job 81 finished: print at RefereeStats.scala:67, took 0.030911 s
18/04/01 20:16:15 INFO JobScheduler: Finished job streaming job 1522602975000 ms.0 from job set of time 1522602975000 ms
18/04/01 20:16:15 INFO JobScheduler: Starting job streaming job 1522602975000 ms.1 from job set of time 1522602975000 ms
-------------------------------------------
Time: 1522602975000 ms
-------------------------------------------
(nextanalytics.com,24000)

18/04/01 20:16:15 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:71
18/04/01 20:16:15 INFO DAGScheduler: Registering RDD 113 (map at RefereeStats.scala:53)
18/04/01 20:16:15 INFO DAGScheduler: Got job 82 (foreachPartition at RefereeStats.scala:71) with 2 output partitions
18/04/01 20:16:15 INFO DAGScheduler: Final stage: ResultStage 131 (foreachPartition at RefereeStats.scala:71)
18/04/01 20:16:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 130)
18/04/01 20:16:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 130)
18/04/01 20:16:15 INFO DAGScheduler: Submitting ShuffleMapStage 130 (MapPartitionsRDD[113] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:16:15 INFO MemoryStore: Block broadcast_131 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:16:15 INFO MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:16:15 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:15 INFO SparkContext: Created broadcast 131 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:15 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 130 (MapPartitionsRDD[113] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:16:15 INFO TaskSchedulerImpl: Adding task set 130.0 with 5 tasks
18/04/01 20:16:15 INFO TaskSetManager: Starting task 0.0 in stage 130.0 (TID 421, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:15 INFO TaskSetManager: Starting task 1.0 in stage 130.0 (TID 422, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:15 INFO Executor: Running task 1.0 in stage 130.0 (TID 422)
18/04/01 20:16:15 INFO Executor: Running task 0.0 in stage 130.0 (TID 421)
18/04/01 20:16:15 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:15 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:15 INFO Executor: Finished task 1.0 in stage 130.0 (TID 422). 938 bytes result sent to driver
18/04/01 20:16:15 INFO Executor: Finished task 0.0 in stage 130.0 (TID 421). 938 bytes result sent to driver
18/04/01 20:16:15 INFO TaskSetManager: Starting task 2.0 in stage 130.0 (TID 423, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:15 INFO TaskSetManager: Starting task 3.0 in stage 130.0 (TID 424, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:15 INFO Executor: Running task 2.0 in stage 130.0 (TID 423)
18/04/01 20:16:15 INFO Executor: Running task 3.0 in stage 130.0 (TID 424)
18/04/01 20:16:15 INFO TaskSetManager: Finished task 0.0 in stage 130.0 (TID 421) in 7 ms on localhost (executor driver) (1/5)
18/04/01 20:16:15 INFO TaskSetManager: Finished task 1.0 in stage 130.0 (TID 422) in 7 ms on localhost (executor driver) (2/5)
18/04/01 20:16:15 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:15 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:15 INFO Executor: Finished task 2.0 in stage 130.0 (TID 423). 938 bytes result sent to driver
18/04/01 20:16:15 INFO Executor: Finished task 3.0 in stage 130.0 (TID 424). 938 bytes result sent to driver
18/04/01 20:16:15 INFO TaskSetManager: Starting task 4.0 in stage 130.0 (TID 425, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:15 INFO TaskSetManager: Finished task 3.0 in stage 130.0 (TID 424) in 7 ms on localhost (executor driver) (3/5)
18/04/01 20:16:15 INFO TaskSetManager: Finished task 2.0 in stage 130.0 (TID 423) in 8 ms on localhost (executor driver) (4/5)
18/04/01 20:16:15 INFO Executor: Running task 4.0 in stage 130.0 (TID 425)
18/04/01 20:16:15 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 728 -> 729
18/04/01 20:16:15 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 728
18/04/01 20:16:15 INFO Executor: Finished task 4.0 in stage 130.0 (TID 425). 1024 bytes result sent to driver
18/04/01 20:16:15 INFO TaskSetManager: Finished task 4.0 in stage 130.0 (TID 425) in 474 ms on localhost (executor driver) (5/5)
18/04/01 20:16:15 INFO TaskSchedulerImpl: Removed TaskSet 130.0, whose tasks have all completed, from pool 
18/04/01 20:16:15 INFO DAGScheduler: ShuffleMapStage 130 (map at RefereeStats.scala:53) finished in 0.496 s
18/04/01 20:16:15 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:16:15 INFO DAGScheduler: running: Set()
18/04/01 20:16:15 INFO DAGScheduler: waiting: Set(ResultStage 131)
18/04/01 20:16:15 INFO DAGScheduler: failed: Set()
18/04/01 20:16:15 INFO DAGScheduler: Submitting ResultStage 131 (ShuffledRDD[114] at reduceByKey at RefereeStats.scala:60), which has no missing parents
18/04/01 20:16:15 INFO MemoryStore: Block broadcast_132 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:16:15 INFO MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 1706.0 B, free 477.2 MB)
18/04/01 20:16:15 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on 192.168.1.3:35449 (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:16:15 INFO SparkContext: Created broadcast 132 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 131 (ShuffledRDD[114] at reduceByKey at RefereeStats.scala:60) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:16:15 INFO TaskSchedulerImpl: Adding task set 131.0 with 2 tasks
18/04/01 20:16:15 INFO TaskSetManager: Starting task 1.0 in stage 131.0 (TID 426, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:15 INFO TaskSetManager: Starting task 0.0 in stage 131.0 (TID 427, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:16:15 INFO Executor: Running task 0.0 in stage 131.0 (TID 427)
18/04/01 20:16:15 INFO Executor: Running task 1.0 in stage 131.0 (TID 426)
18/04/01 20:16:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:16:15 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:15 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:15 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:15 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:15 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:15 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:15 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:15 INFO KafkaProducer: [Producer clientId=producer-97] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:15 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:16:15 INFO KafkaProducer: [Producer clientId=producer-98] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:15 INFO Executor: Finished task 1.0 in stage 131.0 (TID 426). 1138 bytes result sent to driver
18/04/01 20:16:15 INFO TaskSetManager: Finished task 1.0 in stage 131.0 (TID 426) in 27 ms on localhost (executor driver) (1/2)
18/04/01 20:16:15 INFO Executor: Finished task 0.0 in stage 131.0 (TID 427). 1138 bytes result sent to driver
18/04/01 20:16:15 INFO TaskSetManager: Finished task 0.0 in stage 131.0 (TID 427) in 35 ms on localhost (executor driver) (2/2)
18/04/01 20:16:15 INFO TaskSchedulerImpl: Removed TaskSet 131.0, whose tasks have all completed, from pool 
18/04/01 20:16:15 INFO DAGScheduler: ResultStage 131 (foreachPartition at RefereeStats.scala:71) finished in 0.044 s
18/04/01 20:16:15 INFO DAGScheduler: Job 82 finished: foreachPartition at RefereeStats.scala:71, took 0.547114 s
18/04/01 20:16:15 INFO JobScheduler: Finished job streaming job 1522602975000 ms.1 from job set of time 1522602975000 ms
18/04/01 20:16:15 INFO JobScheduler: Starting job streaming job 1522602975000 ms.2 from job set of time 1522602975000 ms
18/04/01 20:16:15 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:89
18/04/01 20:16:15 INFO DAGScheduler: Registering RDD 115 (map at RefereeStats.scala:46)
18/04/01 20:16:15 INFO DAGScheduler: Got job 83 (foreachPartition at RefereeStats.scala:89) with 2 output partitions
18/04/01 20:16:15 INFO DAGScheduler: Final stage: ResultStage 133 (foreachPartition at RefereeStats.scala:89)
18/04/01 20:16:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 132)
18/04/01 20:16:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 132)
18/04/01 20:16:15 INFO DAGScheduler: Submitting ShuffleMapStage 132 (MapPartitionsRDD[115] at map at RefereeStats.scala:46), which has no missing parents
18/04/01 20:16:15 INFO MemoryStore: Block broadcast_133 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:16:15 INFO MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:16:15 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:15 INFO SparkContext: Created broadcast 133 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:15 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 132 (MapPartitionsRDD[115] at map at RefereeStats.scala:46) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:16:15 INFO TaskSchedulerImpl: Adding task set 132.0 with 5 tasks
18/04/01 20:16:15 INFO TaskSetManager: Starting task 0.0 in stage 132.0 (TID 428, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:15 INFO TaskSetManager: Starting task 1.0 in stage 132.0 (TID 429, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:15 INFO Executor: Running task 0.0 in stage 132.0 (TID 428)
18/04/01 20:16:15 INFO Executor: Running task 1.0 in stage 132.0 (TID 429)
18/04/01 20:16:15 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:15 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:15 INFO Executor: Finished task 1.0 in stage 132.0 (TID 429). 938 bytes result sent to driver
18/04/01 20:16:15 INFO Executor: Finished task 0.0 in stage 132.0 (TID 428). 938 bytes result sent to driver
18/04/01 20:16:15 INFO TaskSetManager: Starting task 2.0 in stage 132.0 (TID 430, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:15 INFO Executor: Running task 2.0 in stage 132.0 (TID 430)
18/04/01 20:16:15 INFO TaskSetManager: Starting task 3.0 in stage 132.0 (TID 431, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:15 INFO TaskSetManager: Finished task 0.0 in stage 132.0 (TID 428) in 7 ms on localhost (executor driver) (1/5)
18/04/01 20:16:15 INFO TaskSetManager: Finished task 1.0 in stage 132.0 (TID 429) in 8 ms on localhost (executor driver) (2/5)
18/04/01 20:16:15 INFO Executor: Running task 3.0 in stage 132.0 (TID 431)
18/04/01 20:16:15 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:15 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:15 INFO Executor: Finished task 3.0 in stage 132.0 (TID 431). 938 bytes result sent to driver
18/04/01 20:16:15 INFO Executor: Finished task 2.0 in stage 132.0 (TID 430). 938 bytes result sent to driver
18/04/01 20:16:15 INFO TaskSetManager: Starting task 4.0 in stage 132.0 (TID 432, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:15 INFO Executor: Running task 4.0 in stage 132.0 (TID 432)
18/04/01 20:16:15 INFO TaskSetManager: Finished task 3.0 in stage 132.0 (TID 431) in 7 ms on localhost (executor driver) (3/5)
18/04/01 20:16:15 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 728 -> 729
18/04/01 20:16:15 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 728
18/04/01 20:16:15 INFO TaskSetManager: Finished task 2.0 in stage 132.0 (TID 430) in 13 ms on localhost (executor driver) (4/5)
18/04/01 20:16:16 INFO Executor: Finished task 4.0 in stage 132.0 (TID 432). 1024 bytes result sent to driver
18/04/01 20:16:16 INFO TaskSetManager: Finished task 4.0 in stage 132.0 (TID 432) in 418 ms on localhost (executor driver) (5/5)
18/04/01 20:16:16 INFO TaskSchedulerImpl: Removed TaskSet 132.0, whose tasks have all completed, from pool 
18/04/01 20:16:16 INFO DAGScheduler: ShuffleMapStage 132 (map at RefereeStats.scala:46) finished in 0.444 s
18/04/01 20:16:16 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:16:16 INFO DAGScheduler: running: Set()
18/04/01 20:16:16 INFO DAGScheduler: waiting: Set(ResultStage 133)
18/04/01 20:16:16 INFO DAGScheduler: failed: Set()
18/04/01 20:16:16 INFO DAGScheduler: Submitting ResultStage 133 (ShuffledRDD[116] at reduceByKey at RefereeStats.scala:51), which has no missing parents
18/04/01 20:16:16 INFO MemoryStore: Block broadcast_134 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:16:16 INFO MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 1708.0 B, free 477.2 MB)
18/04/01 20:16:16 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on 192.168.1.3:35449 (size: 1708.0 B, free: 477.3 MB)
18/04/01 20:16:16 INFO SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 133 (ShuffledRDD[116] at reduceByKey at RefereeStats.scala:51) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:16:16 INFO TaskSchedulerImpl: Adding task set 133.0 with 2 tasks
18/04/01 20:16:16 INFO TaskSetManager: Starting task 1.0 in stage 133.0 (TID 433, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:16 INFO TaskSetManager: Starting task 0.0 in stage 133.0 (TID 434, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:16:16 INFO Executor: Running task 0.0 in stage 133.0 (TID 434)
18/04/01 20:16:16 INFO Executor: Running task 1.0 in stage 133.0 (TID 433)
18/04/01 20:16:16 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:16 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:16:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:16 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:16 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:16 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:16 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:16 INFO KafkaProducer: [Producer clientId=producer-99] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:16 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:16 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:16 INFO Executor: Finished task 1.0 in stage 133.0 (TID 433). 1138 bytes result sent to driver
18/04/01 20:16:16 INFO TaskSetManager: Finished task 1.0 in stage 133.0 (TID 433) in 13 ms on localhost (executor driver) (1/2)
18/04/01 20:16:16 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:16:16 INFO KafkaProducer: [Producer clientId=producer-100] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:16 INFO Executor: Finished task 0.0 in stage 133.0 (TID 434). 1138 bytes result sent to driver
18/04/01 20:16:16 INFO TaskSetManager: Finished task 0.0 in stage 133.0 (TID 434) in 22 ms on localhost (executor driver) (2/2)
18/04/01 20:16:16 INFO TaskSchedulerImpl: Removed TaskSet 133.0, whose tasks have all completed, from pool 
18/04/01 20:16:16 INFO DAGScheduler: ResultStage 133 (foreachPartition at RefereeStats.scala:89) finished in 0.040 s
18/04/01 20:16:16 INFO DAGScheduler: Job 83 finished: foreachPartition at RefereeStats.scala:89, took 0.490809 s
18/04/01 20:16:16 INFO JobScheduler: Finished job streaming job 1522602975000 ms.2 from job set of time 1522602975000 ms
18/04/01 20:16:16 INFO JobScheduler: Starting job streaming job 1522602975000 ms.3 from job set of time 1522602975000 ms
18/04/01 20:16:16 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:106
18/04/01 20:16:16 INFO DAGScheduler: Registering RDD 117 (map at RefereeStats.scala:39)
18/04/01 20:16:16 INFO DAGScheduler: Got job 84 (foreachPartition at RefereeStats.scala:106) with 2 output partitions
18/04/01 20:16:16 INFO DAGScheduler: Final stage: ResultStage 135 (foreachPartition at RefereeStats.scala:106)
18/04/01 20:16:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 134)
18/04/01 20:16:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 134)
18/04/01 20:16:16 INFO DAGScheduler: Submitting ShuffleMapStage 134 (MapPartitionsRDD[117] at map at RefereeStats.scala:39), which has no missing parents
18/04/01 20:16:16 INFO MemoryStore: Block broadcast_135 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:16:16 INFO MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:16:16 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:16 INFO SparkContext: Created broadcast 135 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:16 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 134 (MapPartitionsRDD[117] at map at RefereeStats.scala:39) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:16:16 INFO TaskSchedulerImpl: Adding task set 134.0 with 5 tasks
18/04/01 20:16:16 INFO TaskSetManager: Starting task 0.0 in stage 134.0 (TID 435, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:16 INFO TaskSetManager: Starting task 1.0 in stage 134.0 (TID 436, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:16 INFO Executor: Running task 0.0 in stage 134.0 (TID 435)
18/04/01 20:16:16 INFO Executor: Running task 1.0 in stage 134.0 (TID 436)
18/04/01 20:16:16 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:16 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:16 INFO Executor: Finished task 0.0 in stage 134.0 (TID 435). 938 bytes result sent to driver
18/04/01 20:16:16 INFO Executor: Finished task 1.0 in stage 134.0 (TID 436). 938 bytes result sent to driver
18/04/01 20:16:16 INFO TaskSetManager: Starting task 2.0 in stage 134.0 (TID 437, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:16 INFO Executor: Running task 2.0 in stage 134.0 (TID 437)
18/04/01 20:16:16 INFO TaskSetManager: Starting task 3.0 in stage 134.0 (TID 438, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:16 INFO TaskSetManager: Finished task 0.0 in stage 134.0 (TID 435) in 8 ms on localhost (executor driver) (1/5)
18/04/01 20:16:16 INFO Executor: Running task 3.0 in stage 134.0 (TID 438)
18/04/01 20:16:16 INFO TaskSetManager: Finished task 1.0 in stage 134.0 (TID 436) in 8 ms on localhost (executor driver) (2/5)
18/04/01 20:16:16 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:16 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:16 INFO Executor: Finished task 2.0 in stage 134.0 (TID 437). 938 bytes result sent to driver
18/04/01 20:16:16 INFO TaskSetManager: Starting task 4.0 in stage 134.0 (TID 439, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:16 INFO Executor: Running task 4.0 in stage 134.0 (TID 439)
18/04/01 20:16:16 INFO TaskSetManager: Finished task 2.0 in stage 134.0 (TID 437) in 6 ms on localhost (executor driver) (3/5)
18/04/01 20:16:16 INFO Executor: Finished task 3.0 in stage 134.0 (TID 438). 938 bytes result sent to driver
18/04/01 20:16:16 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 728 -> 729
18/04/01 20:16:16 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 728
18/04/01 20:16:16 INFO TaskSetManager: Finished task 3.0 in stage 134.0 (TID 438) in 10 ms on localhost (executor driver) (4/5)
18/04/01 20:16:16 INFO Executor: Finished task 4.0 in stage 134.0 (TID 439). 1024 bytes result sent to driver
18/04/01 20:16:16 INFO TaskSetManager: Finished task 4.0 in stage 134.0 (TID 439) in 13 ms on localhost (executor driver) (5/5)
18/04/01 20:16:16 INFO TaskSchedulerImpl: Removed TaskSet 134.0, whose tasks have all completed, from pool 
18/04/01 20:16:16 INFO DAGScheduler: ShuffleMapStage 134 (map at RefereeStats.scala:39) finished in 0.036 s
18/04/01 20:16:16 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:16:16 INFO DAGScheduler: running: Set()
18/04/01 20:16:16 INFO DAGScheduler: waiting: Set(ResultStage 135)
18/04/01 20:16:16 INFO DAGScheduler: failed: Set()
18/04/01 20:16:16 INFO DAGScheduler: Submitting ResultStage 135 (ShuffledRDD[118] at reduceByKey at RefereeStats.scala:43), which has no missing parents
18/04/01 20:16:16 INFO MemoryStore: Block broadcast_136 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:16:16 INFO MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 1704.0 B, free 477.2 MB)
18/04/01 20:16:16 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on 192.168.1.3:35449 (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:16:16 INFO SparkContext: Created broadcast 136 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 135 (ShuffledRDD[118] at reduceByKey at RefereeStats.scala:43) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:16:16 INFO TaskSchedulerImpl: Adding task set 135.0 with 2 tasks
18/04/01 20:16:16 INFO TaskSetManager: Starting task 1.0 in stage 135.0 (TID 440, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:16 INFO TaskSetManager: Starting task 0.0 in stage 135.0 (TID 441, localhost, executor driver, partition 0, ANY, 7649 bytes)
18/04/01 20:16:16 INFO Executor: Running task 1.0 in stage 135.0 (TID 440)
18/04/01 20:16:16 INFO Executor: Running task 0.0 in stage 135.0 (TID 441)
18/04/01 20:16:16 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:16 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:16 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:16:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
18/04/01 20:16:16 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:16 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:16 INFO KafkaProducer: [Producer clientId=producer-101] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:16 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:16 INFO Executor: Finished task 1.0 in stage 135.0 (TID 440). 1138 bytes result sent to driver
18/04/01 20:16:16 INFO TaskSetManager: Finished task 1.0 in stage 135.0 (TID 440) in 15 ms on localhost (executor driver) (1/2)
18/04/01 20:16:16 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:16 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:16 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:16:16 INFO KafkaProducer: [Producer clientId=producer-102] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:16 INFO Executor: Finished task 0.0 in stage 135.0 (TID 441). 1181 bytes result sent to driver
18/04/01 20:16:16 INFO TaskSetManager: Finished task 0.0 in stage 135.0 (TID 441) in 33 ms on localhost (executor driver) (2/2)
18/04/01 20:16:16 INFO TaskSchedulerImpl: Removed TaskSet 135.0, whose tasks have all completed, from pool 
18/04/01 20:16:16 INFO DAGScheduler: ResultStage 135 (foreachPartition at RefereeStats.scala:106) finished in 0.041 s
18/04/01 20:16:16 INFO DAGScheduler: Job 84 finished: foreachPartition at RefereeStats.scala:106, took 0.083872 s
18/04/01 20:16:16 INFO JobScheduler: Finished job streaming job 1522602975000 ms.3 from job set of time 1522602975000 ms
18/04/01 20:16:16 INFO JobScheduler: Total delay: 1.246 s for time 1522602975000 ms (execution: 1.221 s)
18/04/01 20:16:16 INFO MapPartitionsRDD: Removing RDD 106 from persistence list
18/04/01 20:16:16 INFO BlockManager: Removing RDD 106
18/04/01 20:16:16 INFO KafkaRDD: Removing RDD 105 from persistence list
18/04/01 20:16:16 INFO BlockManager: Removing RDD 105
18/04/01 20:16:16 INFO ShuffledRDD: Removing RDD 107 from persistence list
18/04/01 20:16:16 INFO BlockManager: Removing RDD 107
18/04/01 20:16:16 INFO ShuffledRDD: Removing RDD 109 from persistence list
18/04/01 20:16:16 INFO BlockManager: Removing RDD 109
18/04/01 20:16:16 INFO MapPartitionsRDD: Removing RDD 108 from persistence list
18/04/01 20:16:16 INFO BlockManager: Removing RDD 108
18/04/01 20:16:16 INFO ShuffledRDD: Removing RDD 111 from persistence list
18/04/01 20:16:16 INFO BlockManager: Removing RDD 111
18/04/01 20:16:16 INFO MapPartitionsRDD: Removing RDD 110 from persistence list
18/04/01 20:16:16 INFO BlockManager: Removing RDD 110
18/04/01 20:16:16 INFO JobGenerator: Checkpointing graph for time 1522602975000 ms
18/04/01 20:16:16 INFO DStreamGraph: Updating checkpoint data for time 1522602975000 ms
18/04/01 20:16:16 INFO DStreamGraph: Updated checkpoint data for time 1522602975000 ms
18/04/01 20:16:16 INFO CheckpointWriter: Submitted checkpoint of time 1522602975000 ms to writer queue
18/04/01 20:16:16 INFO CheckpointWriter: Saving checkpoint for time 1522602975000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602975000'
18/04/01 20:16:16 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602950000
18/04/01 20:16:16 INFO CheckpointWriter: Checkpoint for time 1522602975000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602975000', took 5537 bytes and 17 ms
18/04/01 20:16:16 INFO DStreamGraph: Clearing checkpoint data for time 1522602975000 ms
18/04/01 20:16:16 INFO DStreamGraph: Cleared checkpoint data for time 1522602975000 ms
18/04/01 20:16:16 INFO ReceivedBlockTracker: Deleting batches: 
18/04/01 20:16:16 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/tmp/refs-xyzabb/receivedBlockMetadata older than 1522602970000: 
18/04/01 20:16:16 INFO InputInfoTracker: remove old batch metadata: 1522602965000 ms
18/04/01 20:16:20 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-0 to offset 731.
18/04/01 20:16:20 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-3 to offset 0.
18/04/01 20:16:20 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-4 to offset 0.
18/04/01 20:16:20 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-1 to offset 0.
18/04/01 20:16:20 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-2 to offset 0.
18/04/01 20:16:20 INFO JobScheduler: Starting job streaming job 1522602980000 ms.0 from job set of time 1522602980000 ms
18/04/01 20:16:20 INFO JobScheduler: Added jobs for time 1522602980000 ms
18/04/01 20:16:20 INFO JobGenerator: Checkpointing graph for time 1522602980000 ms
18/04/01 20:16:20 INFO DStreamGraph: Updating checkpoint data for time 1522602980000 ms
18/04/01 20:16:20 INFO DStreamGraph: Updated checkpoint data for time 1522602980000 ms
18/04/01 20:16:20 INFO CheckpointWriter: Submitted checkpoint of time 1522602980000 ms to writer queue
18/04/01 20:16:20 INFO CheckpointWriter: Saving checkpoint for time 1522602980000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602980000'
18/04/01 20:16:20 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:16:20 INFO DAGScheduler: Got job 85 (print at RefereeStats.scala:67) with 1 output partitions
18/04/01 20:16:20 INFO DAGScheduler: Final stage: ResultStage 136 (print at RefereeStats.scala:67)
18/04/01 20:16:20 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:16:20 INFO DAGScheduler: Missing parents: List()
18/04/01 20:16:20 INFO DAGScheduler: Submitting ResultStage 136 (MapPartitionsRDD[120] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:16:20 INFO MemoryStore: Block broadcast_137 stored as values in memory (estimated size 3.0 KB, free 477.2 MB)
18/04/01 20:16:20 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602955000.bk
18/04/01 20:16:20 INFO CheckpointWriter: Checkpoint for time 1522602980000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602980000', took 5595 bytes and 15 ms
18/04/01 20:16:20 INFO MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.2 MB)
18/04/01 20:16:20 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:20 INFO SparkContext: Created broadcast 137 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 136 (MapPartitionsRDD[120] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0))
18/04/01 20:16:20 INFO TaskSchedulerImpl: Adding task set 136.0 with 1 tasks
18/04/01 20:16:20 INFO TaskSetManager: Starting task 0.0 in stage 136.0 (TID 442, localhost, executor driver, partition 0, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:20 INFO Executor: Running task 0.0 in stage 136.0 (TID 442)
18/04/01 20:16:20 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:20 INFO Executor: Finished task 0.0 in stage 136.0 (TID 442). 661 bytes result sent to driver
18/04/01 20:16:20 INFO TaskSetManager: Finished task 0.0 in stage 136.0 (TID 442) in 6 ms on localhost (executor driver) (1/1)
18/04/01 20:16:20 INFO TaskSchedulerImpl: Removed TaskSet 136.0, whose tasks have all completed, from pool 
18/04/01 20:16:20 INFO DAGScheduler: ResultStage 136 (print at RefereeStats.scala:67) finished in 0.017 s
18/04/01 20:16:20 INFO DAGScheduler: Job 85 finished: print at RefereeStats.scala:67, took 0.020752 s
18/04/01 20:16:20 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:16:20 INFO DAGScheduler: Got job 86 (print at RefereeStats.scala:67) with 4 output partitions
18/04/01 20:16:20 INFO DAGScheduler: Final stage: ResultStage 137 (print at RefereeStats.scala:67)
18/04/01 20:16:20 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:16:20 INFO DAGScheduler: Missing parents: List()
18/04/01 20:16:20 INFO DAGScheduler: Submitting ResultStage 137 (MapPartitionsRDD[120] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:16:20 INFO MemoryStore: Block broadcast_138 stored as values in memory (estimated size 3.0 KB, free 477.2 MB)
18/04/01 20:16:20 INFO MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.2 MB)
18/04/01 20:16:20 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:20 INFO SparkContext: Created broadcast 138 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 137 (MapPartitionsRDD[120] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
18/04/01 20:16:20 INFO TaskSchedulerImpl: Adding task set 137.0 with 4 tasks
18/04/01 20:16:20 INFO TaskSetManager: Starting task 0.0 in stage 137.0 (TID 443, localhost, executor driver, partition 1, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:20 INFO TaskSetManager: Starting task 1.0 in stage 137.0 (TID 444, localhost, executor driver, partition 2, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:20 INFO Executor: Running task 0.0 in stage 137.0 (TID 443)
18/04/01 20:16:20 INFO Executor: Running task 1.0 in stage 137.0 (TID 444)
18/04/01 20:16:20 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:20 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:20 INFO Executor: Finished task 1.0 in stage 137.0 (TID 444). 661 bytes result sent to driver
18/04/01 20:16:20 INFO TaskSetManager: Starting task 2.0 in stage 137.0 (TID 445, localhost, executor driver, partition 3, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:20 INFO Executor: Finished task 0.0 in stage 137.0 (TID 443). 661 bytes result sent to driver
18/04/01 20:16:20 INFO TaskSetManager: Finished task 1.0 in stage 137.0 (TID 444) in 5 ms on localhost (executor driver) (1/4)
18/04/01 20:16:20 INFO TaskSetManager: Starting task 3.0 in stage 137.0 (TID 446, localhost, executor driver, partition 4, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:20 INFO TaskSetManager: Finished task 0.0 in stage 137.0 (TID 443) in 7 ms on localhost (executor driver) (2/4)
18/04/01 20:16:20 INFO Executor: Running task 3.0 in stage 137.0 (TID 446)
18/04/01 20:16:20 INFO Executor: Running task 2.0 in stage 137.0 (TID 445)
18/04/01 20:16:20 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 729 -> 731
18/04/01 20:16:20 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:20 INFO Executor: Finished task 2.0 in stage 137.0 (TID 445). 704 bytes result sent to driver
18/04/01 20:16:20 INFO TaskSetManager: Finished task 2.0 in stage 137.0 (TID 445) in 9 ms on localhost (executor driver) (3/4)
18/04/01 20:16:20 INFO Executor: Finished task 3.0 in stage 137.0 (TID 446). 890 bytes result sent to driver
18/04/01 20:16:20 INFO TaskSetManager: Finished task 3.0 in stage 137.0 (TID 446) in 11 ms on localhost (executor driver) (4/4)
18/04/01 20:16:20 INFO TaskSchedulerImpl: Removed TaskSet 137.0, whose tasks have all completed, from pool 
18/04/01 20:16:20 INFO DAGScheduler: ResultStage 137 (print at RefereeStats.scala:67) finished in 0.028 s
18/04/01 20:16:20 INFO DAGScheduler: Job 86 finished: print at RefereeStats.scala:67, took 0.031441 s
18/04/01 20:16:20 INFO JobScheduler: Finished job streaming job 1522602980000 ms.0 from job set of time 1522602980000 ms
18/04/01 20:16:20 INFO JobScheduler: Starting job streaming job 1522602980000 ms.1 from job set of time 1522602980000 ms
-------------------------------------------
Time: 1522602980000 ms
-------------------------------------------
(twitter.*,0)
(google.*,12000)

18/04/01 20:16:20 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:71
18/04/01 20:16:20 INFO DAGScheduler: Registering RDD 120 (map at RefereeStats.scala:53)
18/04/01 20:16:20 INFO DAGScheduler: Got job 87 (foreachPartition at RefereeStats.scala:71) with 2 output partitions
18/04/01 20:16:20 INFO DAGScheduler: Final stage: ResultStage 139 (foreachPartition at RefereeStats.scala:71)
18/04/01 20:16:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 138)
18/04/01 20:16:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 138)
18/04/01 20:16:20 INFO DAGScheduler: Submitting ShuffleMapStage 138 (MapPartitionsRDD[120] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:16:20 INFO MemoryStore: Block broadcast_139 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3015
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3326
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3105
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3440
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3102
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3106
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2954
18/04/01 20:16:20 INFO MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:16:20 INFO BlockManagerInfo: Removed broadcast_133_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3082
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3151
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3049
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3154
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3328
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3143
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3319
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3425
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3300
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3066
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3206
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3312
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3037
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3249
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3029
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3335
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3033
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3361
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3197
18/04/01 20:16:20 INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:20 INFO ContextCleaner: Cleaned shuffle 46
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3279
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3404
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3086
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3329
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3383
18/04/01 20:16:20 INFO ContextCleaner: Cleaned shuffle 40
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3183
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3039
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3182
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3422
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3434
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3157
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3297
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3044
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3139
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3438
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3442
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3311
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3187
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3426
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3042
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2960
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2989
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3446
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3307
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3017
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3094
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2972
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3355
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3021
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2957
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3306
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2993
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3115
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3223
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3009
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3412
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3244
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3432
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3275
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3200
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3213
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3233
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3372
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3123
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3399
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2958
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2981
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3064
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3055
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3347
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3315
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3305
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3186
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3350
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3414
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3056
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3027
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3271
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3318
18/04/01 20:16:20 INFO SparkContext: Created broadcast 139 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:20 INFO BlockManagerInfo: Removed broadcast_122_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3040
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3046
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2986
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3240
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3209
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3096
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3236
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3247
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3195
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3241
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3028
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3320
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3354
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3371
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3075
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3222
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3301
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3230
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3058
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2983
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3313
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3104
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3136
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3246
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2961
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2992
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3291
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3242
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3324
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2965
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3352
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3382
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2979
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3423
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3392
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3216
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3137
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3284
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3030
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3003
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3083
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3217
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3054
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3400
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3272
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3290
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3014
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3089
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3224
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2971
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3267
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3220
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3283
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3417
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3449
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3112
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3025
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3293
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3059
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2975
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3444
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3036
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3114
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3188
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3038
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3008
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3251
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3032
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3447
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3181
18/04/01 20:16:20 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 138 (MapPartitionsRDD[120] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:16:20 INFO TaskSchedulerImpl: Adding task set 138.0 with 5 tasks
18/04/01 20:16:20 INFO BlockManagerInfo: Removed broadcast_120_piece0 on 192.168.1.3:35449 in memory (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:16:20 INFO TaskSetManager: Starting task 0.0 in stage 138.0 (TID 447, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:20 INFO TaskSetManager: Starting task 1.0 in stage 138.0 (TID 448, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:20 INFO Executor: Running task 1.0 in stage 138.0 (TID 448)
18/04/01 20:16:20 INFO Executor: Running task 0.0 in stage 138.0 (TID 447)
18/04/01 20:16:20 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:20 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3065
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3140
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3330
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3416
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3303
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3342
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3385
18/04/01 20:16:20 INFO ContextCleaner: Cleaned shuffle 42
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3424
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3281
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3090
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3062
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3047
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3411
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3050
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3207
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3011
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3043
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3161
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3097
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3166
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3421
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3100
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3257
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3407
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3150
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3333
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2990
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3191
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3341
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3160
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3093
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2968
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3117
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3189
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3373
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3034
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3192
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3278
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3147
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3294
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3155
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3041
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3427
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3377
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3394
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3172
18/04/01 20:16:20 INFO BlockManagerInfo: Removed broadcast_134_piece0 on 192.168.1.3:35449 in memory (size: 1708.0 B, free: 477.3 MB)
18/04/01 20:16:20 INFO Executor: Finished task 0.0 in stage 138.0 (TID 447). 938 bytes result sent to driver
18/04/01 20:16:20 INFO Executor: Finished task 1.0 in stage 138.0 (TID 448). 938 bytes result sent to driver
18/04/01 20:16:20 INFO TaskSetManager: Starting task 2.0 in stage 138.0 (TID 449, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3362
18/04/01 20:16:20 INFO Executor: Running task 2.0 in stage 138.0 (TID 449)
18/04/01 20:16:20 INFO TaskSetManager: Starting task 3.0 in stage 138.0 (TID 450, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3120
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3158
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3238
18/04/01 20:16:20 INFO TaskSetManager: Finished task 0.0 in stage 138.0 (TID 447) in 13 ms on localhost (executor driver) (1/5)
18/04/01 20:16:20 INFO Executor: Running task 3.0 in stage 138.0 (TID 450)
18/04/01 20:16:20 INFO TaskSetManager: Finished task 1.0 in stage 138.0 (TID 448) in 13 ms on localhost (executor driver) (2/5)
18/04/01 20:16:20 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:20 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3337
18/04/01 20:16:20 INFO ContextCleaner: Cleaned shuffle 43
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3210
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3012
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3343
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2988
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3018
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2998
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3436
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2991
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3128
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2973
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3007
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3381
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3374
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3302
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3219
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3227
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3317
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3409
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3245
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3339
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3212
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3435
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3359
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3001
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3045
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3077
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3135
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3194
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3268
18/04/01 20:16:20 INFO Executor: Finished task 3.0 in stage 138.0 (TID 450). 981 bytes result sent to driver
18/04/01 20:16:20 INFO TaskSetManager: Starting task 4.0 in stage 138.0 (TID 451, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:20 INFO Executor: Running task 4.0 in stage 138.0 (TID 451)
18/04/01 20:16:20 INFO TaskSetManager: Finished task 3.0 in stage 138.0 (TID 450) in 12 ms on localhost (executor driver) (3/5)
18/04/01 20:16:20 INFO BlockManagerInfo: Removed broadcast_127_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:20 INFO Executor: Finished task 2.0 in stage 138.0 (TID 449). 938 bytes result sent to driver
18/04/01 20:16:20 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 729 -> 731
18/04/01 20:16:20 INFO TaskSetManager: Finished task 2.0 in stage 138.0 (TID 449) in 18 ms on localhost (executor driver) (4/5)
18/04/01 20:16:20 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 729
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3401
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3331
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3176
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3408
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3110
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3116
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3208
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3292
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2985
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3101
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3010
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3163
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3138
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3081
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3430
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3156
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3072
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3234
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3225
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3125
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3395
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3349
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3334
18/04/01 20:16:20 INFO ContextCleaner: Cleaned shuffle 47
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3274
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3256
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3260
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3193
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3198
18/04/01 20:16:20 INFO BlockManagerInfo: Removed broadcast_135_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3180
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2959
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3118
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3237
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3048
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3357
18/04/01 20:16:20 INFO BlockManagerInfo: Removed broadcast_126_piece0 on 192.168.1.3:35449 in memory (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2997
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3026
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2970
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3365
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3122
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3152
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3231
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3264
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3153
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3323
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3269
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3356
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3126
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3393
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3239
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3205
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3067
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3127
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2967
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3360
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3344
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3053
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3364
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3353
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3019
18/04/01 20:16:20 INFO BlockManagerInfo: Removed broadcast_125_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3406
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3091
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3433
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3159
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3309
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3020
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3358
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2995
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3253
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3321
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2956
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3203
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3141
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3314
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3061
18/04/01 20:16:20 INFO ContextCleaner: Cleaned shuffle 39
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3051
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3099
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3310
18/04/01 20:16:20 INFO BlockManagerInfo: Removed broadcast_129_piece0 on 192.168.1.3:35449 in memory (size: 1988.0 B, free: 477.3 MB)
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3376
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3265
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2996
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3289
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3142
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3445
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3171
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2974
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3397
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3184
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2966
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2969
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3002
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3144
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3162
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3448
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3130
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3229
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3124
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3078
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3378
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2978
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3088
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3287
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3391
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3266
18/04/01 20:16:20 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3336
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3199
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3024
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3322
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3023
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3071
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3103
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3134
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3429
18/04/01 20:16:20 INFO BlockManagerInfo: Removed broadcast_128_piece0 on 192.168.1.3:35449 in memory (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3285
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3080
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3419
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3252
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3398
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3418
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3218
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2953
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3384
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2994
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3345
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3016
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3146
18/04/01 20:16:20 INFO ContextCleaner: Cleaned shuffle 45
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3431
18/04/01 20:16:20 INFO BlockManagerInfo: Removed broadcast_132_piece0 on 192.168.1.3:35449 in memory (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3327
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3111
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3164
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3375
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2976
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3052
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3366
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3439
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3169
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3133
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3299
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3108
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2987
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3178
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3013
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3005
18/04/01 20:16:20 INFO BlockManagerInfo: Removed broadcast_130_piece0 on 192.168.1.3:35449 in memory (size: 1988.0 B, free: 477.3 MB)
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2964
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3167
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3325
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3196
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3286
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3121
18/04/01 20:16:20 INFO BlockManagerInfo: Removed broadcast_136_piece0 on 192.168.1.3:35449 in memory (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3405
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3295
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2962
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3386
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3389
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3070
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3338
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3388
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2977
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3232
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3004
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3174
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3443
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3262
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3000
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3068
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3282
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3351
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3177
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3277
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3369
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3214
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3074
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3109
18/04/01 20:16:20 INFO BlockManagerInfo: Removed broadcast_124_piece0 on 192.168.1.3:35449 in memory (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:16:20 INFO BlockManagerInfo: Removed broadcast_131_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3270
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3226
18/04/01 20:16:20 INFO BlockManagerInfo: Removed broadcast_121_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3280
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3387
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3119
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3168
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3380
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3332
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3261
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3145
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3340
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2999
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3235
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3031
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3410
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3175
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3170
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3149
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3367
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3243
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3346
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3035
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3063
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3185
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3006
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3441
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3413
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3057
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3390
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3403
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2982
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3073
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3402
18/04/01 20:16:20 INFO BlockManagerInfo: Removed broadcast_123_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3298
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3132
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3085
18/04/01 20:16:20 INFO ContextCleaner: Cleaned shuffle 44
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3173
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3363
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3079
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3258
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3095
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3092
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3076
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3248
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3259
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2955
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3190
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3348
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3263
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3179
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3288
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3296
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3379
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3428
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3273
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2963
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3069
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2950
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3221
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3228
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3250
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3022
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3255
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3215
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3201
18/04/01 20:16:20 INFO BlockManagerInfo: Removed broadcast_137_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3107
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3113
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3368
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3131
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3308
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3211
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3060
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2984
18/04/01 20:16:20 INFO BlockManagerInfo: Removed broadcast_138_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3370
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2952
18/04/01 20:16:20 INFO ContextCleaner: Cleaned shuffle 41
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3084
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3276
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3129
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3316
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3254
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3165
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3087
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3396
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3420
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3098
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3148
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3202
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3415
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2980
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 2951
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3304
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3204
18/04/01 20:16:20 INFO ContextCleaner: Cleaned accumulator 3437
18/04/01 20:16:20 INFO Executor: Finished task 4.0 in stage 138.0 (TID 451). 1024 bytes result sent to driver
18/04/01 20:16:20 INFO TaskSetManager: Finished task 4.0 in stage 138.0 (TID 451) in 433 ms on localhost (executor driver) (5/5)
18/04/01 20:16:20 INFO TaskSchedulerImpl: Removed TaskSet 138.0, whose tasks have all completed, from pool 
18/04/01 20:16:20 INFO DAGScheduler: ShuffleMapStage 138 (map at RefereeStats.scala:53) finished in 0.493 s
18/04/01 20:16:20 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:16:20 INFO DAGScheduler: running: Set()
18/04/01 20:16:20 INFO DAGScheduler: waiting: Set(ResultStage 139)
18/04/01 20:16:20 INFO DAGScheduler: failed: Set()
18/04/01 20:16:20 INFO DAGScheduler: Submitting ResultStage 139 (ShuffledRDD[121] at reduceByKey at RefereeStats.scala:60), which has no missing parents
18/04/01 20:16:20 INFO MemoryStore: Block broadcast_140 stored as values in memory (estimated size 2.8 KB, free 477.3 MB)
18/04/01 20:16:20 INFO MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 1705.0 B, free 477.3 MB)
18/04/01 20:16:20 INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on 192.168.1.3:35449 (size: 1705.0 B, free: 477.3 MB)
18/04/01 20:16:20 INFO SparkContext: Created broadcast 140 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:20 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 139 (ShuffledRDD[121] at reduceByKey at RefereeStats.scala:60) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:16:20 INFO TaskSchedulerImpl: Adding task set 139.0 with 2 tasks
18/04/01 20:16:20 INFO TaskSetManager: Starting task 0.0 in stage 139.0 (TID 452, localhost, executor driver, partition 0, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:20 INFO TaskSetManager: Starting task 1.0 in stage 139.0 (TID 453, localhost, executor driver, partition 1, ANY, 7649 bytes)
18/04/01 20:16:20 INFO Executor: Running task 0.0 in stage 139.0 (TID 452)
18/04/01 20:16:20 INFO Executor: Running task 1.0 in stage 139.0 (TID 453)
18/04/01 20:16:20 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:16:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:20 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:20 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:20 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:20 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:20 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:20 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:20 INFO KafkaProducer: [Producer clientId=producer-103] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:20 INFO Executor: Finished task 0.0 in stage 139.0 (TID 452). 1138 bytes result sent to driver
18/04/01 20:16:20 INFO TaskSetManager: Finished task 0.0 in stage 139.0 (TID 452) in 17 ms on localhost (executor driver) (1/2)
18/04/01 20:16:20 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:16:20 INFO KafkaProducer: [Producer clientId=producer-104] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:20 INFO Executor: Finished task 1.0 in stage 139.0 (TID 453). 1138 bytes result sent to driver
18/04/01 20:16:20 INFO TaskSetManager: Finished task 1.0 in stage 139.0 (TID 453) in 28 ms on localhost (executor driver) (2/2)
18/04/01 20:16:20 INFO TaskSchedulerImpl: Removed TaskSet 139.0, whose tasks have all completed, from pool 
18/04/01 20:16:20 INFO DAGScheduler: ResultStage 139 (foreachPartition at RefereeStats.scala:71) finished in 0.037 s
18/04/01 20:16:20 INFO DAGScheduler: Job 87 finished: foreachPartition at RefereeStats.scala:71, took 0.536215 s
18/04/01 20:16:20 INFO JobScheduler: Finished job streaming job 1522602980000 ms.1 from job set of time 1522602980000 ms
18/04/01 20:16:20 INFO JobScheduler: Starting job streaming job 1522602980000 ms.2 from job set of time 1522602980000 ms
18/04/01 20:16:20 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:89
18/04/01 20:16:20 INFO DAGScheduler: Registering RDD 122 (map at RefereeStats.scala:46)
18/04/01 20:16:20 INFO DAGScheduler: Got job 88 (foreachPartition at RefereeStats.scala:89) with 2 output partitions
18/04/01 20:16:20 INFO DAGScheduler: Final stage: ResultStage 141 (foreachPartition at RefereeStats.scala:89)
18/04/01 20:16:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 140)
18/04/01 20:16:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 140)
18/04/01 20:16:20 INFO DAGScheduler: Submitting ShuffleMapStage 140 (MapPartitionsRDD[122] at map at RefereeStats.scala:46), which has no missing parents
18/04/01 20:16:20 INFO MemoryStore: Block broadcast_141 stored as values in memory (estimated size 3.9 KB, free 477.3 MB)
18/04/01 20:16:20 INFO MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.3 MB)
18/04/01 20:16:20 INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:20 INFO SparkContext: Created broadcast 141 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:20 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 140 (MapPartitionsRDD[122] at map at RefereeStats.scala:46) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:16:20 INFO TaskSchedulerImpl: Adding task set 140.0 with 5 tasks
18/04/01 20:16:20 INFO TaskSetManager: Starting task 0.0 in stage 140.0 (TID 454, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:20 INFO TaskSetManager: Starting task 1.0 in stage 140.0 (TID 455, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:20 INFO Executor: Running task 0.0 in stage 140.0 (TID 454)
18/04/01 20:16:20 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:20 INFO Executor: Running task 1.0 in stage 140.0 (TID 455)
18/04/01 20:16:20 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:20 INFO Executor: Finished task 1.0 in stage 140.0 (TID 455). 938 bytes result sent to driver
18/04/01 20:16:20 INFO TaskSetManager: Starting task 2.0 in stage 140.0 (TID 456, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:20 INFO TaskSetManager: Finished task 1.0 in stage 140.0 (TID 455) in 11 ms on localhost (executor driver) (1/5)
18/04/01 20:16:20 INFO Executor: Finished task 0.0 in stage 140.0 (TID 454). 938 bytes result sent to driver
18/04/01 20:16:20 INFO Executor: Running task 2.0 in stage 140.0 (TID 456)
18/04/01 20:16:20 INFO TaskSetManager: Starting task 3.0 in stage 140.0 (TID 457, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:20 INFO TaskSetManager: Finished task 0.0 in stage 140.0 (TID 454) in 14 ms on localhost (executor driver) (2/5)
18/04/01 20:16:20 INFO Executor: Running task 3.0 in stage 140.0 (TID 457)
18/04/01 20:16:20 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:20 INFO Executor: Finished task 2.0 in stage 140.0 (TID 456). 981 bytes result sent to driver
18/04/01 20:16:20 INFO TaskSetManager: Starting task 4.0 in stage 140.0 (TID 458, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:20 INFO TaskSetManager: Finished task 2.0 in stage 140.0 (TID 456) in 9 ms on localhost (executor driver) (3/5)
18/04/01 20:16:20 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:20 INFO Executor: Running task 4.0 in stage 140.0 (TID 458)
18/04/01 20:16:20 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 729 -> 731
18/04/01 20:16:20 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 729
18/04/01 20:16:20 INFO Executor: Finished task 3.0 in stage 140.0 (TID 457). 938 bytes result sent to driver
18/04/01 20:16:20 INFO TaskSetManager: Finished task 3.0 in stage 140.0 (TID 457) in 19 ms on localhost (executor driver) (4/5)
18/04/01 20:16:21 INFO Executor: Finished task 4.0 in stage 140.0 (TID 458). 1067 bytes result sent to driver
18/04/01 20:16:21 INFO TaskSetManager: Finished task 4.0 in stage 140.0 (TID 458) in 422 ms on localhost (executor driver) (5/5)
18/04/01 20:16:21 INFO TaskSchedulerImpl: Removed TaskSet 140.0, whose tasks have all completed, from pool 
18/04/01 20:16:21 INFO DAGScheduler: ShuffleMapStage 140 (map at RefereeStats.scala:46) finished in 0.452 s
18/04/01 20:16:21 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:16:21 INFO DAGScheduler: running: Set()
18/04/01 20:16:21 INFO DAGScheduler: waiting: Set(ResultStage 141)
18/04/01 20:16:21 INFO DAGScheduler: failed: Set()
18/04/01 20:16:21 INFO DAGScheduler: Submitting ResultStage 141 (ShuffledRDD[123] at reduceByKey at RefereeStats.scala:51), which has no missing parents
18/04/01 20:16:21 INFO MemoryStore: Block broadcast_142 stored as values in memory (estimated size 2.8 KB, free 477.3 MB)
18/04/01 20:16:21 INFO MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 1709.0 B, free 477.3 MB)
18/04/01 20:16:21 INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on 192.168.1.3:35449 (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:16:21 INFO SparkContext: Created broadcast 142 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:21 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 141 (ShuffledRDD[123] at reduceByKey at RefereeStats.scala:51) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:16:21 INFO TaskSchedulerImpl: Adding task set 141.0 with 2 tasks
18/04/01 20:16:21 INFO TaskSetManager: Starting task 0.0 in stage 141.0 (TID 459, localhost, executor driver, partition 0, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:21 INFO TaskSetManager: Starting task 1.0 in stage 141.0 (TID 460, localhost, executor driver, partition 1, ANY, 7649 bytes)
18/04/01 20:16:21 INFO Executor: Running task 1.0 in stage 141.0 (TID 460)
18/04/01 20:16:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:16:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:21 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:21 INFO Executor: Running task 0.0 in stage 141.0 (TID 459)
18/04/01 20:16:21 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:21 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:21 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:21 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:21 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:21 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:21 INFO KafkaProducer: [Producer clientId=producer-106] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:21 INFO Executor: Finished task 0.0 in stage 141.0 (TID 459). 1138 bytes result sent to driver
18/04/01 20:16:21 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:16:21 INFO TaskSetManager: Finished task 0.0 in stage 141.0 (TID 459) in 21 ms on localhost (executor driver) (1/2)
18/04/01 20:16:21 INFO KafkaProducer: [Producer clientId=producer-105] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:21 INFO Executor: Finished task 1.0 in stage 141.0 (TID 460). 1138 bytes result sent to driver
18/04/01 20:16:21 INFO TaskSetManager: Finished task 1.0 in stage 141.0 (TID 460) in 34 ms on localhost (executor driver) (2/2)
18/04/01 20:16:21 INFO TaskSchedulerImpl: Removed TaskSet 141.0, whose tasks have all completed, from pool 
18/04/01 20:16:21 INFO DAGScheduler: ResultStage 141 (foreachPartition at RefereeStats.scala:89) finished in 0.045 s
18/04/01 20:16:21 INFO DAGScheduler: Job 88 finished: foreachPartition at RefereeStats.scala:89, took 0.503264 s
18/04/01 20:16:21 INFO JobScheduler: Finished job streaming job 1522602980000 ms.2 from job set of time 1522602980000 ms
18/04/01 20:16:21 INFO JobScheduler: Starting job streaming job 1522602980000 ms.3 from job set of time 1522602980000 ms
18/04/01 20:16:21 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:106
18/04/01 20:16:21 INFO DAGScheduler: Registering RDD 124 (map at RefereeStats.scala:39)
18/04/01 20:16:21 INFO DAGScheduler: Got job 89 (foreachPartition at RefereeStats.scala:106) with 2 output partitions
18/04/01 20:16:21 INFO DAGScheduler: Final stage: ResultStage 143 (foreachPartition at RefereeStats.scala:106)
18/04/01 20:16:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 142)
18/04/01 20:16:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 142)
18/04/01 20:16:21 INFO DAGScheduler: Submitting ShuffleMapStage 142 (MapPartitionsRDD[124] at map at RefereeStats.scala:39), which has no missing parents
18/04/01 20:16:21 INFO MemoryStore: Block broadcast_143 stored as values in memory (estimated size 3.9 KB, free 477.3 MB)
18/04/01 20:16:21 INFO MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.3 MB)
18/04/01 20:16:21 INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:21 INFO SparkContext: Created broadcast 143 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:21 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 142 (MapPartitionsRDD[124] at map at RefereeStats.scala:39) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:16:21 INFO TaskSchedulerImpl: Adding task set 142.0 with 5 tasks
18/04/01 20:16:21 INFO TaskSetManager: Starting task 0.0 in stage 142.0 (TID 461, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:21 INFO TaskSetManager: Starting task 1.0 in stage 142.0 (TID 462, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:21 INFO Executor: Running task 1.0 in stage 142.0 (TID 462)
18/04/01 20:16:21 INFO Executor: Running task 0.0 in stage 142.0 (TID 461)
18/04/01 20:16:21 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:21 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:21 INFO Executor: Finished task 1.0 in stage 142.0 (TID 462). 938 bytes result sent to driver
18/04/01 20:16:21 INFO Executor: Finished task 0.0 in stage 142.0 (TID 461). 938 bytes result sent to driver
18/04/01 20:16:21 INFO TaskSetManager: Starting task 2.0 in stage 142.0 (TID 463, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:21 INFO TaskSetManager: Finished task 1.0 in stage 142.0 (TID 462) in 7 ms on localhost (executor driver) (1/5)
18/04/01 20:16:21 INFO Executor: Running task 2.0 in stage 142.0 (TID 463)
18/04/01 20:16:21 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:21 INFO TaskSetManager: Starting task 3.0 in stage 142.0 (TID 464, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:21 INFO TaskSetManager: Finished task 0.0 in stage 142.0 (TID 461) in 12 ms on localhost (executor driver) (2/5)
18/04/01 20:16:21 INFO Executor: Running task 3.0 in stage 142.0 (TID 464)
18/04/01 20:16:21 INFO Executor: Finished task 2.0 in stage 142.0 (TID 463). 938 bytes result sent to driver
18/04/01 20:16:21 INFO TaskSetManager: Starting task 4.0 in stage 142.0 (TID 465, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:21 INFO TaskSetManager: Finished task 2.0 in stage 142.0 (TID 463) in 8 ms on localhost (executor driver) (3/5)
18/04/01 20:16:21 INFO Executor: Running task 4.0 in stage 142.0 (TID 465)
18/04/01 20:16:21 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:21 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 729 -> 731
18/04/01 20:16:21 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 729
18/04/01 20:16:21 INFO Executor: Finished task 3.0 in stage 142.0 (TID 464). 938 bytes result sent to driver
18/04/01 20:16:21 INFO TaskSetManager: Finished task 3.0 in stage 142.0 (TID 464) in 8 ms on localhost (executor driver) (4/5)
18/04/01 20:16:21 INFO Executor: Finished task 4.0 in stage 142.0 (TID 465). 1024 bytes result sent to driver
18/04/01 20:16:21 INFO TaskSetManager: Finished task 4.0 in stage 142.0 (TID 465) in 425 ms on localhost (executor driver) (5/5)
18/04/01 20:16:21 INFO TaskSchedulerImpl: Removed TaskSet 142.0, whose tasks have all completed, from pool 
18/04/01 20:16:21 INFO DAGScheduler: ShuffleMapStage 142 (map at RefereeStats.scala:39) finished in 0.446 s
18/04/01 20:16:21 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:16:21 INFO DAGScheduler: running: Set()
18/04/01 20:16:21 INFO DAGScheduler: waiting: Set(ResultStage 143)
18/04/01 20:16:21 INFO DAGScheduler: failed: Set()
18/04/01 20:16:21 INFO DAGScheduler: Submitting ResultStage 143 (ShuffledRDD[125] at reduceByKey at RefereeStats.scala:43), which has no missing parents
18/04/01 20:16:21 INFO MemoryStore: Block broadcast_144 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:16:21 INFO MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 1711.0 B, free 477.2 MB)
18/04/01 20:16:21 INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on 192.168.1.3:35449 (size: 1711.0 B, free: 477.3 MB)
18/04/01 20:16:21 INFO SparkContext: Created broadcast 144 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:21 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 143 (ShuffledRDD[125] at reduceByKey at RefereeStats.scala:43) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:16:21 INFO TaskSchedulerImpl: Adding task set 143.0 with 2 tasks
18/04/01 20:16:21 INFO TaskSetManager: Starting task 0.0 in stage 143.0 (TID 466, localhost, executor driver, partition 0, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:21 INFO TaskSetManager: Starting task 1.0 in stage 143.0 (TID 467, localhost, executor driver, partition 1, ANY, 7649 bytes)
18/04/01 20:16:21 INFO Executor: Running task 0.0 in stage 143.0 (TID 466)
18/04/01 20:16:21 INFO Executor: Running task 1.0 in stage 143.0 (TID 467)
18/04/01 20:16:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:16:21 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:16:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:16:21 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:21 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:21 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:21 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:21 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:21 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:21 INFO KafkaProducer: [Producer clientId=producer-107] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:21 INFO Executor: Finished task 0.0 in stage 143.0 (TID 466). 1181 bytes result sent to driver
18/04/01 20:16:21 INFO TaskSetManager: Finished task 0.0 in stage 143.0 (TID 466) in 14 ms on localhost (executor driver) (1/2)
18/04/01 20:16:21 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:16:21 INFO KafkaProducer: [Producer clientId=producer-108] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:21 INFO Executor: Finished task 1.0 in stage 143.0 (TID 467). 1138 bytes result sent to driver
18/04/01 20:16:21 INFO TaskSetManager: Finished task 1.0 in stage 143.0 (TID 467) in 27 ms on localhost (executor driver) (2/2)
18/04/01 20:16:21 INFO TaskSchedulerImpl: Removed TaskSet 143.0, whose tasks have all completed, from pool 
18/04/01 20:16:21 INFO DAGScheduler: ResultStage 143 (foreachPartition at RefereeStats.scala:106) finished in 0.035 s
18/04/01 20:16:21 INFO DAGScheduler: Job 89 finished: foreachPartition at RefereeStats.scala:106, took 0.488440 s
18/04/01 20:16:21 INFO JobScheduler: Finished job streaming job 1522602980000 ms.3 from job set of time 1522602980000 ms
18/04/01 20:16:21 INFO JobScheduler: Total delay: 1.660 s for time 1522602980000 ms (execution: 1.635 s)
18/04/01 20:16:21 INFO MapPartitionsRDD: Removing RDD 113 from persistence list
18/04/01 20:16:21 INFO BlockManager: Removing RDD 113
18/04/01 20:16:21 INFO KafkaRDD: Removing RDD 112 from persistence list
18/04/01 20:16:21 INFO BlockManager: Removing RDD 112
18/04/01 20:16:21 INFO ShuffledRDD: Removing RDD 114 from persistence list
18/04/01 20:16:21 INFO BlockManager: Removing RDD 114
18/04/01 20:16:21 INFO ShuffledRDD: Removing RDD 116 from persistence list
18/04/01 20:16:21 INFO BlockManager: Removing RDD 116
18/04/01 20:16:21 INFO MapPartitionsRDD: Removing RDD 115 from persistence list
18/04/01 20:16:21 INFO ShuffledRDD: Removing RDD 118 from persistence list
18/04/01 20:16:21 INFO BlockManager: Removing RDD 115
18/04/01 20:16:21 INFO BlockManager: Removing RDD 118
18/04/01 20:16:21 INFO MapPartitionsRDD: Removing RDD 117 from persistence list
18/04/01 20:16:21 INFO BlockManager: Removing RDD 117
18/04/01 20:16:21 INFO JobGenerator: Checkpointing graph for time 1522602980000 ms
18/04/01 20:16:21 INFO DStreamGraph: Updating checkpoint data for time 1522602980000 ms
18/04/01 20:16:21 INFO DStreamGraph: Updated checkpoint data for time 1522602980000 ms
18/04/01 20:16:21 INFO CheckpointWriter: Submitted checkpoint of time 1522602980000 ms to writer queue
18/04/01 20:16:21 INFO CheckpointWriter: Saving checkpoint for time 1522602980000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602980000'
18/04/01 20:16:21 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602955000
18/04/01 20:16:21 INFO CheckpointWriter: Checkpoint for time 1522602980000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602980000', took 5537 bytes and 18 ms
18/04/01 20:16:21 INFO DStreamGraph: Clearing checkpoint data for time 1522602980000 ms
18/04/01 20:16:21 INFO DStreamGraph: Cleared checkpoint data for time 1522602980000 ms
18/04/01 20:16:21 INFO ReceivedBlockTracker: Deleting batches: 
18/04/01 20:16:21 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/tmp/refs-xyzabb/receivedBlockMetadata older than 1522602975000: 
18/04/01 20:16:21 INFO InputInfoTracker: remove old batch metadata: 1522602970000 ms
18/04/01 20:16:25 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-0 to offset 732.
18/04/01 20:16:25 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-3 to offset 0.
18/04/01 20:16:25 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-4 to offset 0.
18/04/01 20:16:25 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-1 to offset 0.
18/04/01 20:16:25 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-2 to offset 0.
18/04/01 20:16:25 INFO JobScheduler: Added jobs for time 1522602985000 ms
18/04/01 20:16:25 INFO JobGenerator: Checkpointing graph for time 1522602985000 ms
18/04/01 20:16:25 INFO DStreamGraph: Updating checkpoint data for time 1522602985000 ms
18/04/01 20:16:25 INFO DStreamGraph: Updated checkpoint data for time 1522602985000 ms
18/04/01 20:16:25 INFO JobScheduler: Starting job streaming job 1522602985000 ms.0 from job set of time 1522602985000 ms
18/04/01 20:16:25 INFO CheckpointWriter: Submitted checkpoint of time 1522602985000 ms to writer queue
18/04/01 20:16:25 INFO CheckpointWriter: Saving checkpoint for time 1522602985000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602985000'
18/04/01 20:16:25 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:16:25 INFO DAGScheduler: Got job 90 (print at RefereeStats.scala:67) with 1 output partitions
18/04/01 20:16:25 INFO DAGScheduler: Final stage: ResultStage 144 (print at RefereeStats.scala:67)
18/04/01 20:16:25 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:16:25 INFO DAGScheduler: Missing parents: List()
18/04/01 20:16:25 INFO DAGScheduler: Submitting ResultStage 144 (MapPartitionsRDD[127] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:16:25 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602960000.bk
18/04/01 20:16:25 INFO CheckpointWriter: Checkpoint for time 1522602985000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602985000', took 5595 bytes and 15 ms
18/04/01 20:16:25 INFO MemoryStore: Block broadcast_145 stored as values in memory (estimated size 3.0 KB, free 477.2 MB)
18/04/01 20:16:25 INFO MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.2 MB)
18/04/01 20:16:25 INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:25 INFO SparkContext: Created broadcast 145 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 144 (MapPartitionsRDD[127] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0))
18/04/01 20:16:25 INFO TaskSchedulerImpl: Adding task set 144.0 with 1 tasks
18/04/01 20:16:25 INFO TaskSetManager: Starting task 0.0 in stage 144.0 (TID 468, localhost, executor driver, partition 0, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:25 INFO Executor: Running task 0.0 in stage 144.0 (TID 468)
18/04/01 20:16:25 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:25 INFO Executor: Finished task 0.0 in stage 144.0 (TID 468). 704 bytes result sent to driver
18/04/01 20:16:25 INFO TaskSetManager: Finished task 0.0 in stage 144.0 (TID 468) in 4 ms on localhost (executor driver) (1/1)
18/04/01 20:16:25 INFO TaskSchedulerImpl: Removed TaskSet 144.0, whose tasks have all completed, from pool 
18/04/01 20:16:25 INFO DAGScheduler: ResultStage 144 (print at RefereeStats.scala:67) finished in 0.011 s
18/04/01 20:16:25 INFO DAGScheduler: Job 90 finished: print at RefereeStats.scala:67, took 0.015655 s
18/04/01 20:16:25 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:16:25 INFO DAGScheduler: Got job 91 (print at RefereeStats.scala:67) with 4 output partitions
18/04/01 20:16:25 INFO DAGScheduler: Final stage: ResultStage 145 (print at RefereeStats.scala:67)
18/04/01 20:16:25 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:16:25 INFO DAGScheduler: Missing parents: List()
18/04/01 20:16:25 INFO DAGScheduler: Submitting ResultStage 145 (MapPartitionsRDD[127] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:16:25 INFO MemoryStore: Block broadcast_146 stored as values in memory (estimated size 3.0 KB, free 477.2 MB)
18/04/01 20:16:25 INFO MemoryStore: Block broadcast_146_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.2 MB)
18/04/01 20:16:25 INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:25 INFO SparkContext: Created broadcast 146 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:25 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 145 (MapPartitionsRDD[127] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
18/04/01 20:16:25 INFO TaskSchedulerImpl: Adding task set 145.0 with 4 tasks
18/04/01 20:16:25 INFO TaskSetManager: Starting task 0.0 in stage 145.0 (TID 469, localhost, executor driver, partition 1, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:25 INFO TaskSetManager: Starting task 1.0 in stage 145.0 (TID 470, localhost, executor driver, partition 2, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:25 INFO Executor: Running task 1.0 in stage 145.0 (TID 470)
18/04/01 20:16:25 INFO Executor: Running task 0.0 in stage 145.0 (TID 469)
18/04/01 20:16:25 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:25 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:25 INFO Executor: Finished task 1.0 in stage 145.0 (TID 470). 704 bytes result sent to driver
18/04/01 20:16:25 INFO Executor: Finished task 0.0 in stage 145.0 (TID 469). 704 bytes result sent to driver
18/04/01 20:16:25 INFO TaskSetManager: Starting task 2.0 in stage 145.0 (TID 471, localhost, executor driver, partition 3, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:25 INFO Executor: Running task 2.0 in stage 145.0 (TID 471)
18/04/01 20:16:25 INFO TaskSetManager: Starting task 3.0 in stage 145.0 (TID 472, localhost, executor driver, partition 4, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:25 INFO Executor: Running task 3.0 in stage 145.0 (TID 472)
18/04/01 20:16:25 INFO TaskSetManager: Finished task 1.0 in stage 145.0 (TID 470) in 5 ms on localhost (executor driver) (1/4)
18/04/01 20:16:25 INFO TaskSetManager: Finished task 0.0 in stage 145.0 (TID 469) in 6 ms on localhost (executor driver) (2/4)
18/04/01 20:16:25 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:25 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 731 -> 732
18/04/01 20:16:25 INFO Executor: Finished task 2.0 in stage 145.0 (TID 471). 704 bytes result sent to driver
18/04/01 20:16:25 INFO Executor: Finished task 3.0 in stage 145.0 (TID 472). 902 bytes result sent to driver
18/04/01 20:16:25 INFO TaskSetManager: Finished task 2.0 in stage 145.0 (TID 471) in 9 ms on localhost (executor driver) (3/4)
18/04/01 20:16:25 INFO TaskSetManager: Finished task 3.0 in stage 145.0 (TID 472) in 8 ms on localhost (executor driver) (4/4)
18/04/01 20:16:25 INFO TaskSchedulerImpl: Removed TaskSet 145.0, whose tasks have all completed, from pool 
18/04/01 20:16:25 INFO DAGScheduler: ResultStage 145 (print at RefereeStats.scala:67) finished in 0.024 s
18/04/01 20:16:25 INFO DAGScheduler: Job 91 finished: print at RefereeStats.scala:67, took 0.029408 s
18/04/01 20:16:25 INFO JobScheduler: Finished job streaming job 1522602985000 ms.0 from job set of time 1522602985000 ms
18/04/01 20:16:25 INFO JobScheduler: Starting job streaming job 1522602985000 ms.1 from job set of time 1522602985000 ms
-------------------------------------------
Time: 1522602985000 ms
-------------------------------------------
(twitter.*,0)

18/04/01 20:16:25 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:71
18/04/01 20:16:25 INFO DAGScheduler: Registering RDD 127 (map at RefereeStats.scala:53)
18/04/01 20:16:25 INFO DAGScheduler: Got job 92 (foreachPartition at RefereeStats.scala:71) with 2 output partitions
18/04/01 20:16:25 INFO DAGScheduler: Final stage: ResultStage 147 (foreachPartition at RefereeStats.scala:71)
18/04/01 20:16:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 146)
18/04/01 20:16:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 146)
18/04/01 20:16:25 INFO DAGScheduler: Submitting ShuffleMapStage 146 (MapPartitionsRDD[127] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:16:25 INFO MemoryStore: Block broadcast_147 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:16:25 INFO MemoryStore: Block broadcast_147_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:16:25 INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:25 INFO SparkContext: Created broadcast 147 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:25 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 146 (MapPartitionsRDD[127] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:16:25 INFO TaskSchedulerImpl: Adding task set 146.0 with 5 tasks
18/04/01 20:16:25 INFO TaskSetManager: Starting task 0.0 in stage 146.0 (TID 473, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:25 INFO TaskSetManager: Starting task 1.0 in stage 146.0 (TID 474, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:25 INFO Executor: Running task 0.0 in stage 146.0 (TID 473)
18/04/01 20:16:25 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:25 INFO Executor: Running task 1.0 in stage 146.0 (TID 474)
18/04/01 20:16:25 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:25 INFO Executor: Finished task 0.0 in stage 146.0 (TID 473). 938 bytes result sent to driver
18/04/01 20:16:25 INFO Executor: Finished task 1.0 in stage 146.0 (TID 474). 938 bytes result sent to driver
18/04/01 20:16:25 INFO TaskSetManager: Starting task 2.0 in stage 146.0 (TID 475, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:25 INFO Executor: Running task 2.0 in stage 146.0 (TID 475)
18/04/01 20:16:25 INFO TaskSetManager: Starting task 3.0 in stage 146.0 (TID 476, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:25 INFO Executor: Running task 3.0 in stage 146.0 (TID 476)
18/04/01 20:16:25 INFO TaskSetManager: Finished task 1.0 in stage 146.0 (TID 474) in 12 ms on localhost (executor driver) (1/5)
18/04/01 20:16:25 INFO TaskSetManager: Finished task 0.0 in stage 146.0 (TID 473) in 13 ms on localhost (executor driver) (2/5)
18/04/01 20:16:25 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:25 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:25 INFO Executor: Finished task 2.0 in stage 146.0 (TID 475). 938 bytes result sent to driver
18/04/01 20:16:25 INFO Executor: Finished task 3.0 in stage 146.0 (TID 476). 938 bytes result sent to driver
18/04/01 20:16:25 INFO TaskSetManager: Starting task 4.0 in stage 146.0 (TID 477, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:25 INFO Executor: Running task 4.0 in stage 146.0 (TID 477)
18/04/01 20:16:25 INFO TaskSetManager: Finished task 3.0 in stage 146.0 (TID 476) in 7 ms on localhost (executor driver) (3/5)
18/04/01 20:16:25 INFO TaskSetManager: Finished task 2.0 in stage 146.0 (TID 475) in 8 ms on localhost (executor driver) (4/5)
18/04/01 20:16:25 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 731 -> 732
18/04/01 20:16:25 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 731
18/04/01 20:16:25 INFO Executor: Finished task 4.0 in stage 146.0 (TID 477). 1024 bytes result sent to driver
18/04/01 20:16:25 INFO TaskSetManager: Finished task 4.0 in stage 146.0 (TID 477) in 466 ms on localhost (executor driver) (5/5)
18/04/01 20:16:25 INFO TaskSchedulerImpl: Removed TaskSet 146.0, whose tasks have all completed, from pool 
18/04/01 20:16:25 INFO DAGScheduler: ShuffleMapStage 146 (map at RefereeStats.scala:53) finished in 0.492 s
18/04/01 20:16:25 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:16:25 INFO DAGScheduler: running: Set()
18/04/01 20:16:25 INFO DAGScheduler: waiting: Set(ResultStage 147)
18/04/01 20:16:25 INFO DAGScheduler: failed: Set()
18/04/01 20:16:25 INFO DAGScheduler: Submitting ResultStage 147 (ShuffledRDD[128] at reduceByKey at RefereeStats.scala:60), which has no missing parents
18/04/01 20:16:25 INFO MemoryStore: Block broadcast_148 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:16:25 INFO MemoryStore: Block broadcast_148_piece0 stored as bytes in memory (estimated size 1706.0 B, free 477.2 MB)
18/04/01 20:16:25 INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on 192.168.1.3:35449 (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:16:25 INFO SparkContext: Created broadcast 148 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:25 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 147 (ShuffledRDD[128] at reduceByKey at RefereeStats.scala:60) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:16:25 INFO TaskSchedulerImpl: Adding task set 147.0 with 2 tasks
18/04/01 20:16:25 INFO TaskSetManager: Starting task 0.0 in stage 147.0 (TID 478, localhost, executor driver, partition 0, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:25 INFO TaskSetManager: Starting task 1.0 in stage 147.0 (TID 479, localhost, executor driver, partition 1, ANY, 7649 bytes)
18/04/01 20:16:25 INFO Executor: Running task 1.0 in stage 147.0 (TID 479)
18/04/01 20:16:25 INFO Executor: Running task 0.0 in stage 147.0 (TID 478)
18/04/01 20:16:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:16:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:16:25 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:25 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
18/04/01 20:16:25 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:25 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:25 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:25 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:25 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:25 INFO KafkaProducer: [Producer clientId=producer-110] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:25 INFO Executor: Finished task 0.0 in stage 147.0 (TID 478). 1138 bytes result sent to driver
18/04/01 20:16:25 INFO TaskSetManager: Finished task 0.0 in stage 147.0 (TID 478) in 18 ms on localhost (executor driver) (1/2)
18/04/01 20:16:25 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:16:25 INFO KafkaProducer: [Producer clientId=producer-109] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:25 INFO Executor: Finished task 1.0 in stage 147.0 (TID 479). 1138 bytes result sent to driver
18/04/01 20:16:25 INFO TaskSetManager: Finished task 1.0 in stage 147.0 (TID 479) in 30 ms on localhost (executor driver) (2/2)
18/04/01 20:16:25 INFO TaskSchedulerImpl: Removed TaskSet 147.0, whose tasks have all completed, from pool 
18/04/01 20:16:25 INFO DAGScheduler: ResultStage 147 (foreachPartition at RefereeStats.scala:71) finished in 0.042 s
18/04/01 20:16:25 INFO DAGScheduler: Job 92 finished: foreachPartition at RefereeStats.scala:71, took 0.540146 s
18/04/01 20:16:25 INFO JobScheduler: Finished job streaming job 1522602985000 ms.1 from job set of time 1522602985000 ms
18/04/01 20:16:25 INFO JobScheduler: Starting job streaming job 1522602985000 ms.2 from job set of time 1522602985000 ms
18/04/01 20:16:25 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:89
18/04/01 20:16:25 INFO DAGScheduler: Registering RDD 129 (map at RefereeStats.scala:46)
18/04/01 20:16:25 INFO DAGScheduler: Got job 93 (foreachPartition at RefereeStats.scala:89) with 2 output partitions
18/04/01 20:16:25 INFO DAGScheduler: Final stage: ResultStage 149 (foreachPartition at RefereeStats.scala:89)
18/04/01 20:16:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 148)
18/04/01 20:16:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 148)
18/04/01 20:16:25 INFO DAGScheduler: Submitting ShuffleMapStage 148 (MapPartitionsRDD[129] at map at RefereeStats.scala:46), which has no missing parents
18/04/01 20:16:25 INFO MemoryStore: Block broadcast_149 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:16:25 INFO MemoryStore: Block broadcast_149_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:16:25 INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:25 INFO SparkContext: Created broadcast 149 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:25 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 148 (MapPartitionsRDD[129] at map at RefereeStats.scala:46) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:16:25 INFO TaskSchedulerImpl: Adding task set 148.0 with 5 tasks
18/04/01 20:16:25 INFO TaskSetManager: Starting task 0.0 in stage 148.0 (TID 480, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:25 INFO TaskSetManager: Starting task 1.0 in stage 148.0 (TID 481, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:25 INFO Executor: Running task 1.0 in stage 148.0 (TID 481)
18/04/01 20:16:25 INFO Executor: Running task 0.0 in stage 148.0 (TID 480)
18/04/01 20:16:25 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:25 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:25 INFO Executor: Finished task 0.0 in stage 148.0 (TID 480). 938 bytes result sent to driver
18/04/01 20:16:25 INFO TaskSetManager: Starting task 2.0 in stage 148.0 (TID 482, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:25 INFO TaskSetManager: Finished task 0.0 in stage 148.0 (TID 480) in 8 ms on localhost (executor driver) (1/5)
18/04/01 20:16:25 INFO Executor: Finished task 1.0 in stage 148.0 (TID 481). 938 bytes result sent to driver
18/04/01 20:16:25 INFO Executor: Running task 2.0 in stage 148.0 (TID 482)
18/04/01 20:16:25 INFO TaskSetManager: Starting task 3.0 in stage 148.0 (TID 483, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:25 INFO TaskSetManager: Finished task 1.0 in stage 148.0 (TID 481) in 8 ms on localhost (executor driver) (2/5)
18/04/01 20:16:25 INFO Executor: Running task 3.0 in stage 148.0 (TID 483)
18/04/01 20:16:25 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:25 INFO Executor: Finished task 3.0 in stage 148.0 (TID 483). 938 bytes result sent to driver
18/04/01 20:16:25 INFO TaskSetManager: Starting task 4.0 in stage 148.0 (TID 484, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:25 INFO Executor: Running task 4.0 in stage 148.0 (TID 484)
18/04/01 20:16:25 INFO TaskSetManager: Finished task 3.0 in stage 148.0 (TID 483) in 7 ms on localhost (executor driver) (3/5)
18/04/01 20:16:25 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:25 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 731 -> 732
18/04/01 20:16:25 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 731
18/04/01 20:16:25 INFO Executor: Finished task 2.0 in stage 148.0 (TID 482). 938 bytes result sent to driver
18/04/01 20:16:25 INFO TaskSetManager: Finished task 2.0 in stage 148.0 (TID 482) in 14 ms on localhost (executor driver) (4/5)
18/04/01 20:16:26 INFO Executor: Finished task 4.0 in stage 148.0 (TID 484). 1024 bytes result sent to driver
18/04/01 20:16:26 INFO TaskSetManager: Finished task 4.0 in stage 148.0 (TID 484) in 429 ms on localhost (executor driver) (5/5)
18/04/01 20:16:26 INFO TaskSchedulerImpl: Removed TaskSet 148.0, whose tasks have all completed, from pool 
18/04/01 20:16:26 INFO DAGScheduler: ShuffleMapStage 148 (map at RefereeStats.scala:46) finished in 0.452 s
18/04/01 20:16:26 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:16:26 INFO DAGScheduler: running: Set()
18/04/01 20:16:26 INFO DAGScheduler: waiting: Set(ResultStage 149)
18/04/01 20:16:26 INFO DAGScheduler: failed: Set()
18/04/01 20:16:26 INFO DAGScheduler: Submitting ResultStage 149 (ShuffledRDD[130] at reduceByKey at RefereeStats.scala:51), which has no missing parents
18/04/01 20:16:26 INFO MemoryStore: Block broadcast_150 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:16:26 INFO MemoryStore: Block broadcast_150_piece0 stored as bytes in memory (estimated size 1709.0 B, free 477.2 MB)
18/04/01 20:16:26 INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on 192.168.1.3:35449 (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:16:26 INFO SparkContext: Created broadcast 150 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 149 (ShuffledRDD[130] at reduceByKey at RefereeStats.scala:51) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:16:26 INFO TaskSchedulerImpl: Adding task set 149.0 with 2 tasks
18/04/01 20:16:26 INFO TaskSetManager: Starting task 0.0 in stage 149.0 (TID 485, localhost, executor driver, partition 0, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:26 INFO TaskSetManager: Starting task 1.0 in stage 149.0 (TID 486, localhost, executor driver, partition 1, ANY, 7649 bytes)
18/04/01 20:16:26 INFO Executor: Running task 0.0 in stage 149.0 (TID 485)
18/04/01 20:16:26 INFO Executor: Running task 1.0 in stage 149.0 (TID 486)
18/04/01 20:16:26 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:16:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:26 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:26 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:26 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:26 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:26 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:26 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:26 INFO KafkaProducer: [Producer clientId=producer-111] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:26 INFO Executor: Finished task 0.0 in stage 149.0 (TID 485). 1138 bytes result sent to driver
18/04/01 20:16:26 INFO TaskSetManager: Finished task 0.0 in stage 149.0 (TID 485) in 16 ms on localhost (executor driver) (1/2)
18/04/01 20:16:26 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:16:26 INFO KafkaProducer: [Producer clientId=producer-112] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:26 INFO Executor: Finished task 1.0 in stage 149.0 (TID 486). 1138 bytes result sent to driver
18/04/01 20:16:26 INFO TaskSetManager: Finished task 1.0 in stage 149.0 (TID 486) in 27 ms on localhost (executor driver) (2/2)
18/04/01 20:16:26 INFO TaskSchedulerImpl: Removed TaskSet 149.0, whose tasks have all completed, from pool 
18/04/01 20:16:26 INFO DAGScheduler: ResultStage 149 (foreachPartition at RefereeStats.scala:89) finished in 0.035 s
18/04/01 20:16:26 INFO DAGScheduler: Job 93 finished: foreachPartition at RefereeStats.scala:89, took 0.492548 s
18/04/01 20:16:26 INFO JobScheduler: Finished job streaming job 1522602985000 ms.2 from job set of time 1522602985000 ms
18/04/01 20:16:26 INFO JobScheduler: Starting job streaming job 1522602985000 ms.3 from job set of time 1522602985000 ms
18/04/01 20:16:26 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:106
18/04/01 20:16:26 INFO DAGScheduler: Registering RDD 131 (map at RefereeStats.scala:39)
18/04/01 20:16:26 INFO DAGScheduler: Got job 94 (foreachPartition at RefereeStats.scala:106) with 2 output partitions
18/04/01 20:16:26 INFO DAGScheduler: Final stage: ResultStage 151 (foreachPartition at RefereeStats.scala:106)
18/04/01 20:16:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 150)
18/04/01 20:16:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 150)
18/04/01 20:16:26 INFO DAGScheduler: Submitting ShuffleMapStage 150 (MapPartitionsRDD[131] at map at RefereeStats.scala:39), which has no missing parents
18/04/01 20:16:26 INFO MemoryStore: Block broadcast_151 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:16:26 INFO MemoryStore: Block broadcast_151_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:16:26 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:26 INFO SparkContext: Created broadcast 151 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:26 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 150 (MapPartitionsRDD[131] at map at RefereeStats.scala:39) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:16:26 INFO TaskSchedulerImpl: Adding task set 150.0 with 5 tasks
18/04/01 20:16:26 INFO TaskSetManager: Starting task 0.0 in stage 150.0 (TID 487, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:26 INFO TaskSetManager: Starting task 1.0 in stage 150.0 (TID 488, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:26 INFO Executor: Running task 0.0 in stage 150.0 (TID 487)
18/04/01 20:16:26 INFO Executor: Running task 1.0 in stage 150.0 (TID 488)
18/04/01 20:16:26 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:26 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:26 INFO Executor: Finished task 1.0 in stage 150.0 (TID 488). 938 bytes result sent to driver
18/04/01 20:16:26 INFO Executor: Finished task 0.0 in stage 150.0 (TID 487). 938 bytes result sent to driver
18/04/01 20:16:26 INFO TaskSetManager: Starting task 2.0 in stage 150.0 (TID 489, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:26 INFO TaskSetManager: Finished task 1.0 in stage 150.0 (TID 488) in 7 ms on localhost (executor driver) (1/5)
18/04/01 20:16:26 INFO Executor: Running task 2.0 in stage 150.0 (TID 489)
18/04/01 20:16:26 INFO TaskSetManager: Starting task 3.0 in stage 150.0 (TID 490, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:26 INFO TaskSetManager: Finished task 0.0 in stage 150.0 (TID 487) in 8 ms on localhost (executor driver) (2/5)
18/04/01 20:16:26 INFO Executor: Running task 3.0 in stage 150.0 (TID 490)
18/04/01 20:16:26 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:26 INFO Executor: Finished task 2.0 in stage 150.0 (TID 489). 938 bytes result sent to driver
18/04/01 20:16:26 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:26 INFO TaskSetManager: Starting task 4.0 in stage 150.0 (TID 491, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:26 INFO TaskSetManager: Finished task 2.0 in stage 150.0 (TID 489) in 6 ms on localhost (executor driver) (3/5)
18/04/01 20:16:26 INFO Executor: Running task 4.0 in stage 150.0 (TID 491)
18/04/01 20:16:26 INFO Executor: Finished task 3.0 in stage 150.0 (TID 490). 938 bytes result sent to driver
18/04/01 20:16:26 INFO TaskSetManager: Finished task 3.0 in stage 150.0 (TID 490) in 8 ms on localhost (executor driver) (4/5)
18/04/01 20:16:26 INFO KafkaRDD: Computing topic clients-purchases-src-xxx, partition 0 offsets 731 -> 732
18/04/01 20:16:26 INFO CachedKafkaConsumer: Initial fetch for spark-executor-streamer-xxx-xyzab clients-purchases-src-xxx 0 731
18/04/01 20:16:26 INFO Executor: Finished task 4.0 in stage 150.0 (TID 491). 1024 bytes result sent to driver
18/04/01 20:16:26 INFO TaskSetManager: Finished task 4.0 in stage 150.0 (TID 491) in 437 ms on localhost (executor driver) (5/5)
18/04/01 20:16:26 INFO TaskSchedulerImpl: Removed TaskSet 150.0, whose tasks have all completed, from pool 
18/04/01 20:16:26 INFO DAGScheduler: ShuffleMapStage 150 (map at RefereeStats.scala:39) finished in 0.458 s
18/04/01 20:16:26 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:16:26 INFO DAGScheduler: running: Set()
18/04/01 20:16:26 INFO DAGScheduler: waiting: Set(ResultStage 151)
18/04/01 20:16:26 INFO DAGScheduler: failed: Set()
18/04/01 20:16:26 INFO DAGScheduler: Submitting ResultStage 151 (ShuffledRDD[132] at reduceByKey at RefereeStats.scala:43), which has no missing parents
18/04/01 20:16:26 INFO MemoryStore: Block broadcast_152 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:16:26 INFO MemoryStore: Block broadcast_152_piece0 stored as bytes in memory (estimated size 1704.0 B, free 477.2 MB)
18/04/01 20:16:26 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on 192.168.1.3:35449 (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:16:26 INFO SparkContext: Created broadcast 152 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 151 (ShuffledRDD[132] at reduceByKey at RefereeStats.scala:43) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:16:26 INFO TaskSchedulerImpl: Adding task set 151.0 with 2 tasks
18/04/01 20:16:26 INFO TaskSetManager: Starting task 0.0 in stage 151.0 (TID 492, localhost, executor driver, partition 0, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:26 INFO TaskSetManager: Starting task 1.0 in stage 151.0 (TID 493, localhost, executor driver, partition 1, ANY, 7649 bytes)
18/04/01 20:16:26 INFO Executor: Running task 1.0 in stage 151.0 (TID 493)
18/04/01 20:16:26 INFO Executor: Running task 0.0 in stage 151.0 (TID 492)
18/04/01 20:16:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
18/04/01 20:16:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:26 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:26 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:26 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:26 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:26 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:26 INFO KafkaProducer: [Producer clientId=producer-113] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:26 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:26 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:26 INFO Executor: Finished task 0.0 in stage 151.0 (TID 492). 1138 bytes result sent to driver
18/04/01 20:16:26 INFO TaskSetManager: Finished task 0.0 in stage 151.0 (TID 492) in 15 ms on localhost (executor driver) (1/2)
18/04/01 20:16:26 INFO Metadata: Cluster ID: PeiwkUWbSVSE_0h8brQedQ
18/04/01 20:16:26 INFO KafkaProducer: [Producer clientId=producer-114] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:26 INFO Executor: Finished task 1.0 in stage 151.0 (TID 493). 1138 bytes result sent to driver
18/04/01 20:16:26 INFO TaskSetManager: Finished task 1.0 in stage 151.0 (TID 493) in 29 ms on localhost (executor driver) (2/2)
18/04/01 20:16:26 INFO TaskSchedulerImpl: Removed TaskSet 151.0, whose tasks have all completed, from pool 
18/04/01 20:16:26 INFO DAGScheduler: ResultStage 151 (foreachPartition at RefereeStats.scala:106) finished in 0.037 s
18/04/01 20:16:26 INFO DAGScheduler: Job 94 finished: foreachPartition at RefereeStats.scala:106, took 0.501268 s
18/04/01 20:16:26 INFO JobScheduler: Finished job streaming job 1522602985000 ms.3 from job set of time 1522602985000 ms
18/04/01 20:16:26 INFO JobScheduler: Total delay: 1.655 s for time 1522602985000 ms (execution: 1.626 s)
18/04/01 20:16:26 INFO MapPartitionsRDD: Removing RDD 120 from persistence list
18/04/01 20:16:26 INFO BlockManager: Removing RDD 120
18/04/01 20:16:26 INFO KafkaRDD: Removing RDD 119 from persistence list
18/04/01 20:16:26 INFO BlockManager: Removing RDD 119
18/04/01 20:16:26 INFO ShuffledRDD: Removing RDD 121 from persistence list
18/04/01 20:16:26 INFO BlockManager: Removing RDD 121
18/04/01 20:16:26 INFO ShuffledRDD: Removing RDD 123 from persistence list
18/04/01 20:16:26 INFO BlockManager: Removing RDD 123
18/04/01 20:16:26 INFO MapPartitionsRDD: Removing RDD 122 from persistence list
18/04/01 20:16:26 INFO BlockManager: Removing RDD 122
18/04/01 20:16:26 INFO ShuffledRDD: Removing RDD 125 from persistence list
18/04/01 20:16:26 INFO BlockManager: Removing RDD 125
18/04/01 20:16:26 INFO MapPartitionsRDD: Removing RDD 124 from persistence list
18/04/01 20:16:26 INFO BlockManager: Removing RDD 124
18/04/01 20:16:26 INFO JobGenerator: Checkpointing graph for time 1522602985000 ms
18/04/01 20:16:26 INFO DStreamGraph: Updating checkpoint data for time 1522602985000 ms
18/04/01 20:16:26 INFO DStreamGraph: Updated checkpoint data for time 1522602985000 ms
18/04/01 20:16:26 INFO CheckpointWriter: Submitted checkpoint of time 1522602985000 ms to writer queue
18/04/01 20:16:26 INFO CheckpointWriter: Saving checkpoint for time 1522602985000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602985000'
18/04/01 20:16:26 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602960000
18/04/01 20:16:26 INFO CheckpointWriter: Checkpoint for time 1522602985000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602985000', took 5537 bytes and 15 ms
18/04/01 20:16:26 INFO DStreamGraph: Clearing checkpoint data for time 1522602985000 ms
18/04/01 20:16:26 INFO DStreamGraph: Cleared checkpoint data for time 1522602985000 ms
18/04/01 20:16:26 INFO ReceivedBlockTracker: Deleting batches: 
18/04/01 20:16:26 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/tmp/refs-xyzabb/receivedBlockMetadata older than 1522602980000: 
18/04/01 20:16:26 INFO InputInfoTracker: remove old batch metadata: 1522602975000 ms
18/04/01 20:16:30 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-0 to offset 732.
18/04/01 20:16:30 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-3 to offset 0.
18/04/01 20:16:30 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-4 to offset 0.
18/04/01 20:16:30 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-1 to offset 0.
18/04/01 20:16:30 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-2 to offset 0.
18/04/01 20:16:30 INFO JobScheduler: Added jobs for time 1522602990000 ms
18/04/01 20:16:30 INFO JobGenerator: Checkpointing graph for time 1522602990000 ms
18/04/01 20:16:30 INFO DStreamGraph: Updating checkpoint data for time 1522602990000 ms
18/04/01 20:16:30 INFO DStreamGraph: Updated checkpoint data for time 1522602990000 ms
18/04/01 20:16:30 INFO CheckpointWriter: Saving checkpoint for time 1522602990000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602990000'
18/04/01 20:16:30 INFO JobScheduler: Starting job streaming job 1522602990000 ms.0 from job set of time 1522602990000 ms
18/04/01 20:16:30 INFO CheckpointWriter: Submitted checkpoint of time 1522602990000 ms to writer queue
18/04/01 20:16:30 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602965000.bk
18/04/01 20:16:30 INFO CheckpointWriter: Checkpoint for time 1522602990000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602990000', took 5586 bytes and 18 ms
18/04/01 20:16:30 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:16:30 INFO DAGScheduler: Got job 95 (print at RefereeStats.scala:67) with 1 output partitions
18/04/01 20:16:30 INFO DAGScheduler: Final stage: ResultStage 152 (print at RefereeStats.scala:67)
18/04/01 20:16:30 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:16:30 INFO DAGScheduler: Missing parents: List()
18/04/01 20:16:30 INFO DAGScheduler: Submitting ResultStage 152 (MapPartitionsRDD[134] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:16:30 INFO MemoryStore: Block broadcast_153 stored as values in memory (estimated size 3.0 KB, free 477.2 MB)
18/04/01 20:16:30 INFO MemoryStore: Block broadcast_153_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.2 MB)
18/04/01 20:16:30 INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:30 INFO SparkContext: Created broadcast 153 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 152 (MapPartitionsRDD[134] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0))
18/04/01 20:16:30 INFO TaskSchedulerImpl: Adding task set 152.0 with 1 tasks
18/04/01 20:16:30 INFO TaskSetManager: Starting task 0.0 in stage 152.0 (TID 494, localhost, executor driver, partition 0, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:30 INFO Executor: Running task 0.0 in stage 152.0 (TID 494)
18/04/01 20:16:30 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:30 INFO Executor: Finished task 0.0 in stage 152.0 (TID 494). 747 bytes result sent to driver
18/04/01 20:16:30 INFO TaskSetManager: Finished task 0.0 in stage 152.0 (TID 494) in 5 ms on localhost (executor driver) (1/1)
18/04/01 20:16:30 INFO TaskSchedulerImpl: Removed TaskSet 152.0, whose tasks have all completed, from pool 
18/04/01 20:16:30 INFO DAGScheduler: ResultStage 152 (print at RefereeStats.scala:67) finished in 0.013 s
18/04/01 20:16:30 INFO DAGScheduler: Job 95 finished: print at RefereeStats.scala:67, took 0.017414 s
18/04/01 20:16:30 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:16:30 INFO DAGScheduler: Got job 96 (print at RefereeStats.scala:67) with 4 output partitions
18/04/01 20:16:30 INFO DAGScheduler: Final stage: ResultStage 153 (print at RefereeStats.scala:67)
18/04/01 20:16:30 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:16:30 INFO DAGScheduler: Missing parents: List()
18/04/01 20:16:30 INFO DAGScheduler: Submitting ResultStage 153 (MapPartitionsRDD[134] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:16:30 INFO MemoryStore: Block broadcast_154 stored as values in memory (estimated size 3.0 KB, free 477.2 MB)
18/04/01 20:16:30 INFO MemoryStore: Block broadcast_154_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.2 MB)
18/04/01 20:16:30 INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:30 INFO SparkContext: Created broadcast 154 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:30 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 153 (MapPartitionsRDD[134] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
18/04/01 20:16:30 INFO TaskSchedulerImpl: Adding task set 153.0 with 4 tasks
18/04/01 20:16:30 INFO TaskSetManager: Starting task 0.0 in stage 153.0 (TID 495, localhost, executor driver, partition 1, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:30 INFO TaskSetManager: Starting task 1.0 in stage 153.0 (TID 496, localhost, executor driver, partition 2, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:30 INFO Executor: Running task 1.0 in stage 153.0 (TID 496)
18/04/01 20:16:30 INFO Executor: Running task 0.0 in stage 153.0 (TID 495)
18/04/01 20:16:30 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:30 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:30 INFO Executor: Finished task 0.0 in stage 153.0 (TID 495). 704 bytes result sent to driver
18/04/01 20:16:30 INFO Executor: Finished task 1.0 in stage 153.0 (TID 496). 704 bytes result sent to driver
18/04/01 20:16:30 INFO TaskSetManager: Starting task 2.0 in stage 153.0 (TID 497, localhost, executor driver, partition 3, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:30 INFO TaskSetManager: Finished task 0.0 in stage 153.0 (TID 495) in 8 ms on localhost (executor driver) (1/4)
18/04/01 20:16:30 INFO TaskSetManager: Finished task 1.0 in stage 153.0 (TID 496) in 8 ms on localhost (executor driver) (2/4)
18/04/01 20:16:30 INFO Executor: Running task 2.0 in stage 153.0 (TID 497)
18/04/01 20:16:30 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:30 INFO Executor: Finished task 2.0 in stage 153.0 (TID 497). 704 bytes result sent to driver
18/04/01 20:16:30 INFO TaskSetManager: Starting task 3.0 in stage 153.0 (TID 498, localhost, executor driver, partition 4, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:30 INFO Executor: Running task 3.0 in stage 153.0 (TID 498)
18/04/01 20:16:30 INFO TaskSetManager: Finished task 2.0 in stage 153.0 (TID 497) in 6 ms on localhost (executor driver) (3/4)
18/04/01 20:16:30 INFO KafkaRDD: Beginning offset 732 is the same as ending offset skipping clients-purchases-src-xxx 0
18/04/01 20:16:30 INFO Executor: Finished task 3.0 in stage 153.0 (TID 498). 704 bytes result sent to driver
18/04/01 20:16:30 INFO TaskSetManager: Finished task 3.0 in stage 153.0 (TID 498) in 4 ms on localhost (executor driver) (4/4)
18/04/01 20:16:30 INFO TaskSchedulerImpl: Removed TaskSet 153.0, whose tasks have all completed, from pool 
18/04/01 20:16:30 INFO DAGScheduler: ResultStage 153 (print at RefereeStats.scala:67) finished in 0.025 s
18/04/01 20:16:30 INFO DAGScheduler: Job 96 finished: print at RefereeStats.scala:67, took 0.029975 s
18/04/01 20:16:30 INFO JobScheduler: Finished job streaming job 1522602990000 ms.0 from job set of time 1522602990000 ms
18/04/01 20:16:30 INFO JobScheduler: Starting job streaming job 1522602990000 ms.1 from job set of time 1522602990000 ms
-------------------------------------------
Time: 1522602990000 ms
-------------------------------------------

18/04/01 20:16:30 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:71
18/04/01 20:16:30 INFO DAGScheduler: Registering RDD 134 (map at RefereeStats.scala:53)
18/04/01 20:16:30 INFO DAGScheduler: Got job 97 (foreachPartition at RefereeStats.scala:71) with 2 output partitions
18/04/01 20:16:30 INFO DAGScheduler: Final stage: ResultStage 155 (foreachPartition at RefereeStats.scala:71)
18/04/01 20:16:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 154)
18/04/01 20:16:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 154)
18/04/01 20:16:30 INFO DAGScheduler: Submitting ShuffleMapStage 154 (MapPartitionsRDD[134] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:16:30 INFO MemoryStore: Block broadcast_155 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:16:30 INFO MemoryStore: Block broadcast_155_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:16:30 INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:30 INFO SparkContext: Created broadcast 155 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:30 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 154 (MapPartitionsRDD[134] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:16:30 INFO TaskSchedulerImpl: Adding task set 154.0 with 5 tasks
18/04/01 20:16:30 INFO TaskSetManager: Starting task 0.0 in stage 154.0 (TID 499, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:30 INFO TaskSetManager: Starting task 1.0 in stage 154.0 (TID 500, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:30 INFO Executor: Running task 0.0 in stage 154.0 (TID 499)
18/04/01 20:16:30 INFO Executor: Running task 1.0 in stage 154.0 (TID 500)
18/04/01 20:16:30 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:30 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:30 INFO Executor: Finished task 0.0 in stage 154.0 (TID 499). 938 bytes result sent to driver
18/04/01 20:16:30 INFO Executor: Finished task 1.0 in stage 154.0 (TID 500). 938 bytes result sent to driver
18/04/01 20:16:30 INFO TaskSetManager: Starting task 2.0 in stage 154.0 (TID 501, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:30 INFO Executor: Running task 2.0 in stage 154.0 (TID 501)
18/04/01 20:16:30 INFO TaskSetManager: Finished task 0.0 in stage 154.0 (TID 499) in 7 ms on localhost (executor driver) (1/5)
18/04/01 20:16:30 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:30 INFO Executor: Finished task 2.0 in stage 154.0 (TID 501). 938 bytes result sent to driver
18/04/01 20:16:30 INFO TaskSetManager: Starting task 3.0 in stage 154.0 (TID 502, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:30 INFO Executor: Running task 3.0 in stage 154.0 (TID 502)
18/04/01 20:16:30 INFO TaskSetManager: Finished task 2.0 in stage 154.0 (TID 501) in 7 ms on localhost (executor driver) (2/5)
18/04/01 20:16:30 INFO TaskSetManager: Starting task 4.0 in stage 154.0 (TID 503, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:30 INFO Executor: Running task 4.0 in stage 154.0 (TID 503)
18/04/01 20:16:30 INFO TaskSetManager: Finished task 1.0 in stage 154.0 (TID 500) in 16 ms on localhost (executor driver) (3/5)
18/04/01 20:16:30 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:30 INFO KafkaRDD: Beginning offset 732 is the same as ending offset skipping clients-purchases-src-xxx 0
18/04/01 20:16:30 INFO Executor: Finished task 3.0 in stage 154.0 (TID 502). 938 bytes result sent to driver
18/04/01 20:16:30 INFO TaskSetManager: Finished task 3.0 in stage 154.0 (TID 502) in 13 ms on localhost (executor driver) (4/5)
18/04/01 20:16:30 INFO Executor: Finished task 4.0 in stage 154.0 (TID 503). 938 bytes result sent to driver
18/04/01 20:16:30 INFO TaskSetManager: Finished task 4.0 in stage 154.0 (TID 503) in 11 ms on localhost (executor driver) (5/5)
18/04/01 20:16:30 INFO TaskSchedulerImpl: Removed TaskSet 154.0, whose tasks have all completed, from pool 
18/04/01 20:16:30 INFO DAGScheduler: ShuffleMapStage 154 (map at RefereeStats.scala:53) finished in 0.050 s
18/04/01 20:16:30 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:16:30 INFO DAGScheduler: running: Set()
18/04/01 20:16:30 INFO DAGScheduler: waiting: Set(ResultStage 155)
18/04/01 20:16:30 INFO DAGScheduler: failed: Set()
18/04/01 20:16:30 INFO DAGScheduler: Submitting ResultStage 155 (ShuffledRDD[135] at reduceByKey at RefereeStats.scala:60), which has no missing parents
18/04/01 20:16:30 INFO MemoryStore: Block broadcast_156 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:16:30 INFO MemoryStore: Block broadcast_156_piece0 stored as bytes in memory (estimated size 1711.0 B, free 477.2 MB)
18/04/01 20:16:30 INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on 192.168.1.3:35449 (size: 1711.0 B, free: 477.3 MB)
18/04/01 20:16:30 INFO SparkContext: Created broadcast 156 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 155 (ShuffledRDD[135] at reduceByKey at RefereeStats.scala:60) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:16:30 INFO TaskSchedulerImpl: Adding task set 155.0 with 2 tasks
18/04/01 20:16:30 INFO TaskSetManager: Starting task 0.0 in stage 155.0 (TID 504, localhost, executor driver, partition 0, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:30 INFO TaskSetManager: Starting task 1.0 in stage 155.0 (TID 505, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:30 INFO Executor: Running task 1.0 in stage 155.0 (TID 505)
18/04/01 20:16:30 INFO Executor: Running task 0.0 in stage 155.0 (TID 504)
18/04/01 20:16:30 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:30 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:30 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:30 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:30 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:30 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:30 INFO KafkaProducer: [Producer clientId=producer-115] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:30 INFO Executor: Finished task 1.0 in stage 155.0 (TID 505). 1138 bytes result sent to driver
18/04/01 20:16:30 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:30 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:30 INFO TaskSetManager: Finished task 1.0 in stage 155.0 (TID 505) in 19 ms on localhost (executor driver) (1/2)
18/04/01 20:16:30 INFO KafkaProducer: [Producer clientId=producer-116] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:30 INFO Executor: Finished task 0.0 in stage 155.0 (TID 504). 1138 bytes result sent to driver
18/04/01 20:16:30 INFO TaskSetManager: Finished task 0.0 in stage 155.0 (TID 504) in 24 ms on localhost (executor driver) (2/2)
18/04/01 20:16:30 INFO TaskSchedulerImpl: Removed TaskSet 155.0, whose tasks have all completed, from pool 
18/04/01 20:16:30 INFO DAGScheduler: ResultStage 155 (foreachPartition at RefereeStats.scala:71) finished in 0.035 s
18/04/01 20:16:30 INFO DAGScheduler: Job 97 finished: foreachPartition at RefereeStats.scala:71, took 0.095352 s
18/04/01 20:16:30 INFO JobScheduler: Finished job streaming job 1522602990000 ms.1 from job set of time 1522602990000 ms
18/04/01 20:16:30 INFO JobScheduler: Starting job streaming job 1522602990000 ms.2 from job set of time 1522602990000 ms
18/04/01 20:16:30 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:89
18/04/01 20:16:30 INFO DAGScheduler: Registering RDD 136 (map at RefereeStats.scala:46)
18/04/01 20:16:30 INFO DAGScheduler: Got job 98 (foreachPartition at RefereeStats.scala:89) with 2 output partitions
18/04/01 20:16:30 INFO DAGScheduler: Final stage: ResultStage 157 (foreachPartition at RefereeStats.scala:89)
18/04/01 20:16:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 156)
18/04/01 20:16:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 156)
18/04/01 20:16:30 INFO DAGScheduler: Submitting ShuffleMapStage 156 (MapPartitionsRDD[136] at map at RefereeStats.scala:46), which has no missing parents
18/04/01 20:16:30 INFO MemoryStore: Block broadcast_157 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:16:30 INFO MemoryStore: Block broadcast_157_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:16:30 INFO BlockManagerInfo: Added broadcast_157_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:30 INFO SparkContext: Created broadcast 157 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:30 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 156 (MapPartitionsRDD[136] at map at RefereeStats.scala:46) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:16:30 INFO TaskSchedulerImpl: Adding task set 156.0 with 5 tasks
18/04/01 20:16:30 INFO TaskSetManager: Starting task 0.0 in stage 156.0 (TID 506, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:30 INFO TaskSetManager: Starting task 1.0 in stage 156.0 (TID 507, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:30 INFO Executor: Running task 0.0 in stage 156.0 (TID 506)
18/04/01 20:16:30 INFO Executor: Running task 1.0 in stage 156.0 (TID 507)
18/04/01 20:16:30 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:30 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:30 INFO Executor: Finished task 0.0 in stage 156.0 (TID 506). 938 bytes result sent to driver
18/04/01 20:16:30 INFO TaskSetManager: Starting task 2.0 in stage 156.0 (TID 508, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:30 INFO Executor: Finished task 1.0 in stage 156.0 (TID 507). 938 bytes result sent to driver
18/04/01 20:16:30 INFO TaskSetManager: Finished task 0.0 in stage 156.0 (TID 506) in 7 ms on localhost (executor driver) (1/5)
18/04/01 20:16:30 INFO Executor: Running task 2.0 in stage 156.0 (TID 508)
18/04/01 20:16:30 INFO TaskSetManager: Starting task 3.0 in stage 156.0 (TID 509, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:30 INFO TaskSetManager: Finished task 1.0 in stage 156.0 (TID 507) in 8 ms on localhost (executor driver) (2/5)
18/04/01 20:16:30 INFO Executor: Running task 3.0 in stage 156.0 (TID 509)
18/04/01 20:16:30 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:30 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:30 INFO Executor: Finished task 3.0 in stage 156.0 (TID 509). 938 bytes result sent to driver
18/04/01 20:16:30 INFO TaskSetManager: Starting task 4.0 in stage 156.0 (TID 510, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:30 INFO TaskSetManager: Finished task 3.0 in stage 156.0 (TID 509) in 9 ms on localhost (executor driver) (3/5)
18/04/01 20:16:30 INFO Executor: Running task 4.0 in stage 156.0 (TID 510)
18/04/01 20:16:30 INFO KafkaRDD: Beginning offset 732 is the same as ending offset skipping clients-purchases-src-xxx 0
18/04/01 20:16:30 INFO Executor: Finished task 4.0 in stage 156.0 (TID 510). 938 bytes result sent to driver
18/04/01 20:16:30 INFO TaskSetManager: Finished task 4.0 in stage 156.0 (TID 510) in 10 ms on localhost (executor driver) (4/5)
18/04/01 20:16:30 INFO Executor: Finished task 2.0 in stage 156.0 (TID 508). 981 bytes result sent to driver
18/04/01 20:16:30 INFO TaskSetManager: Finished task 2.0 in stage 156.0 (TID 508) in 25 ms on localhost (executor driver) (5/5)
18/04/01 20:16:30 INFO TaskSchedulerImpl: Removed TaskSet 156.0, whose tasks have all completed, from pool 
18/04/01 20:16:30 INFO DAGScheduler: ShuffleMapStage 156 (map at RefereeStats.scala:46) finished in 0.040 s
18/04/01 20:16:30 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:16:30 INFO DAGScheduler: running: Set()
18/04/01 20:16:30 INFO DAGScheduler: waiting: Set(ResultStage 157)
18/04/01 20:16:30 INFO DAGScheduler: failed: Set()
18/04/01 20:16:30 INFO DAGScheduler: Submitting ResultStage 157 (ShuffledRDD[137] at reduceByKey at RefereeStats.scala:51), which has no missing parents
18/04/01 20:16:30 INFO MemoryStore: Block broadcast_158 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:16:30 INFO MemoryStore: Block broadcast_158_piece0 stored as bytes in memory (estimated size 1709.0 B, free 477.2 MB)
18/04/01 20:16:30 INFO BlockManagerInfo: Added broadcast_158_piece0 in memory on 192.168.1.3:35449 (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:16:30 INFO SparkContext: Created broadcast 158 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 157 (ShuffledRDD[137] at reduceByKey at RefereeStats.scala:51) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:16:30 INFO TaskSchedulerImpl: Adding task set 157.0 with 2 tasks
18/04/01 20:16:30 INFO TaskSetManager: Starting task 0.0 in stage 157.0 (TID 511, localhost, executor driver, partition 0, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:30 INFO TaskSetManager: Starting task 1.0 in stage 157.0 (TID 512, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:30 INFO Executor: Running task 1.0 in stage 157.0 (TID 512)
18/04/01 20:16:30 INFO Executor: Running task 0.0 in stage 157.0 (TID 511)
18/04/01 20:16:30 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:30 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:30 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
18/04/01 20:16:30 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:30 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:30 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:30 INFO KafkaProducer: [Producer clientId=producer-117] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:30 INFO Executor: Finished task 0.0 in stage 157.0 (TID 511). 1138 bytes result sent to driver
18/04/01 20:16:30 INFO TaskSetManager: Finished task 0.0 in stage 157.0 (TID 511) in 27 ms on localhost (executor driver) (1/2)
18/04/01 20:16:30 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:30 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:30 INFO KafkaProducer: [Producer clientId=producer-118] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:30 INFO Executor: Finished task 1.0 in stage 157.0 (TID 512). 1138 bytes result sent to driver
18/04/01 20:16:30 INFO TaskSetManager: Finished task 1.0 in stage 157.0 (TID 512) in 47 ms on localhost (executor driver) (2/2)
18/04/01 20:16:30 INFO TaskSchedulerImpl: Removed TaskSet 157.0, whose tasks have all completed, from pool 
18/04/01 20:16:30 INFO DAGScheduler: ResultStage 157 (foreachPartition at RefereeStats.scala:89) finished in 0.076 s
18/04/01 20:16:30 INFO DAGScheduler: Job 98 finished: foreachPartition at RefereeStats.scala:89, took 0.127903 s
18/04/01 20:16:30 INFO JobScheduler: Finished job streaming job 1522602990000 ms.2 from job set of time 1522602990000 ms
18/04/01 20:16:30 INFO JobScheduler: Starting job streaming job 1522602990000 ms.3 from job set of time 1522602990000 ms
18/04/01 20:16:30 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:106
18/04/01 20:16:30 INFO DAGScheduler: Registering RDD 138 (map at RefereeStats.scala:39)
18/04/01 20:16:30 INFO DAGScheduler: Got job 99 (foreachPartition at RefereeStats.scala:106) with 2 output partitions
18/04/01 20:16:30 INFO DAGScheduler: Final stage: ResultStage 159 (foreachPartition at RefereeStats.scala:106)
18/04/01 20:16:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 158)
18/04/01 20:16:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 158)
18/04/01 20:16:30 INFO DAGScheduler: Submitting ShuffleMapStage 158 (MapPartitionsRDD[138] at map at RefereeStats.scala:39), which has no missing parents
18/04/01 20:16:30 INFO MemoryStore: Block broadcast_159 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:16:30 INFO MemoryStore: Block broadcast_159_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:16:30 INFO BlockManagerInfo: Added broadcast_159_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.2 MB)
18/04/01 20:16:30 INFO SparkContext: Created broadcast 159 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:30 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 158 (MapPartitionsRDD[138] at map at RefereeStats.scala:39) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:16:30 INFO TaskSchedulerImpl: Adding task set 158.0 with 5 tasks
18/04/01 20:16:30 INFO TaskSetManager: Starting task 0.0 in stage 158.0 (TID 513, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:30 INFO TaskSetManager: Starting task 1.0 in stage 158.0 (TID 514, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:30 INFO Executor: Running task 0.0 in stage 158.0 (TID 513)
18/04/01 20:16:30 INFO Executor: Running task 1.0 in stage 158.0 (TID 514)
18/04/01 20:16:30 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:30 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:30 INFO Executor: Finished task 0.0 in stage 158.0 (TID 513). 938 bytes result sent to driver
18/04/01 20:16:30 INFO Executor: Finished task 1.0 in stage 158.0 (TID 514). 938 bytes result sent to driver
18/04/01 20:16:30 INFO TaskSetManager: Starting task 2.0 in stage 158.0 (TID 515, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:30 INFO Executor: Running task 2.0 in stage 158.0 (TID 515)
18/04/01 20:16:30 INFO TaskSetManager: Finished task 0.0 in stage 158.0 (TID 513) in 17 ms on localhost (executor driver) (1/5)
18/04/01 20:16:30 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:30 INFO Executor: Finished task 2.0 in stage 158.0 (TID 515). 938 bytes result sent to driver
18/04/01 20:16:30 INFO TaskSetManager: Starting task 3.0 in stage 158.0 (TID 516, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:30 INFO Executor: Running task 3.0 in stage 158.0 (TID 516)
18/04/01 20:16:30 INFO TaskSetManager: Finished task 2.0 in stage 158.0 (TID 515) in 9 ms on localhost (executor driver) (2/5)
18/04/01 20:16:30 INFO TaskSetManager: Starting task 4.0 in stage 158.0 (TID 517, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:30 INFO TaskSetManager: Finished task 1.0 in stage 158.0 (TID 514) in 26 ms on localhost (executor driver) (3/5)
18/04/01 20:16:30 INFO Executor: Running task 4.0 in stage 158.0 (TID 517)
18/04/01 20:16:30 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:30 INFO Executor: Finished task 3.0 in stage 158.0 (TID 516). 981 bytes result sent to driver
18/04/01 20:16:30 INFO TaskSetManager: Finished task 3.0 in stage 158.0 (TID 516) in 8 ms on localhost (executor driver) (4/5)
18/04/01 20:16:30 INFO KafkaRDD: Beginning offset 732 is the same as ending offset skipping clients-purchases-src-xxx 0
18/04/01 20:16:30 INFO Executor: Finished task 4.0 in stage 158.0 (TID 517). 938 bytes result sent to driver
18/04/01 20:16:30 INFO TaskSetManager: Finished task 4.0 in stage 158.0 (TID 517) in 16 ms on localhost (executor driver) (5/5)
18/04/01 20:16:30 INFO TaskSchedulerImpl: Removed TaskSet 158.0, whose tasks have all completed, from pool 
18/04/01 20:16:30 INFO DAGScheduler: ShuffleMapStage 158 (map at RefereeStats.scala:39) finished in 0.053 s
18/04/01 20:16:30 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:16:30 INFO DAGScheduler: running: Set()
18/04/01 20:16:30 INFO DAGScheduler: waiting: Set(ResultStage 159)
18/04/01 20:16:30 INFO DAGScheduler: failed: Set()
18/04/01 20:16:30 INFO DAGScheduler: Submitting ResultStage 159 (ShuffledRDD[139] at reduceByKey at RefereeStats.scala:43), which has no missing parents
18/04/01 20:16:30 INFO MemoryStore: Block broadcast_160 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3697
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3879
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3852
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3599
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3661
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3839
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3601
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3792
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3667
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3582
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3577
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3860
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3644
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3688
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3726
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3567
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3838
18/04/01 20:16:30 INFO BlockManagerInfo: Removed broadcast_139_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3764
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3514
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3936
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3744
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3844
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3529
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3572
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3919
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3801
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3733
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3813
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3519
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3538
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3708
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3835
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3715
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3948
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3541
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3781
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3722
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3512
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3626
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3483
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3683
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3785
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3922
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3510
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3805
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3593
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3654
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3492
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3850
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3724
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3453
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3467
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3616
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3458
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3731
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3826
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3927
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3615
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3670
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3509
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3516
18/04/01 20:16:30 INFO MemoryStore: Block broadcast_160_piece0 stored as bytes in memory (estimated size 1704.0 B, free 477.2 MB)
18/04/01 20:16:30 INFO BlockManagerInfo: Added broadcast_160_piece0 in memory on 192.168.1.3:35449 (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:16:30 INFO BlockManagerInfo: Removed broadcast_151_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:30 INFO SparkContext: Created broadcast 160 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3647
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3707
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3757
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3664
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3858
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3740
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3882
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3465
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3456
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3580
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3909
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3836
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3772
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3797
18/04/01 20:16:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 159 (ShuffledRDD[139] at reduceByKey at RefereeStats.scala:43) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:16:30 INFO TaskSchedulerImpl: Adding task set 159.0 with 2 tasks
18/04/01 20:16:30 INFO TaskSetManager: Starting task 0.0 in stage 159.0 (TID 518, localhost, executor driver, partition 0, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:30 INFO BlockManagerInfo: Removed broadcast_141_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:30 INFO TaskSetManager: Starting task 1.0 in stage 159.0 (TID 519, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:30 INFO Executor: Running task 1.0 in stage 159.0 (TID 519)
18/04/01 20:16:30 INFO Executor: Running task 0.0 in stage 159.0 (TID 518)
18/04/01 20:16:30 INFO BlockManagerInfo: Removed broadcast_150_piece0 on 192.168.1.3:35449 in memory (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:16:30 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:30 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:30 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3765
18/04/01 20:16:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:16:30 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:30 INFO BlockManagerInfo: Removed broadcast_155_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3620
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3555
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3938
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3578
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3811
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3469
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3571
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3917
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3767
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3928
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3866
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3900
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3701
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3796
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3816
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3874
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3653
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3554
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3727
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3649
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3522
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3501
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3682
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3652
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3840
18/04/01 20:16:30 INFO BlockManagerInfo: Removed broadcast_158_piece0 on 192.168.1.3:35449 in memory (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3769
18/04/01 20:16:30 INFO ContextCleaner: Cleaned shuffle 52
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3749
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3841
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3937
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3913
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3546
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3823
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3617
18/04/01 20:16:30 INFO BlockManagerInfo: Removed broadcast_154_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:30 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:30 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:30 INFO KafkaProducer: [Producer clientId=producer-120] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3725
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3618
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3680
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3696
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3548
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3759
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3935
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3631
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3685
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3675
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3476
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3752
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3709
18/04/01 20:16:30 INFO BlockManagerInfo: Removed broadcast_144_piece0 on 192.168.1.3:35449 in memory (size: 1711.0 B, free: 477.3 MB)
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3702
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3736
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3470
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3562
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3666
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3621
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3581
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3574
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3735
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3754
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3594
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3607
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3539
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3793
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3934
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3837
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3931
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3665
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3829
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3633
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3741
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3699
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3786
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3872
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3794
18/04/01 20:16:30 INFO Executor: Finished task 0.0 in stage 159.0 (TID 518). 1138 bytes result sent to driver
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3487
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3778
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3496
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3830
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3585
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3669
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3763
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3926
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3897
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3589
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3640
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3570
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3851
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3887
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3452
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3662
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3719
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3834
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3756
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3515
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3540
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3751
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3774
18/04/01 20:16:30 INFO TaskSetManager: Finished task 0.0 in stage 159.0 (TID 518) in 23 ms on localhost (executor driver) (1/2)
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3642
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3789
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3884
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3679
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3475
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3921
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3886
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3939
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3916
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3673
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3466
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3646
18/04/01 20:16:30 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:30 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:30 INFO BlockManagerInfo: Removed broadcast_147_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:30 INFO KafkaProducer: [Producer clientId=producer-119] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3655
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3745
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3559
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3779
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3566
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3780
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3876
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3536
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3525
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3691
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3575
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3549
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3802
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3855
18/04/01 20:16:30 INFO ContextCleaner: Cleaned shuffle 50
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3638
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3490
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3545
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3596
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3542
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3671
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3527
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3933
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3713
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3556
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3532
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3552
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3806
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3910
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3853
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3808
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3668
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3705
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3583
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3908
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3634
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3464
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3573
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3533
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3799
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3641
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3472
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3645
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3883
18/04/01 20:16:30 INFO Executor: Finished task 1.0 in stage 159.0 (TID 519). 1138 bytes result sent to driver
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3565
18/04/01 20:16:30 INFO TaskSetManager: Finished task 1.0 in stage 159.0 (TID 519) in 31 ms on localhost (executor driver) (2/2)
18/04/01 20:16:30 INFO TaskSchedulerImpl: Removed TaskSet 159.0, whose tasks have all completed, from pool 
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3873
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3868
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3704
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3869
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3489
18/04/01 20:16:30 INFO DAGScheduler: ResultStage 159 (foreachPartition at RefereeStats.scala:106) finished in 0.069 s
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3810
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3564
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3761
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3561
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3523
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3689
18/04/01 20:16:30 INFO DAGScheduler: Job 99 finished: foreachPartition at RefereeStats.scala:106, took 0.131109 s
18/04/01 20:16:30 INFO JobScheduler: Finished job streaming job 1522602990000 ms.3 from job set of time 1522602990000 ms
18/04/01 20:16:30 INFO JobScheduler: Total delay: 0.497 s for time 1522602990000 ms (execution: 0.467 s)
18/04/01 20:16:30 INFO MapPartitionsRDD: Removing RDD 127 from persistence list
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3517
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3686
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3611
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3847
18/04/01 20:16:30 INFO KafkaRDD: Removing RDD 126 from persistence list
18/04/01 20:16:30 INFO BlockManager: Removing RDD 127
18/04/01 20:16:30 INFO ShuffledRDD: Removing RDD 128 from persistence list
18/04/01 20:16:30 INFO BlockManagerInfo: Removed broadcast_146_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:30 INFO BlockManager: Removing RDD 126
18/04/01 20:16:30 INFO BlockManager: Removing RDD 128
18/04/01 20:16:30 INFO ShuffledRDD: Removing RDD 130 from persistence list
18/04/01 20:16:30 INFO BlockManager: Removing RDD 130
18/04/01 20:16:30 INFO MapPartitionsRDD: Removing RDD 129 from persistence list
18/04/01 20:16:30 INFO BlockManager: Removing RDD 129
18/04/01 20:16:30 INFO ShuffledRDD: Removing RDD 132 from persistence list
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3758
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3500
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3524
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3871
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3480
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3775
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3651
18/04/01 20:16:30 INFO BlockManager: Removing RDD 132
18/04/01 20:16:30 INFO MapPartitionsRDD: Removing RDD 131 from persistence list
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3613
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3809
18/04/01 20:16:30 INFO BlockManager: Removing RDD 131
18/04/01 20:16:30 INFO JobGenerator: Checkpointing graph for time 1522602990000 ms
18/04/01 20:16:30 INFO DStreamGraph: Updating checkpoint data for time 1522602990000 ms
18/04/01 20:16:30 INFO DStreamGraph: Updated checkpoint data for time 1522602990000 ms
18/04/01 20:16:30 INFO CheckpointWriter: Submitted checkpoint of time 1522602990000 ms to writer queue
18/04/01 20:16:30 INFO CheckpointWriter: Saving checkpoint for time 1522602990000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602990000'
18/04/01 20:16:30 INFO BlockManagerInfo: Removed broadcast_156_piece0 on 192.168.1.3:35449 in memory (size: 1711.0 B, free: 477.3 MB)
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3766
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3842
18/04/01 20:16:30 INFO ContextCleaner: Cleaned shuffle 49
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3494
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3504
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3576
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3894
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3947
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3485
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3825
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3755
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3460
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3531
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3750
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3488
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3846
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3798
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3880
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3468
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3687
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3718
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3923
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3643
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3714
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3602
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3478
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3940
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3491
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3477
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3930
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3723
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3507
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3482
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3535
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3890
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3547
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3511
18/04/01 20:16:30 INFO BlockManagerInfo: Removed broadcast_152_piece0 on 192.168.1.3:35449 in memory (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3898
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3721
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3920
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3502
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3543
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3814
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3861
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3462
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3518
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3614
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3732
18/04/01 20:16:30 INFO BlockManagerInfo: Removed broadcast_142_piece0 on 192.168.1.3:35449 in memory (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3672
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3902
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3658
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3474
18/04/01 20:16:30 INFO BlockManagerInfo: Removed broadcast_157_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:30 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602965000
18/04/01 20:16:30 INFO CheckpointWriter: Checkpoint for time 1522602990000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602990000', took 5535 bytes and 24 ms
18/04/01 20:16:30 INFO DStreamGraph: Clearing checkpoint data for time 1522602990000 ms
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3450
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3579
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3479
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3912
18/04/01 20:16:30 INFO DStreamGraph: Cleared checkpoint data for time 1522602990000 ms
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3903
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3824
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3659
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3660
18/04/01 20:16:30 INFO ReceivedBlockTracker: Deleting batches: 
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3557
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3636
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3915
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3787
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3768
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3526
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3865
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3497
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3563
18/04/01 20:16:30 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/tmp/refs-xyzabb/receivedBlockMetadata older than 1522602985000: 
18/04/01 20:16:30 INFO InputInfoTracker: remove old batch metadata: 1522602980000 ms
18/04/01 20:16:30 INFO BlockManagerInfo: Removed broadcast_143_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3904
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3694
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3877
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3544
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3625
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3600
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3746
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3856
18/04/01 20:16:30 INFO ContextCleaner: Cleaned shuffle 53
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3473
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3737
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3790
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3742
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3663
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3812
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3738
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3771
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3817
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3918
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3463
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3804
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3944
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3730
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3635
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3828
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3907
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3551
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3911
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3720
18/04/01 20:16:30 INFO ContextCleaner: Cleaned shuffle 51
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3677
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3508
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3863
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3760
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3892
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3591
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3558
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3587
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3622
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3627
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3657
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3612
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3728
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3862
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3867
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3592
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3684
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3457
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3639
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3857
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3609
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3595
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3455
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3803
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3827
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3459
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3843
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3505
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3945
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3624
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3929
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3495
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3606
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3753
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3885
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3586
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3891
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3777
18/04/01 20:16:30 INFO BlockManagerInfo: Removed broadcast_153_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3493
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3896
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3499
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3471
18/04/01 20:16:30 INFO ContextCleaner: Cleaned shuffle 48
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3550
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3681
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3941
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3762
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3822
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3603
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3889
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3528
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3899
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3784
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3629
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3486
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3854
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3782
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3905
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3831
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3832
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3783
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3893
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3820
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3711
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3703
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3628
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3717
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3895
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3788
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3604
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3692
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3623
18/04/01 20:16:30 INFO BlockManagerInfo: Removed broadcast_148_piece0 on 192.168.1.3:35449 in memory (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3888
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3818
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3875
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3598
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3864
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3859
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3906
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3845
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3656
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3590
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3506
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3748
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3569
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3637
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3946
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3743
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3747
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3734
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3878
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3773
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3650
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3791
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3821
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3800
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3849
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3914
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3795
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3943
18/04/01 20:16:30 INFO BlockManagerInfo: Removed broadcast_149_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3608
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3560
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3648
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3481
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3949
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3690
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3537
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3630
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3568
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3451
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3807
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3530
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3619
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3924
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3833
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3848
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3597
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3484
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3901
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3503
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3770
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3706
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3461
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3870
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3513
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3605
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3698
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3520
18/04/01 20:16:30 INFO BlockManagerInfo: Removed broadcast_145_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3729
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3716
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3700
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3712
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3534
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3498
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3881
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3776
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3676
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3674
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3584
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3588
18/04/01 20:16:30 INFO BlockManagerInfo: Removed broadcast_140_piece0 on 192.168.1.3:35449 in memory (size: 1705.0 B, free: 477.3 MB)
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3678
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3553
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3925
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3739
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3632
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3610
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3695
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3815
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3819
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3932
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3454
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3942
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3521
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3693
18/04/01 20:16:30 INFO ContextCleaner: Cleaned accumulator 3710
18/04/01 20:16:35 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-0 to offset 732.
18/04/01 20:16:35 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-3 to offset 0.
18/04/01 20:16:35 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-4 to offset 0.
18/04/01 20:16:35 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-1 to offset 0.
18/04/01 20:16:35 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-2 to offset 0.
18/04/01 20:16:35 INFO JobScheduler: Added jobs for time 1522602995000 ms
18/04/01 20:16:35 INFO JobGenerator: Checkpointing graph for time 1522602995000 ms
18/04/01 20:16:35 INFO DStreamGraph: Updating checkpoint data for time 1522602995000 ms
18/04/01 20:16:35 INFO JobScheduler: Starting job streaming job 1522602995000 ms.0 from job set of time 1522602995000 ms
18/04/01 20:16:35 INFO DStreamGraph: Updated checkpoint data for time 1522602995000 ms
18/04/01 20:16:35 INFO CheckpointWriter: Submitted checkpoint of time 1522602995000 ms to writer queue
18/04/01 20:16:35 INFO CheckpointWriter: Saving checkpoint for time 1522602995000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602995000'
18/04/01 20:16:35 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:16:35 INFO DAGScheduler: Got job 100 (print at RefereeStats.scala:67) with 1 output partitions
18/04/01 20:16:35 INFO DAGScheduler: Final stage: ResultStage 160 (print at RefereeStats.scala:67)
18/04/01 20:16:35 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:16:35 INFO DAGScheduler: Missing parents: List()
18/04/01 20:16:35 INFO DAGScheduler: Submitting ResultStage 160 (MapPartitionsRDD[141] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:16:35 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602970000.bk
18/04/01 20:16:35 INFO CheckpointWriter: Checkpoint for time 1522602995000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602995000', took 5583 bytes and 17 ms
18/04/01 20:16:35 INFO MemoryStore: Block broadcast_161 stored as values in memory (estimated size 3.0 KB, free 477.3 MB)
18/04/01 20:16:35 INFO MemoryStore: Block broadcast_161_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.3 MB)
18/04/01 20:16:35 INFO BlockManagerInfo: Added broadcast_161_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:35 INFO SparkContext: Created broadcast 161 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 160 (MapPartitionsRDD[141] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0))
18/04/01 20:16:35 INFO TaskSchedulerImpl: Adding task set 160.0 with 1 tasks
18/04/01 20:16:35 INFO TaskSetManager: Starting task 0.0 in stage 160.0 (TID 520, localhost, executor driver, partition 0, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:35 INFO Executor: Running task 0.0 in stage 160.0 (TID 520)
18/04/01 20:16:35 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:35 INFO Executor: Finished task 0.0 in stage 160.0 (TID 520). 704 bytes result sent to driver
18/04/01 20:16:35 INFO TaskSetManager: Finished task 0.0 in stage 160.0 (TID 520) in 4 ms on localhost (executor driver) (1/1)
18/04/01 20:16:35 INFO TaskSchedulerImpl: Removed TaskSet 160.0, whose tasks have all completed, from pool 
18/04/01 20:16:35 INFO DAGScheduler: ResultStage 160 (print at RefereeStats.scala:67) finished in 0.012 s
18/04/01 20:16:35 INFO DAGScheduler: Job 100 finished: print at RefereeStats.scala:67, took 0.015715 s
18/04/01 20:16:35 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:16:35 INFO DAGScheduler: Got job 101 (print at RefereeStats.scala:67) with 4 output partitions
18/04/01 20:16:35 INFO DAGScheduler: Final stage: ResultStage 161 (print at RefereeStats.scala:67)
18/04/01 20:16:35 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:16:35 INFO DAGScheduler: Missing parents: List()
18/04/01 20:16:35 INFO DAGScheduler: Submitting ResultStage 161 (MapPartitionsRDD[141] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:16:35 INFO MemoryStore: Block broadcast_162 stored as values in memory (estimated size 3.0 KB, free 477.3 MB)
18/04/01 20:16:35 INFO MemoryStore: Block broadcast_162_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.3 MB)
18/04/01 20:16:35 INFO BlockManagerInfo: Added broadcast_162_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:35 INFO SparkContext: Created broadcast 162 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:35 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 161 (MapPartitionsRDD[141] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
18/04/01 20:16:35 INFO TaskSchedulerImpl: Adding task set 161.0 with 4 tasks
18/04/01 20:16:35 INFO TaskSetManager: Starting task 0.0 in stage 161.0 (TID 521, localhost, executor driver, partition 1, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:35 INFO TaskSetManager: Starting task 1.0 in stage 161.0 (TID 522, localhost, executor driver, partition 2, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:35 INFO Executor: Running task 1.0 in stage 161.0 (TID 522)
18/04/01 20:16:35 INFO Executor: Running task 0.0 in stage 161.0 (TID 521)
18/04/01 20:16:35 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:35 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:35 INFO Executor: Finished task 0.0 in stage 161.0 (TID 521). 704 bytes result sent to driver
18/04/01 20:16:35 INFO Executor: Finished task 1.0 in stage 161.0 (TID 522). 704 bytes result sent to driver
18/04/01 20:16:35 INFO TaskSetManager: Starting task 2.0 in stage 161.0 (TID 523, localhost, executor driver, partition 3, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:35 INFO TaskSetManager: Starting task 3.0 in stage 161.0 (TID 524, localhost, executor driver, partition 4, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:35 INFO Executor: Running task 2.0 in stage 161.0 (TID 523)
18/04/01 20:16:35 INFO Executor: Running task 3.0 in stage 161.0 (TID 524)
18/04/01 20:16:35 INFO TaskSetManager: Finished task 0.0 in stage 161.0 (TID 521) in 5 ms on localhost (executor driver) (1/4)
18/04/01 20:16:35 INFO TaskSetManager: Finished task 1.0 in stage 161.0 (TID 522) in 6 ms on localhost (executor driver) (2/4)
18/04/01 20:16:35 INFO KafkaRDD: Beginning offset 732 is the same as ending offset skipping clients-purchases-src-xxx 0
18/04/01 20:16:35 INFO Executor: Finished task 3.0 in stage 161.0 (TID 524). 704 bytes result sent to driver
18/04/01 20:16:35 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:35 INFO TaskSetManager: Finished task 3.0 in stage 161.0 (TID 524) in 3 ms on localhost (executor driver) (3/4)
18/04/01 20:16:35 INFO Executor: Finished task 2.0 in stage 161.0 (TID 523). 704 bytes result sent to driver
18/04/01 20:16:35 INFO TaskSetManager: Finished task 2.0 in stage 161.0 (TID 523) in 5 ms on localhost (executor driver) (4/4)
18/04/01 20:16:35 INFO TaskSchedulerImpl: Removed TaskSet 161.0, whose tasks have all completed, from pool 
18/04/01 20:16:35 INFO DAGScheduler: ResultStage 161 (print at RefereeStats.scala:67) finished in 0.018 s
18/04/01 20:16:35 INFO DAGScheduler: Job 101 finished: print at RefereeStats.scala:67, took 0.020407 s
18/04/01 20:16:35 INFO JobScheduler: Finished job streaming job 1522602995000 ms.0 from job set of time 1522602995000 ms
18/04/01 20:16:35 INFO JobScheduler: Starting job streaming job 1522602995000 ms.1 from job set of time 1522602995000 ms
-------------------------------------------
Time: 1522602995000 ms
-------------------------------------------

18/04/01 20:16:35 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:71
18/04/01 20:16:35 INFO DAGScheduler: Registering RDD 141 (map at RefereeStats.scala:53)
18/04/01 20:16:35 INFO DAGScheduler: Got job 102 (foreachPartition at RefereeStats.scala:71) with 2 output partitions
18/04/01 20:16:35 INFO DAGScheduler: Final stage: ResultStage 163 (foreachPartition at RefereeStats.scala:71)
18/04/01 20:16:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 162)
18/04/01 20:16:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 162)
18/04/01 20:16:35 INFO DAGScheduler: Submitting ShuffleMapStage 162 (MapPartitionsRDD[141] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:16:35 INFO MemoryStore: Block broadcast_163 stored as values in memory (estimated size 3.9 KB, free 477.3 MB)
18/04/01 20:16:35 INFO MemoryStore: Block broadcast_163_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.3 MB)
18/04/01 20:16:35 INFO BlockManagerInfo: Added broadcast_163_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:35 INFO SparkContext: Created broadcast 163 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:35 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 162 (MapPartitionsRDD[141] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:16:35 INFO TaskSchedulerImpl: Adding task set 162.0 with 5 tasks
18/04/01 20:16:35 INFO TaskSetManager: Starting task 0.0 in stage 162.0 (TID 525, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:35 INFO TaskSetManager: Starting task 1.0 in stage 162.0 (TID 526, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:35 INFO Executor: Running task 0.0 in stage 162.0 (TID 525)
18/04/01 20:16:35 INFO Executor: Running task 1.0 in stage 162.0 (TID 526)
18/04/01 20:16:35 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:35 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:35 INFO Executor: Finished task 1.0 in stage 162.0 (TID 526). 938 bytes result sent to driver
18/04/01 20:16:35 INFO Executor: Finished task 0.0 in stage 162.0 (TID 525). 938 bytes result sent to driver
18/04/01 20:16:35 INFO TaskSetManager: Starting task 2.0 in stage 162.0 (TID 527, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:35 INFO Executor: Running task 2.0 in stage 162.0 (TID 527)
18/04/01 20:16:35 INFO TaskSetManager: Starting task 3.0 in stage 162.0 (TID 528, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:35 INFO TaskSetManager: Finished task 0.0 in stage 162.0 (TID 525) in 8 ms on localhost (executor driver) (1/5)
18/04/01 20:16:35 INFO Executor: Running task 3.0 in stage 162.0 (TID 528)
18/04/01 20:16:35 INFO TaskSetManager: Finished task 1.0 in stage 162.0 (TID 526) in 9 ms on localhost (executor driver) (2/5)
18/04/01 20:16:35 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:35 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:35 INFO Executor: Finished task 2.0 in stage 162.0 (TID 527). 938 bytes result sent to driver
18/04/01 20:16:35 INFO TaskSetManager: Starting task 4.0 in stage 162.0 (TID 529, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:35 INFO Executor: Finished task 3.0 in stage 162.0 (TID 528). 938 bytes result sent to driver
18/04/01 20:16:35 INFO TaskSetManager: Finished task 2.0 in stage 162.0 (TID 527) in 6 ms on localhost (executor driver) (3/5)
18/04/01 20:16:35 INFO TaskSetManager: Finished task 3.0 in stage 162.0 (TID 528) in 6 ms on localhost (executor driver) (4/5)
18/04/01 20:16:35 INFO Executor: Running task 4.0 in stage 162.0 (TID 529)
18/04/01 20:16:35 INFO KafkaRDD: Beginning offset 732 is the same as ending offset skipping clients-purchases-src-xxx 0
18/04/01 20:16:35 INFO Executor: Finished task 4.0 in stage 162.0 (TID 529). 938 bytes result sent to driver
18/04/01 20:16:35 INFO TaskSetManager: Finished task 4.0 in stage 162.0 (TID 529) in 6 ms on localhost (executor driver) (5/5)
18/04/01 20:16:35 INFO TaskSchedulerImpl: Removed TaskSet 162.0, whose tasks have all completed, from pool 
18/04/01 20:16:35 INFO DAGScheduler: ShuffleMapStage 162 (map at RefereeStats.scala:53) finished in 0.026 s
18/04/01 20:16:35 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:16:35 INFO DAGScheduler: running: Set()
18/04/01 20:16:35 INFO DAGScheduler: waiting: Set(ResultStage 163)
18/04/01 20:16:35 INFO DAGScheduler: failed: Set()
18/04/01 20:16:35 INFO DAGScheduler: Submitting ResultStage 163 (ShuffledRDD[142] at reduceByKey at RefereeStats.scala:60), which has no missing parents
18/04/01 20:16:35 INFO MemoryStore: Block broadcast_164 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:16:35 INFO MemoryStore: Block broadcast_164_piece0 stored as bytes in memory (estimated size 1706.0 B, free 477.2 MB)
18/04/01 20:16:35 INFO BlockManagerInfo: Added broadcast_164_piece0 in memory on 192.168.1.3:35449 (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:16:35 INFO SparkContext: Created broadcast 164 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 163 (ShuffledRDD[142] at reduceByKey at RefereeStats.scala:60) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:16:35 INFO TaskSchedulerImpl: Adding task set 163.0 with 2 tasks
18/04/01 20:16:35 INFO TaskSetManager: Starting task 0.0 in stage 163.0 (TID 530, localhost, executor driver, partition 0, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:35 INFO TaskSetManager: Starting task 1.0 in stage 163.0 (TID 531, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:35 INFO Executor: Running task 0.0 in stage 163.0 (TID 530)
18/04/01 20:16:35 INFO Executor: Running task 1.0 in stage 163.0 (TID 531)
18/04/01 20:16:35 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:35 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:35 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:35 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:35 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:35 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:35 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:35 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:35 INFO KafkaProducer: [Producer clientId=producer-122] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:35 INFO KafkaProducer: [Producer clientId=producer-121] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:35 INFO Executor: Finished task 0.0 in stage 163.0 (TID 530). 1138 bytes result sent to driver
18/04/01 20:16:35 INFO Executor: Finished task 1.0 in stage 163.0 (TID 531). 1138 bytes result sent to driver
18/04/01 20:16:35 INFO TaskSetManager: Finished task 0.0 in stage 163.0 (TID 530) in 14 ms on localhost (executor driver) (1/2)
18/04/01 20:16:35 INFO TaskSetManager: Finished task 1.0 in stage 163.0 (TID 531) in 14 ms on localhost (executor driver) (2/2)
18/04/01 20:16:35 INFO TaskSchedulerImpl: Removed TaskSet 163.0, whose tasks have all completed, from pool 
18/04/01 20:16:35 INFO DAGScheduler: ResultStage 163 (foreachPartition at RefereeStats.scala:71) finished in 0.022 s
18/04/01 20:16:35 INFO DAGScheduler: Job 102 finished: foreachPartition at RefereeStats.scala:71, took 0.053056 s
18/04/01 20:16:35 INFO JobScheduler: Finished job streaming job 1522602995000 ms.1 from job set of time 1522602995000 ms
18/04/01 20:16:35 INFO JobScheduler: Starting job streaming job 1522602995000 ms.2 from job set of time 1522602995000 ms
18/04/01 20:16:35 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:89
18/04/01 20:16:35 INFO DAGScheduler: Registering RDD 143 (map at RefereeStats.scala:46)
18/04/01 20:16:35 INFO DAGScheduler: Got job 103 (foreachPartition at RefereeStats.scala:89) with 2 output partitions
18/04/01 20:16:35 INFO DAGScheduler: Final stage: ResultStage 165 (foreachPartition at RefereeStats.scala:89)
18/04/01 20:16:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 164)
18/04/01 20:16:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 164)
18/04/01 20:16:35 INFO DAGScheduler: Submitting ShuffleMapStage 164 (MapPartitionsRDD[143] at map at RefereeStats.scala:46), which has no missing parents
18/04/01 20:16:35 INFO MemoryStore: Block broadcast_165 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:16:35 INFO MemoryStore: Block broadcast_165_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:16:35 INFO BlockManagerInfo: Added broadcast_165_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:35 INFO SparkContext: Created broadcast 165 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:35 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 164 (MapPartitionsRDD[143] at map at RefereeStats.scala:46) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:16:35 INFO TaskSchedulerImpl: Adding task set 164.0 with 5 tasks
18/04/01 20:16:35 INFO TaskSetManager: Starting task 0.0 in stage 164.0 (TID 532, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:35 INFO TaskSetManager: Starting task 1.0 in stage 164.0 (TID 533, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:35 INFO Executor: Running task 0.0 in stage 164.0 (TID 532)
18/04/01 20:16:35 INFO Executor: Running task 1.0 in stage 164.0 (TID 533)
18/04/01 20:16:35 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:35 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:35 INFO Executor: Finished task 0.0 in stage 164.0 (TID 532). 938 bytes result sent to driver
18/04/01 20:16:35 INFO Executor: Finished task 1.0 in stage 164.0 (TID 533). 938 bytes result sent to driver
18/04/01 20:16:35 INFO TaskSetManager: Starting task 2.0 in stage 164.0 (TID 534, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:35 INFO Executor: Running task 2.0 in stage 164.0 (TID 534)
18/04/01 20:16:35 INFO TaskSetManager: Starting task 3.0 in stage 164.0 (TID 535, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:35 INFO TaskSetManager: Finished task 1.0 in stage 164.0 (TID 533) in 6 ms on localhost (executor driver) (1/5)
18/04/01 20:16:35 INFO Executor: Running task 3.0 in stage 164.0 (TID 535)
18/04/01 20:16:35 INFO TaskSetManager: Finished task 0.0 in stage 164.0 (TID 532) in 6 ms on localhost (executor driver) (2/5)
18/04/01 20:16:35 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:35 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:35 INFO Executor: Finished task 2.0 in stage 164.0 (TID 534). 938 bytes result sent to driver
18/04/01 20:16:35 INFO Executor: Finished task 3.0 in stage 164.0 (TID 535). 938 bytes result sent to driver
18/04/01 20:16:35 INFO TaskSetManager: Starting task 4.0 in stage 164.0 (TID 536, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:35 INFO Executor: Running task 4.0 in stage 164.0 (TID 536)
18/04/01 20:16:35 INFO TaskSetManager: Finished task 2.0 in stage 164.0 (TID 534) in 5 ms on localhost (executor driver) (3/5)
18/04/01 20:16:35 INFO TaskSetManager: Finished task 3.0 in stage 164.0 (TID 535) in 6 ms on localhost (executor driver) (4/5)
18/04/01 20:16:35 INFO KafkaRDD: Beginning offset 732 is the same as ending offset skipping clients-purchases-src-xxx 0
18/04/01 20:16:35 INFO Executor: Finished task 4.0 in stage 164.0 (TID 536). 938 bytes result sent to driver
18/04/01 20:16:35 INFO TaskSetManager: Finished task 4.0 in stage 164.0 (TID 536) in 6 ms on localhost (executor driver) (5/5)
18/04/01 20:16:35 INFO TaskSchedulerImpl: Removed TaskSet 164.0, whose tasks have all completed, from pool 
18/04/01 20:16:35 INFO DAGScheduler: ShuffleMapStage 164 (map at RefereeStats.scala:46) finished in 0.024 s
18/04/01 20:16:35 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:16:35 INFO DAGScheduler: running: Set()
18/04/01 20:16:35 INFO DAGScheduler: waiting: Set(ResultStage 165)
18/04/01 20:16:35 INFO DAGScheduler: failed: Set()
18/04/01 20:16:35 INFO DAGScheduler: Submitting ResultStage 165 (ShuffledRDD[144] at reduceByKey at RefereeStats.scala:51), which has no missing parents
18/04/01 20:16:35 INFO MemoryStore: Block broadcast_166 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:16:35 INFO MemoryStore: Block broadcast_166_piece0 stored as bytes in memory (estimated size 1709.0 B, free 477.2 MB)
18/04/01 20:16:35 INFO BlockManagerInfo: Added broadcast_166_piece0 in memory on 192.168.1.3:35449 (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:16:35 INFO SparkContext: Created broadcast 166 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 165 (ShuffledRDD[144] at reduceByKey at RefereeStats.scala:51) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:16:35 INFO TaskSchedulerImpl: Adding task set 165.0 with 2 tasks
18/04/01 20:16:35 INFO TaskSetManager: Starting task 0.0 in stage 165.0 (TID 537, localhost, executor driver, partition 0, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:35 INFO TaskSetManager: Starting task 1.0 in stage 165.0 (TID 538, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:35 INFO Executor: Running task 0.0 in stage 165.0 (TID 537)
18/04/01 20:16:35 INFO Executor: Running task 1.0 in stage 165.0 (TID 538)
18/04/01 20:16:35 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:35 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:35 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:35 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:35 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:35 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:35 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:35 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:35 INFO KafkaProducer: [Producer clientId=producer-123] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:35 INFO KafkaProducer: [Producer clientId=producer-124] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:35 INFO Executor: Finished task 1.0 in stage 165.0 (TID 538). 1138 bytes result sent to driver
18/04/01 20:16:35 INFO TaskSetManager: Finished task 1.0 in stage 165.0 (TID 538) in 19 ms on localhost (executor driver) (1/2)
18/04/01 20:16:35 INFO Executor: Finished task 0.0 in stage 165.0 (TID 537). 1138 bytes result sent to driver
18/04/01 20:16:35 INFO TaskSetManager: Finished task 0.0 in stage 165.0 (TID 537) in 27 ms on localhost (executor driver) (2/2)
18/04/01 20:16:35 INFO TaskSchedulerImpl: Removed TaskSet 165.0, whose tasks have all completed, from pool 
18/04/01 20:16:35 INFO DAGScheduler: ResultStage 165 (foreachPartition at RefereeStats.scala:89) finished in 0.036 s
18/04/01 20:16:35 INFO DAGScheduler: Job 103 finished: foreachPartition at RefereeStats.scala:89, took 0.065282 s
18/04/01 20:16:35 INFO JobScheduler: Finished job streaming job 1522602995000 ms.2 from job set of time 1522602995000 ms
18/04/01 20:16:35 INFO JobScheduler: Starting job streaming job 1522602995000 ms.3 from job set of time 1522602995000 ms
18/04/01 20:16:35 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:106
18/04/01 20:16:35 INFO DAGScheduler: Registering RDD 145 (map at RefereeStats.scala:39)
18/04/01 20:16:35 INFO DAGScheduler: Got job 104 (foreachPartition at RefereeStats.scala:106) with 2 output partitions
18/04/01 20:16:35 INFO DAGScheduler: Final stage: ResultStage 167 (foreachPartition at RefereeStats.scala:106)
18/04/01 20:16:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 166)
18/04/01 20:16:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 166)
18/04/01 20:16:35 INFO DAGScheduler: Submitting ShuffleMapStage 166 (MapPartitionsRDD[145] at map at RefereeStats.scala:39), which has no missing parents
18/04/01 20:16:35 INFO MemoryStore: Block broadcast_167 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:16:35 INFO MemoryStore: Block broadcast_167_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:16:35 INFO BlockManagerInfo: Added broadcast_167_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:35 INFO SparkContext: Created broadcast 167 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:35 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 166 (MapPartitionsRDD[145] at map at RefereeStats.scala:39) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:16:35 INFO TaskSchedulerImpl: Adding task set 166.0 with 5 tasks
18/04/01 20:16:35 INFO TaskSetManager: Starting task 0.0 in stage 166.0 (TID 539, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:35 INFO TaskSetManager: Starting task 1.0 in stage 166.0 (TID 540, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:35 INFO Executor: Running task 0.0 in stage 166.0 (TID 539)
18/04/01 20:16:35 INFO Executor: Running task 1.0 in stage 166.0 (TID 540)
18/04/01 20:16:35 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:35 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:35 INFO Executor: Finished task 0.0 in stage 166.0 (TID 539). 938 bytes result sent to driver
18/04/01 20:16:35 INFO Executor: Finished task 1.0 in stage 166.0 (TID 540). 895 bytes result sent to driver
18/04/01 20:16:35 INFO TaskSetManager: Starting task 2.0 in stage 166.0 (TID 541, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:35 INFO Executor: Running task 2.0 in stage 166.0 (TID 541)
18/04/01 20:16:35 INFO TaskSetManager: Finished task 0.0 in stage 166.0 (TID 539) in 5 ms on localhost (executor driver) (1/5)
18/04/01 20:16:35 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:35 INFO TaskSetManager: Starting task 3.0 in stage 166.0 (TID 542, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:35 INFO Executor: Running task 3.0 in stage 166.0 (TID 542)
18/04/01 20:16:35 INFO TaskSetManager: Finished task 1.0 in stage 166.0 (TID 540) in 9 ms on localhost (executor driver) (2/5)
18/04/01 20:16:35 INFO Executor: Finished task 2.0 in stage 166.0 (TID 541). 938 bytes result sent to driver
18/04/01 20:16:35 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:35 INFO TaskSetManager: Starting task 4.0 in stage 166.0 (TID 543, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:35 INFO TaskSetManager: Finished task 2.0 in stage 166.0 (TID 541) in 6 ms on localhost (executor driver) (3/5)
18/04/01 20:16:35 INFO Executor: Finished task 3.0 in stage 166.0 (TID 542). 938 bytes result sent to driver
18/04/01 20:16:35 INFO TaskSetManager: Finished task 3.0 in stage 166.0 (TID 542) in 5 ms on localhost (executor driver) (4/5)
18/04/01 20:16:35 INFO Executor: Running task 4.0 in stage 166.0 (TID 543)
18/04/01 20:16:35 INFO KafkaRDD: Beginning offset 732 is the same as ending offset skipping clients-purchases-src-xxx 0
18/04/01 20:16:35 INFO Executor: Finished task 4.0 in stage 166.0 (TID 543). 938 bytes result sent to driver
18/04/01 20:16:35 INFO TaskSetManager: Finished task 4.0 in stage 166.0 (TID 543) in 8 ms on localhost (executor driver) (5/5)
18/04/01 20:16:35 INFO TaskSchedulerImpl: Removed TaskSet 166.0, whose tasks have all completed, from pool 
18/04/01 20:16:35 INFO DAGScheduler: ShuffleMapStage 166 (map at RefereeStats.scala:39) finished in 0.026 s
18/04/01 20:16:35 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:16:35 INFO DAGScheduler: running: Set()
18/04/01 20:16:35 INFO DAGScheduler: waiting: Set(ResultStage 167)
18/04/01 20:16:35 INFO DAGScheduler: failed: Set()
18/04/01 20:16:35 INFO DAGScheduler: Submitting ResultStage 167 (ShuffledRDD[146] at reduceByKey at RefereeStats.scala:43), which has no missing parents
18/04/01 20:16:35 INFO MemoryStore: Block broadcast_168 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:16:35 INFO MemoryStore: Block broadcast_168_piece0 stored as bytes in memory (estimated size 1704.0 B, free 477.2 MB)
18/04/01 20:16:35 INFO BlockManagerInfo: Added broadcast_168_piece0 in memory on 192.168.1.3:35449 (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:16:35 INFO SparkContext: Created broadcast 168 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 167 (ShuffledRDD[146] at reduceByKey at RefereeStats.scala:43) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:16:35 INFO TaskSchedulerImpl: Adding task set 167.0 with 2 tasks
18/04/01 20:16:35 INFO TaskSetManager: Starting task 0.0 in stage 167.0 (TID 544, localhost, executor driver, partition 0, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:35 INFO TaskSetManager: Starting task 1.0 in stage 167.0 (TID 545, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:35 INFO Executor: Running task 0.0 in stage 167.0 (TID 544)
18/04/01 20:16:35 INFO Executor: Running task 1.0 in stage 167.0 (TID 545)
18/04/01 20:16:35 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:35 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:16:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:16:35 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:35 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:35 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:35 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:35 INFO KafkaProducer: [Producer clientId=producer-125] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:35 INFO Executor: Finished task 0.0 in stage 167.0 (TID 544). 1138 bytes result sent to driver
18/04/01 20:16:35 INFO TaskSetManager: Finished task 0.0 in stage 167.0 (TID 544) in 14 ms on localhost (executor driver) (1/2)
18/04/01 20:16:35 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:35 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:35 INFO KafkaProducer: [Producer clientId=producer-126] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:35 INFO Executor: Finished task 1.0 in stage 167.0 (TID 545). 1138 bytes result sent to driver
18/04/01 20:16:35 INFO TaskSetManager: Finished task 1.0 in stage 167.0 (TID 545) in 22 ms on localhost (executor driver) (2/2)
18/04/01 20:16:35 INFO TaskSchedulerImpl: Removed TaskSet 167.0, whose tasks have all completed, from pool 
18/04/01 20:16:35 INFO DAGScheduler: ResultStage 167 (foreachPartition at RefereeStats.scala:106) finished in 0.031 s
18/04/01 20:16:35 INFO DAGScheduler: Job 104 finished: foreachPartition at RefereeStats.scala:106, took 0.063999 s
18/04/01 20:16:35 INFO JobScheduler: Finished job streaming job 1522602995000 ms.3 from job set of time 1522602995000 ms
18/04/01 20:16:35 INFO JobScheduler: Total delay: 0.297 s for time 1522602995000 ms (execution: 0.268 s)
18/04/01 20:16:35 INFO MapPartitionsRDD: Removing RDD 134 from persistence list
18/04/01 20:16:35 INFO KafkaRDD: Removing RDD 133 from persistence list
18/04/01 20:16:35 INFO ShuffledRDD: Removing RDD 135 from persistence list
18/04/01 20:16:35 INFO BlockManager: Removing RDD 134
18/04/01 20:16:35 INFO BlockManager: Removing RDD 135
18/04/01 20:16:35 INFO BlockManager: Removing RDD 133
18/04/01 20:16:35 INFO ShuffledRDD: Removing RDD 137 from persistence list
18/04/01 20:16:35 INFO MapPartitionsRDD: Removing RDD 136 from persistence list
18/04/01 20:16:35 INFO ShuffledRDD: Removing RDD 139 from persistence list
18/04/01 20:16:35 INFO MapPartitionsRDD: Removing RDD 138 from persistence list
18/04/01 20:16:35 INFO BlockManager: Removing RDD 138
18/04/01 20:16:35 INFO BlockManager: Removing RDD 139
18/04/01 20:16:35 INFO BlockManager: Removing RDD 136
18/04/01 20:16:35 INFO JobGenerator: Checkpointing graph for time 1522602995000 ms
18/04/01 20:16:35 INFO DStreamGraph: Updating checkpoint data for time 1522602995000 ms
18/04/01 20:16:35 INFO DStreamGraph: Updated checkpoint data for time 1522602995000 ms
18/04/01 20:16:35 INFO CheckpointWriter: Submitted checkpoint of time 1522602995000 ms to writer queue
18/04/01 20:16:35 INFO CheckpointWriter: Saving checkpoint for time 1522602995000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522602995000'
18/04/01 20:16:35 INFO BlockManager: Removing RDD 137
18/04/01 20:16:35 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602970000
18/04/01 20:16:35 INFO CheckpointWriter: Checkpoint for time 1522602995000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522602995000', took 5535 bytes and 43 ms
18/04/01 20:16:35 INFO DStreamGraph: Clearing checkpoint data for time 1522602995000 ms
18/04/01 20:16:35 INFO DStreamGraph: Cleared checkpoint data for time 1522602995000 ms
18/04/01 20:16:35 INFO ReceivedBlockTracker: Deleting batches: 
18/04/01 20:16:35 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/tmp/refs-xyzabb/receivedBlockMetadata older than 1522602990000: 
18/04/01 20:16:35 INFO InputInfoTracker: remove old batch metadata: 1522602985000 ms
18/04/01 20:16:40 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-0 to offset 732.
18/04/01 20:16:40 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-3 to offset 0.
18/04/01 20:16:40 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-4 to offset 0.
18/04/01 20:16:40 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-1 to offset 0.
18/04/01 20:16:40 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-2 to offset 0.
18/04/01 20:16:40 INFO JobScheduler: Starting job streaming job 1522603000000 ms.0 from job set of time 1522603000000 ms
18/04/01 20:16:40 INFO JobScheduler: Added jobs for time 1522603000000 ms
18/04/01 20:16:40 INFO JobGenerator: Checkpointing graph for time 1522603000000 ms
18/04/01 20:16:40 INFO DStreamGraph: Updating checkpoint data for time 1522603000000 ms
18/04/01 20:16:40 INFO DStreamGraph: Updated checkpoint data for time 1522603000000 ms
18/04/01 20:16:40 INFO CheckpointWriter: Submitted checkpoint of time 1522603000000 ms to writer queue
18/04/01 20:16:40 INFO CheckpointWriter: Saving checkpoint for time 1522603000000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522603000000'
18/04/01 20:16:40 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:16:40 INFO DAGScheduler: Got job 105 (print at RefereeStats.scala:67) with 1 output partitions
18/04/01 20:16:40 INFO DAGScheduler: Final stage: ResultStage 168 (print at RefereeStats.scala:67)
18/04/01 20:16:40 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:16:40 INFO DAGScheduler: Missing parents: List()
18/04/01 20:16:40 INFO DAGScheduler: Submitting ResultStage 168 (MapPartitionsRDD[148] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:16:40 INFO MemoryStore: Block broadcast_169 stored as values in memory (estimated size 3.0 KB, free 477.2 MB)
18/04/01 20:16:40 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602975000.bk
18/04/01 20:16:40 INFO CheckpointWriter: Checkpoint for time 1522603000000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522603000000', took 5589 bytes and 16 ms
18/04/01 20:16:40 INFO MemoryStore: Block broadcast_169_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.2 MB)
18/04/01 20:16:40 INFO BlockManagerInfo: Added broadcast_169_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:40 INFO SparkContext: Created broadcast 169 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 168 (MapPartitionsRDD[148] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0))
18/04/01 20:16:40 INFO TaskSchedulerImpl: Adding task set 168.0 with 1 tasks
18/04/01 20:16:40 INFO TaskSetManager: Starting task 0.0 in stage 168.0 (TID 546, localhost, executor driver, partition 0, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:40 INFO Executor: Running task 0.0 in stage 168.0 (TID 546)
18/04/01 20:16:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:40 INFO Executor: Finished task 0.0 in stage 168.0 (TID 546). 704 bytes result sent to driver
18/04/01 20:16:40 INFO TaskSetManager: Finished task 0.0 in stage 168.0 (TID 546) in 5 ms on localhost (executor driver) (1/1)
18/04/01 20:16:40 INFO TaskSchedulerImpl: Removed TaskSet 168.0, whose tasks have all completed, from pool 
18/04/01 20:16:40 INFO DAGScheduler: ResultStage 168 (print at RefereeStats.scala:67) finished in 0.012 s
18/04/01 20:16:40 INFO DAGScheduler: Job 105 finished: print at RefereeStats.scala:67, took 0.015213 s
18/04/01 20:16:40 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:16:40 INFO DAGScheduler: Got job 106 (print at RefereeStats.scala:67) with 4 output partitions
18/04/01 20:16:40 INFO DAGScheduler: Final stage: ResultStage 169 (print at RefereeStats.scala:67)
18/04/01 20:16:40 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:16:40 INFO DAGScheduler: Missing parents: List()
18/04/01 20:16:40 INFO DAGScheduler: Submitting ResultStage 169 (MapPartitionsRDD[148] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:16:40 INFO MemoryStore: Block broadcast_170 stored as values in memory (estimated size 3.0 KB, free 477.2 MB)
18/04/01 20:16:40 INFO MemoryStore: Block broadcast_170_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.2 MB)
18/04/01 20:16:40 INFO BlockManagerInfo: Added broadcast_170_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:40 INFO SparkContext: Created broadcast 170 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:40 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 169 (MapPartitionsRDD[148] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
18/04/01 20:16:40 INFO TaskSchedulerImpl: Adding task set 169.0 with 4 tasks
18/04/01 20:16:40 INFO TaskSetManager: Starting task 0.0 in stage 169.0 (TID 547, localhost, executor driver, partition 1, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:40 INFO TaskSetManager: Starting task 1.0 in stage 169.0 (TID 548, localhost, executor driver, partition 2, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:40 INFO Executor: Running task 0.0 in stage 169.0 (TID 547)
18/04/01 20:16:40 INFO Executor: Running task 1.0 in stage 169.0 (TID 548)
18/04/01 20:16:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:40 INFO Executor: Finished task 0.0 in stage 169.0 (TID 547). 704 bytes result sent to driver
18/04/01 20:16:40 INFO Executor: Finished task 1.0 in stage 169.0 (TID 548). 704 bytes result sent to driver
18/04/01 20:16:40 INFO TaskSetManager: Starting task 2.0 in stage 169.0 (TID 549, localhost, executor driver, partition 3, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:40 INFO TaskSetManager: Finished task 0.0 in stage 169.0 (TID 547) in 4 ms on localhost (executor driver) (1/4)
18/04/01 20:16:40 INFO Executor: Running task 2.0 in stage 169.0 (TID 549)
18/04/01 20:16:40 INFO TaskSetManager: Starting task 3.0 in stage 169.0 (TID 550, localhost, executor driver, partition 4, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:40 INFO TaskSetManager: Finished task 1.0 in stage 169.0 (TID 548) in 5 ms on localhost (executor driver) (2/4)
18/04/01 20:16:40 INFO Executor: Running task 3.0 in stage 169.0 (TID 550)
18/04/01 20:16:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:40 INFO Executor: Finished task 2.0 in stage 169.0 (TID 549). 704 bytes result sent to driver
18/04/01 20:16:40 INFO TaskSetManager: Finished task 2.0 in stage 169.0 (TID 549) in 4 ms on localhost (executor driver) (3/4)
18/04/01 20:16:40 INFO KafkaRDD: Beginning offset 732 is the same as ending offset skipping clients-purchases-src-xxx 0
18/04/01 20:16:40 INFO Executor: Finished task 3.0 in stage 169.0 (TID 550). 704 bytes result sent to driver
18/04/01 20:16:40 INFO TaskSetManager: Finished task 3.0 in stage 169.0 (TID 550) in 5 ms on localhost (executor driver) (4/4)
18/04/01 20:16:40 INFO TaskSchedulerImpl: Removed TaskSet 169.0, whose tasks have all completed, from pool 
18/04/01 20:16:40 INFO DAGScheduler: ResultStage 169 (print at RefereeStats.scala:67) finished in 0.018 s
-------------------------------------------
Time: 1522603000000 ms
-------------------------------------------

18/04/01 20:16:40 INFO DAGScheduler: Job 106 finished: print at RefereeStats.scala:67, took 0.024837 s
18/04/01 20:16:40 INFO JobScheduler: Finished job streaming job 1522603000000 ms.0 from job set of time 1522603000000 ms
18/04/01 20:16:40 INFO JobScheduler: Starting job streaming job 1522603000000 ms.1 from job set of time 1522603000000 ms
18/04/01 20:16:40 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:71
18/04/01 20:16:40 INFO DAGScheduler: Registering RDD 148 (map at RefereeStats.scala:53)
18/04/01 20:16:40 INFO DAGScheduler: Got job 107 (foreachPartition at RefereeStats.scala:71) with 2 output partitions
18/04/01 20:16:40 INFO DAGScheduler: Final stage: ResultStage 171 (foreachPartition at RefereeStats.scala:71)
18/04/01 20:16:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 170)
18/04/01 20:16:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 170)
18/04/01 20:16:40 INFO DAGScheduler: Submitting ShuffleMapStage 170 (MapPartitionsRDD[148] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:16:40 INFO MemoryStore: Block broadcast_171 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:16:40 INFO MemoryStore: Block broadcast_171_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:16:40 INFO BlockManagerInfo: Added broadcast_171_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:40 INFO SparkContext: Created broadcast 171 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:40 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 170 (MapPartitionsRDD[148] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:16:40 INFO TaskSchedulerImpl: Adding task set 170.0 with 5 tasks
18/04/01 20:16:40 INFO TaskSetManager: Starting task 0.0 in stage 170.0 (TID 551, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:40 INFO TaskSetManager: Starting task 1.0 in stage 170.0 (TID 552, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:40 INFO Executor: Running task 1.0 in stage 170.0 (TID 552)
18/04/01 20:16:40 INFO Executor: Running task 0.0 in stage 170.0 (TID 551)
18/04/01 20:16:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:40 INFO Executor: Finished task 0.0 in stage 170.0 (TID 551). 938 bytes result sent to driver
18/04/01 20:16:40 INFO Executor: Finished task 1.0 in stage 170.0 (TID 552). 938 bytes result sent to driver
18/04/01 20:16:40 INFO TaskSetManager: Starting task 2.0 in stage 170.0 (TID 553, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:40 INFO TaskSetManager: Starting task 3.0 in stage 170.0 (TID 554, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:40 INFO Executor: Running task 2.0 in stage 170.0 (TID 553)
18/04/01 20:16:40 INFO Executor: Running task 3.0 in stage 170.0 (TID 554)
18/04/01 20:16:40 INFO TaskSetManager: Finished task 0.0 in stage 170.0 (TID 551) in 6 ms on localhost (executor driver) (1/5)
18/04/01 20:16:40 INFO TaskSetManager: Finished task 1.0 in stage 170.0 (TID 552) in 7 ms on localhost (executor driver) (2/5)
18/04/01 20:16:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:40 INFO Executor: Finished task 2.0 in stage 170.0 (TID 553). 938 bytes result sent to driver
18/04/01 20:16:40 INFO Executor: Finished task 3.0 in stage 170.0 (TID 554). 938 bytes result sent to driver
18/04/01 20:16:40 INFO TaskSetManager: Starting task 4.0 in stage 170.0 (TID 555, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:40 INFO Executor: Running task 4.0 in stage 170.0 (TID 555)
18/04/01 20:16:40 INFO TaskSetManager: Finished task 2.0 in stage 170.0 (TID 553) in 6 ms on localhost (executor driver) (3/5)
18/04/01 20:16:40 INFO KafkaRDD: Beginning offset 732 is the same as ending offset skipping clients-purchases-src-xxx 0
18/04/01 20:16:40 INFO Executor: Finished task 4.0 in stage 170.0 (TID 555). 938 bytes result sent to driver
18/04/01 20:16:40 INFO TaskSetManager: Finished task 3.0 in stage 170.0 (TID 554) in 13 ms on localhost (executor driver) (4/5)
18/04/01 20:16:40 INFO TaskSetManager: Finished task 4.0 in stage 170.0 (TID 555) in 8 ms on localhost (executor driver) (5/5)
18/04/01 20:16:40 INFO TaskSchedulerImpl: Removed TaskSet 170.0, whose tasks have all completed, from pool 
18/04/01 20:16:40 INFO DAGScheduler: ShuffleMapStage 170 (map at RefereeStats.scala:53) finished in 0.027 s
18/04/01 20:16:40 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:16:40 INFO DAGScheduler: running: Set()
18/04/01 20:16:40 INFO DAGScheduler: waiting: Set(ResultStage 171)
18/04/01 20:16:40 INFO DAGScheduler: failed: Set()
18/04/01 20:16:40 INFO DAGScheduler: Submitting ResultStage 171 (ShuffledRDD[149] at reduceByKey at RefereeStats.scala:60), which has no missing parents
18/04/01 20:16:40 INFO MemoryStore: Block broadcast_172 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:16:40 INFO MemoryStore: Block broadcast_172_piece0 stored as bytes in memory (estimated size 1706.0 B, free 477.2 MB)
18/04/01 20:16:40 INFO BlockManagerInfo: Added broadcast_172_piece0 in memory on 192.168.1.3:35449 (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:16:40 INFO SparkContext: Created broadcast 172 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:40 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 171 (ShuffledRDD[149] at reduceByKey at RefereeStats.scala:60) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:16:40 INFO TaskSchedulerImpl: Adding task set 171.0 with 2 tasks
18/04/01 20:16:40 INFO TaskSetManager: Starting task 0.0 in stage 171.0 (TID 556, localhost, executor driver, partition 0, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:40 INFO TaskSetManager: Starting task 1.0 in stage 171.0 (TID 557, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:40 INFO Executor: Running task 0.0 in stage 171.0 (TID 556)
18/04/01 20:16:40 INFO Executor: Running task 1.0 in stage 171.0 (TID 557)
18/04/01 20:16:40 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:40 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:16:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:40 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:40 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:40 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:40 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:40 INFO KafkaProducer: [Producer clientId=producer-128] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:40 INFO Executor: Finished task 0.0 in stage 171.0 (TID 556). 1138 bytes result sent to driver
18/04/01 20:16:40 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:40 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:40 INFO KafkaProducer: [Producer clientId=producer-127] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:40 INFO TaskSetManager: Finished task 0.0 in stage 171.0 (TID 556) in 13 ms on localhost (executor driver) (1/2)
18/04/01 20:16:40 INFO Executor: Finished task 1.0 in stage 171.0 (TID 557). 1138 bytes result sent to driver
18/04/01 20:16:40 INFO TaskSetManager: Finished task 1.0 in stage 171.0 (TID 557) in 17 ms on localhost (executor driver) (2/2)
18/04/01 20:16:40 INFO TaskSchedulerImpl: Removed TaskSet 171.0, whose tasks have all completed, from pool 
18/04/01 20:16:40 INFO DAGScheduler: ResultStage 171 (foreachPartition at RefereeStats.scala:71) finished in 0.025 s
18/04/01 20:16:40 INFO DAGScheduler: Job 107 finished: foreachPartition at RefereeStats.scala:71, took 0.059276 s
18/04/01 20:16:40 INFO JobScheduler: Finished job streaming job 1522603000000 ms.1 from job set of time 1522603000000 ms
18/04/01 20:16:40 INFO JobScheduler: Starting job streaming job 1522603000000 ms.2 from job set of time 1522603000000 ms
18/04/01 20:16:40 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:89
18/04/01 20:16:40 INFO DAGScheduler: Registering RDD 150 (map at RefereeStats.scala:46)
18/04/01 20:16:40 INFO DAGScheduler: Got job 108 (foreachPartition at RefereeStats.scala:89) with 2 output partitions
18/04/01 20:16:40 INFO DAGScheduler: Final stage: ResultStage 173 (foreachPartition at RefereeStats.scala:89)
18/04/01 20:16:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 172)
18/04/01 20:16:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 172)
18/04/01 20:16:40 INFO DAGScheduler: Submitting ShuffleMapStage 172 (MapPartitionsRDD[150] at map at RefereeStats.scala:46), which has no missing parents
18/04/01 20:16:40 INFO MemoryStore: Block broadcast_173 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:16:40 INFO MemoryStore: Block broadcast_173_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:16:40 INFO BlockManagerInfo: Added broadcast_173_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:40 INFO SparkContext: Created broadcast 173 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:40 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 172 (MapPartitionsRDD[150] at map at RefereeStats.scala:46) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:16:40 INFO TaskSchedulerImpl: Adding task set 172.0 with 5 tasks
18/04/01 20:16:40 INFO TaskSetManager: Starting task 0.0 in stage 172.0 (TID 558, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:40 INFO TaskSetManager: Starting task 1.0 in stage 172.0 (TID 559, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:40 INFO Executor: Running task 1.0 in stage 172.0 (TID 559)
18/04/01 20:16:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:40 INFO Executor: Finished task 1.0 in stage 172.0 (TID 559). 938 bytes result sent to driver
18/04/01 20:16:40 INFO Executor: Running task 0.0 in stage 172.0 (TID 558)
18/04/01 20:16:40 INFO TaskSetManager: Starting task 2.0 in stage 172.0 (TID 560, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:40 INFO Executor: Running task 2.0 in stage 172.0 (TID 560)
18/04/01 20:16:40 INFO TaskSetManager: Finished task 1.0 in stage 172.0 (TID 559) in 6 ms on localhost (executor driver) (1/5)
18/04/01 20:16:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:40 INFO Executor: Finished task 2.0 in stage 172.0 (TID 560). 938 bytes result sent to driver
18/04/01 20:16:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:40 INFO Executor: Finished task 0.0 in stage 172.0 (TID 558). 938 bytes result sent to driver
18/04/01 20:16:40 INFO TaskSetManager: Starting task 3.0 in stage 172.0 (TID 561, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:40 INFO Executor: Running task 3.0 in stage 172.0 (TID 561)
18/04/01 20:16:40 INFO TaskSetManager: Starting task 4.0 in stage 172.0 (TID 562, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:40 INFO Executor: Running task 4.0 in stage 172.0 (TID 562)
18/04/01 20:16:40 INFO TaskSetManager: Finished task 2.0 in stage 172.0 (TID 560) in 9 ms on localhost (executor driver) (2/5)
18/04/01 20:16:40 INFO TaskSetManager: Finished task 0.0 in stage 172.0 (TID 558) in 15 ms on localhost (executor driver) (3/5)
18/04/01 20:16:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:40 INFO KafkaRDD: Beginning offset 732 is the same as ending offset skipping clients-purchases-src-xxx 0
18/04/01 20:16:40 INFO Executor: Finished task 4.0 in stage 172.0 (TID 562). 938 bytes result sent to driver
18/04/01 20:16:40 INFO Executor: Finished task 3.0 in stage 172.0 (TID 561). 938 bytes result sent to driver
18/04/01 20:16:40 INFO TaskSetManager: Finished task 4.0 in stage 172.0 (TID 562) in 6 ms on localhost (executor driver) (4/5)
18/04/01 20:16:40 INFO TaskSetManager: Finished task 3.0 in stage 172.0 (TID 561) in 7 ms on localhost (executor driver) (5/5)
18/04/01 20:16:40 INFO TaskSchedulerImpl: Removed TaskSet 172.0, whose tasks have all completed, from pool 
18/04/01 20:16:40 INFO DAGScheduler: ShuffleMapStage 172 (map at RefereeStats.scala:46) finished in 0.028 s
18/04/01 20:16:40 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:16:40 INFO DAGScheduler: running: Set()
18/04/01 20:16:40 INFO DAGScheduler: waiting: Set(ResultStage 173)
18/04/01 20:16:40 INFO DAGScheduler: failed: Set()
18/04/01 20:16:40 INFO DAGScheduler: Submitting ResultStage 173 (ShuffledRDD[151] at reduceByKey at RefereeStats.scala:51), which has no missing parents
18/04/01 20:16:40 INFO MemoryStore: Block broadcast_174 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:16:40 INFO MemoryStore: Block broadcast_174_piece0 stored as bytes in memory (estimated size 1709.0 B, free 477.2 MB)
18/04/01 20:16:40 INFO BlockManagerInfo: Added broadcast_174_piece0 in memory on 192.168.1.3:35449 (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:16:40 INFO SparkContext: Created broadcast 174 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:40 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 173 (ShuffledRDD[151] at reduceByKey at RefereeStats.scala:51) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:16:40 INFO TaskSchedulerImpl: Adding task set 173.0 with 2 tasks
18/04/01 20:16:40 INFO TaskSetManager: Starting task 0.0 in stage 173.0 (TID 563, localhost, executor driver, partition 0, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:40 INFO TaskSetManager: Starting task 1.0 in stage 173.0 (TID 564, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:40 INFO Executor: Running task 1.0 in stage 173.0 (TID 564)
18/04/01 20:16:40 INFO Executor: Running task 0.0 in stage 173.0 (TID 563)
18/04/01 20:16:40 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:40 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:40 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:40 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:40 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:40 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:40 INFO KafkaProducer: [Producer clientId=producer-129] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:40 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:40 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:40 INFO KafkaProducer: [Producer clientId=producer-130] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:40 INFO Executor: Finished task 1.0 in stage 173.0 (TID 564). 1138 bytes result sent to driver
18/04/01 20:16:40 INFO TaskSetManager: Finished task 1.0 in stage 173.0 (TID 564) in 17 ms on localhost (executor driver) (1/2)
18/04/01 20:16:40 INFO Executor: Finished task 0.0 in stage 173.0 (TID 563). 1138 bytes result sent to driver
18/04/01 20:16:40 INFO TaskSetManager: Finished task 0.0 in stage 173.0 (TID 563) in 20 ms on localhost (executor driver) (2/2)
18/04/01 20:16:40 INFO TaskSchedulerImpl: Removed TaskSet 173.0, whose tasks have all completed, from pool 
18/04/01 20:16:40 INFO DAGScheduler: ResultStage 173 (foreachPartition at RefereeStats.scala:89) finished in 0.027 s
18/04/01 20:16:40 INFO DAGScheduler: Job 108 finished: foreachPartition at RefereeStats.scala:89, took 0.062471 s
18/04/01 20:16:40 INFO JobScheduler: Finished job streaming job 1522603000000 ms.2 from job set of time 1522603000000 ms
18/04/01 20:16:40 INFO JobScheduler: Starting job streaming job 1522603000000 ms.3 from job set of time 1522603000000 ms
18/04/01 20:16:40 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:106
18/04/01 20:16:40 INFO DAGScheduler: Registering RDD 152 (map at RefereeStats.scala:39)
18/04/01 20:16:40 INFO DAGScheduler: Got job 109 (foreachPartition at RefereeStats.scala:106) with 2 output partitions
18/04/01 20:16:40 INFO DAGScheduler: Final stage: ResultStage 175 (foreachPartition at RefereeStats.scala:106)
18/04/01 20:16:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 174)
18/04/01 20:16:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 174)
18/04/01 20:16:40 INFO DAGScheduler: Submitting ShuffleMapStage 174 (MapPartitionsRDD[152] at map at RefereeStats.scala:39), which has no missing parents
18/04/01 20:16:40 INFO MemoryStore: Block broadcast_175 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:16:40 INFO MemoryStore: Block broadcast_175_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:16:40 INFO BlockManagerInfo: Added broadcast_175_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:40 INFO SparkContext: Created broadcast 175 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:40 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 174 (MapPartitionsRDD[152] at map at RefereeStats.scala:39) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:16:40 INFO TaskSchedulerImpl: Adding task set 174.0 with 5 tasks
18/04/01 20:16:40 INFO TaskSetManager: Starting task 0.0 in stage 174.0 (TID 565, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:40 INFO TaskSetManager: Starting task 1.0 in stage 174.0 (TID 566, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:40 INFO Executor: Running task 0.0 in stage 174.0 (TID 565)
18/04/01 20:16:40 INFO Executor: Running task 1.0 in stage 174.0 (TID 566)
18/04/01 20:16:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:40 INFO Executor: Finished task 0.0 in stage 174.0 (TID 565). 938 bytes result sent to driver
18/04/01 20:16:40 INFO Executor: Finished task 1.0 in stage 174.0 (TID 566). 938 bytes result sent to driver
18/04/01 20:16:40 INFO TaskSetManager: Starting task 2.0 in stage 174.0 (TID 567, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:40 INFO Executor: Running task 2.0 in stage 174.0 (TID 567)
18/04/01 20:16:40 INFO TaskSetManager: Starting task 3.0 in stage 174.0 (TID 568, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:40 INFO TaskSetManager: Finished task 0.0 in stage 174.0 (TID 565) in 6 ms on localhost (executor driver) (1/5)
18/04/01 20:16:40 INFO TaskSetManager: Finished task 1.0 in stage 174.0 (TID 566) in 5 ms on localhost (executor driver) (2/5)
18/04/01 20:16:40 INFO Executor: Running task 3.0 in stage 174.0 (TID 568)
18/04/01 20:16:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:40 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:40 INFO Executor: Finished task 2.0 in stage 174.0 (TID 567). 938 bytes result sent to driver
18/04/01 20:16:40 INFO Executor: Finished task 3.0 in stage 174.0 (TID 568). 938 bytes result sent to driver
18/04/01 20:16:40 INFO TaskSetManager: Starting task 4.0 in stage 174.0 (TID 569, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:40 INFO Executor: Running task 4.0 in stage 174.0 (TID 569)
18/04/01 20:16:40 INFO TaskSetManager: Finished task 2.0 in stage 174.0 (TID 567) in 5 ms on localhost (executor driver) (3/5)
18/04/01 20:16:40 INFO TaskSetManager: Finished task 3.0 in stage 174.0 (TID 568) in 5 ms on localhost (executor driver) (4/5)
18/04/01 20:16:40 INFO KafkaRDD: Beginning offset 732 is the same as ending offset skipping clients-purchases-src-xxx 0
18/04/01 20:16:40 INFO Executor: Finished task 4.0 in stage 174.0 (TID 569). 938 bytes result sent to driver
18/04/01 20:16:40 INFO TaskSetManager: Finished task 4.0 in stage 174.0 (TID 569) in 5 ms on localhost (executor driver) (5/5)
18/04/01 20:16:40 INFO TaskSchedulerImpl: Removed TaskSet 174.0, whose tasks have all completed, from pool 
18/04/01 20:16:40 INFO DAGScheduler: ShuffleMapStage 174 (map at RefereeStats.scala:39) finished in 0.021 s
18/04/01 20:16:40 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:16:40 INFO DAGScheduler: running: Set()
18/04/01 20:16:40 INFO DAGScheduler: waiting: Set(ResultStage 175)
18/04/01 20:16:40 INFO DAGScheduler: failed: Set()
18/04/01 20:16:40 INFO DAGScheduler: Submitting ResultStage 175 (ShuffledRDD[153] at reduceByKey at RefereeStats.scala:43), which has no missing parents
18/04/01 20:16:40 INFO MemoryStore: Block broadcast_176 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:16:40 INFO MemoryStore: Block broadcast_176_piece0 stored as bytes in memory (estimated size 1704.0 B, free 477.2 MB)
18/04/01 20:16:40 INFO BlockManagerInfo: Added broadcast_176_piece0 in memory on 192.168.1.3:35449 (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:16:40 INFO SparkContext: Created broadcast 176 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:40 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 175 (ShuffledRDD[153] at reduceByKey at RefereeStats.scala:43) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:16:40 INFO TaskSchedulerImpl: Adding task set 175.0 with 2 tasks
18/04/01 20:16:40 INFO TaskSetManager: Starting task 0.0 in stage 175.0 (TID 570, localhost, executor driver, partition 0, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:40 INFO TaskSetManager: Starting task 1.0 in stage 175.0 (TID 571, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:40 INFO Executor: Running task 1.0 in stage 175.0 (TID 571)
18/04/01 20:16:40 INFO Executor: Running task 0.0 in stage 175.0 (TID 570)
18/04/01 20:16:40 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:40 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:16:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:16:40 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:40 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:40 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:40 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:40 INFO KafkaProducer: [Producer clientId=producer-132] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:40 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:40 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:40 INFO KafkaProducer: [Producer clientId=producer-131] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:40 INFO Executor: Finished task 0.0 in stage 175.0 (TID 570). 1138 bytes result sent to driver
18/04/01 20:16:40 INFO Executor: Finished task 1.0 in stage 175.0 (TID 571). 1138 bytes result sent to driver
18/04/01 20:16:40 INFO TaskSetManager: Finished task 0.0 in stage 175.0 (TID 570) in 13 ms on localhost (executor driver) (1/2)
18/04/01 20:16:40 INFO TaskSetManager: Finished task 1.0 in stage 175.0 (TID 571) in 12 ms on localhost (executor driver) (2/2)
18/04/01 20:16:40 INFO TaskSchedulerImpl: Removed TaskSet 175.0, whose tasks have all completed, from pool 
18/04/01 20:16:40 INFO DAGScheduler: ResultStage 175 (foreachPartition at RefereeStats.scala:106) finished in 0.021 s
18/04/01 20:16:40 INFO DAGScheduler: Job 109 finished: foreachPartition at RefereeStats.scala:106, took 0.047949 s
18/04/01 20:16:40 INFO JobScheduler: Finished job streaming job 1522603000000 ms.3 from job set of time 1522603000000 ms
18/04/01 20:16:40 INFO JobScheduler: Total delay: 0.285 s for time 1522603000000 ms (execution: 0.262 s)
18/04/01 20:16:40 INFO MapPartitionsRDD: Removing RDD 141 from persistence list
18/04/01 20:16:40 INFO KafkaRDD: Removing RDD 140 from persistence list
18/04/01 20:16:40 INFO ShuffledRDD: Removing RDD 142 from persistence list
18/04/01 20:16:40 INFO BlockManager: Removing RDD 141
18/04/01 20:16:40 INFO BlockManager: Removing RDD 142
18/04/01 20:16:40 INFO BlockManager: Removing RDD 140
18/04/01 20:16:40 INFO ShuffledRDD: Removing RDD 144 from persistence list
18/04/01 20:16:40 INFO BlockManager: Removing RDD 144
18/04/01 20:16:40 INFO MapPartitionsRDD: Removing RDD 143 from persistence list
18/04/01 20:16:40 INFO BlockManager: Removing RDD 143
18/04/01 20:16:40 INFO ShuffledRDD: Removing RDD 146 from persistence list
18/04/01 20:16:40 INFO BlockManager: Removing RDD 146
18/04/01 20:16:40 INFO MapPartitionsRDD: Removing RDD 145 from persistence list
18/04/01 20:16:40 INFO BlockManager: Removing RDD 145
18/04/01 20:16:40 INFO JobGenerator: Checkpointing graph for time 1522603000000 ms
18/04/01 20:16:40 INFO DStreamGraph: Updating checkpoint data for time 1522603000000 ms
18/04/01 20:16:40 INFO DStreamGraph: Updated checkpoint data for time 1522603000000 ms
18/04/01 20:16:40 INFO CheckpointWriter: Saving checkpoint for time 1522603000000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522603000000'
18/04/01 20:16:40 INFO CheckpointWriter: Submitted checkpoint of time 1522603000000 ms to writer queue
18/04/01 20:16:40 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602975000
18/04/01 20:16:40 INFO CheckpointWriter: Checkpoint for time 1522603000000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522603000000', took 5535 bytes and 18 ms
18/04/01 20:16:40 INFO DStreamGraph: Clearing checkpoint data for time 1522603000000 ms
18/04/01 20:16:40 INFO DStreamGraph: Cleared checkpoint data for time 1522603000000 ms
18/04/01 20:16:40 INFO ReceivedBlockTracker: Deleting batches: 
18/04/01 20:16:40 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/tmp/refs-xyzabb/receivedBlockMetadata older than 1522602995000: 
18/04/01 20:16:40 INFO InputInfoTracker: remove old batch metadata: 1522602990000 ms
18/04/01 20:16:45 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-0 to offset 732.
18/04/01 20:16:45 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-3 to offset 0.
18/04/01 20:16:45 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-4 to offset 0.
18/04/01 20:16:45 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-1 to offset 0.
18/04/01 20:16:45 INFO Fetcher: [Consumer clientId=consumer-1, groupId=streamer-xxx-xyzab] Resetting offset for partition clients-purchases-src-xxx-2 to offset 0.
18/04/01 20:16:45 INFO JobScheduler: Added jobs for time 1522603005000 ms
18/04/01 20:16:45 INFO JobGenerator: Checkpointing graph for time 1522603005000 ms
18/04/01 20:16:45 INFO DStreamGraph: Updating checkpoint data for time 1522603005000 ms
18/04/01 20:16:45 INFO JobScheduler: Starting job streaming job 1522603005000 ms.0 from job set of time 1522603005000 ms
18/04/01 20:16:45 INFO DStreamGraph: Updated checkpoint data for time 1522603005000 ms
18/04/01 20:16:45 INFO CheckpointWriter: Submitted checkpoint of time 1522603005000 ms to writer queue
18/04/01 20:16:45 INFO CheckpointWriter: Saving checkpoint for time 1522603005000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522603005000'
18/04/01 20:16:45 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:16:45 INFO DAGScheduler: Got job 110 (print at RefereeStats.scala:67) with 1 output partitions
18/04/01 20:16:45 INFO DAGScheduler: Final stage: ResultStage 176 (print at RefereeStats.scala:67)
18/04/01 20:16:45 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:16:45 INFO DAGScheduler: Missing parents: List()
18/04/01 20:16:45 INFO DAGScheduler: Submitting ResultStage 176 (MapPartitionsRDD[155] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:16:45 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602980000.bk
18/04/01 20:16:45 INFO CheckpointWriter: Checkpoint for time 1522603005000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522603005000', took 5589 bytes and 21 ms
18/04/01 20:16:45 INFO MemoryStore: Block broadcast_177 stored as values in memory (estimated size 3.0 KB, free 477.2 MB)
18/04/01 20:16:45 INFO MemoryStore: Block broadcast_177_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.2 MB)
18/04/01 20:16:45 INFO BlockManagerInfo: Added broadcast_177_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:45 INFO SparkContext: Created broadcast 177 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 176 (MapPartitionsRDD[155] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0))
18/04/01 20:16:45 INFO TaskSchedulerImpl: Adding task set 176.0 with 1 tasks
18/04/01 20:16:45 INFO TaskSetManager: Starting task 0.0 in stage 176.0 (TID 572, localhost, executor driver, partition 0, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:45 INFO Executor: Running task 0.0 in stage 176.0 (TID 572)
18/04/01 20:16:45 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:45 INFO Executor: Finished task 0.0 in stage 176.0 (TID 572). 747 bytes result sent to driver
18/04/01 20:16:45 INFO TaskSetManager: Finished task 0.0 in stage 176.0 (TID 572) in 5 ms on localhost (executor driver) (1/1)
18/04/01 20:16:45 INFO TaskSchedulerImpl: Removed TaskSet 176.0, whose tasks have all completed, from pool 
18/04/01 20:16:45 INFO DAGScheduler: ResultStage 176 (print at RefereeStats.scala:67) finished in 0.013 s
18/04/01 20:16:45 INFO DAGScheduler: Job 110 finished: print at RefereeStats.scala:67, took 0.017218 s
18/04/01 20:16:45 INFO SparkContext: Starting job: print at RefereeStats.scala:67
18/04/01 20:16:45 INFO DAGScheduler: Got job 111 (print at RefereeStats.scala:67) with 4 output partitions
18/04/01 20:16:45 INFO DAGScheduler: Final stage: ResultStage 177 (print at RefereeStats.scala:67)
18/04/01 20:16:45 INFO DAGScheduler: Parents of final stage: List()
18/04/01 20:16:45 INFO DAGScheduler: Missing parents: List()
18/04/01 20:16:45 INFO DAGScheduler: Submitting ResultStage 177 (MapPartitionsRDD[155] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:16:45 INFO MemoryStore: Block broadcast_178 stored as values in memory (estimated size 3.0 KB, free 477.2 MB)
18/04/01 20:16:45 INFO MemoryStore: Block broadcast_178_piece0 stored as bytes in memory (estimated size 1987.0 B, free 477.2 MB)
18/04/01 20:16:45 INFO BlockManagerInfo: Added broadcast_178_piece0 in memory on 192.168.1.3:35449 (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:45 INFO SparkContext: Created broadcast 178 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:45 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 177 (MapPartitionsRDD[155] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
18/04/01 20:16:45 INFO TaskSchedulerImpl: Adding task set 177.0 with 4 tasks
18/04/01 20:16:45 INFO TaskSetManager: Starting task 0.0 in stage 177.0 (TID 573, localhost, executor driver, partition 1, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:45 INFO TaskSetManager: Starting task 1.0 in stage 177.0 (TID 574, localhost, executor driver, partition 2, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:45 INFO Executor: Running task 1.0 in stage 177.0 (TID 574)
18/04/01 20:16:45 INFO Executor: Running task 0.0 in stage 177.0 (TID 573)
18/04/01 20:16:45 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:45 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:45 INFO Executor: Finished task 1.0 in stage 177.0 (TID 574). 704 bytes result sent to driver
18/04/01 20:16:45 INFO Executor: Finished task 0.0 in stage 177.0 (TID 573). 661 bytes result sent to driver
18/04/01 20:16:45 INFO TaskSetManager: Starting task 2.0 in stage 177.0 (TID 575, localhost, executor driver, partition 3, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:45 INFO TaskSetManager: Starting task 3.0 in stage 177.0 (TID 576, localhost, executor driver, partition 4, PROCESS_LOCAL, 7751 bytes)
18/04/01 20:16:45 INFO TaskSetManager: Finished task 1.0 in stage 177.0 (TID 574) in 4 ms on localhost (executor driver) (1/4)
18/04/01 20:16:45 INFO TaskSetManager: Finished task 0.0 in stage 177.0 (TID 573) in 5 ms on localhost (executor driver) (2/4)
18/04/01 20:16:45 INFO Executor: Running task 2.0 in stage 177.0 (TID 575)
18/04/01 20:16:45 INFO Executor: Running task 3.0 in stage 177.0 (TID 576)
18/04/01 20:16:45 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:45 INFO KafkaRDD: Beginning offset 732 is the same as ending offset skipping clients-purchases-src-xxx 0
18/04/01 20:16:45 INFO Executor: Finished task 3.0 in stage 177.0 (TID 576). 704 bytes result sent to driver
18/04/01 20:16:45 INFO Executor: Finished task 2.0 in stage 177.0 (TID 575). 661 bytes result sent to driver
18/04/01 20:16:45 INFO TaskSetManager: Finished task 3.0 in stage 177.0 (TID 576) in 4 ms on localhost (executor driver) (3/4)
18/04/01 20:16:45 INFO TaskSetManager: Finished task 2.0 in stage 177.0 (TID 575) in 4 ms on localhost (executor driver) (4/4)
18/04/01 20:16:45 INFO TaskSchedulerImpl: Removed TaskSet 177.0, whose tasks have all completed, from pool 
18/04/01 20:16:45 INFO DAGScheduler: ResultStage 177 (print at RefereeStats.scala:67) finished in 0.015 s
18/04/01 20:16:45 INFO DAGScheduler: Job 111 finished: print at RefereeStats.scala:67, took 0.018400 s
18/04/01 20:16:45 INFO JobScheduler: Finished job streaming job 1522603005000 ms.0 from job set of time 1522603005000 ms
18/04/01 20:16:45 INFO JobScheduler: Starting job streaming job 1522603005000 ms.1 from job set of time 1522603005000 ms
-------------------------------------------
Time: 1522603005000 ms
-------------------------------------------

18/04/01 20:16:45 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:71
18/04/01 20:16:45 INFO DAGScheduler: Registering RDD 155 (map at RefereeStats.scala:53)
18/04/01 20:16:45 INFO DAGScheduler: Got job 112 (foreachPartition at RefereeStats.scala:71) with 2 output partitions
18/04/01 20:16:45 INFO DAGScheduler: Final stage: ResultStage 179 (foreachPartition at RefereeStats.scala:71)
18/04/01 20:16:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 178)
18/04/01 20:16:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 178)
18/04/01 20:16:45 INFO DAGScheduler: Submitting ShuffleMapStage 178 (MapPartitionsRDD[155] at map at RefereeStats.scala:53), which has no missing parents
18/04/01 20:16:45 INFO MemoryStore: Block broadcast_179 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:16:45 INFO MemoryStore: Block broadcast_179_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:16:45 INFO BlockManagerInfo: Added broadcast_179_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:45 INFO SparkContext: Created broadcast 179 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:45 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 178 (MapPartitionsRDD[155] at map at RefereeStats.scala:53) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:16:45 INFO TaskSchedulerImpl: Adding task set 178.0 with 5 tasks
18/04/01 20:16:45 INFO TaskSetManager: Starting task 0.0 in stage 178.0 (TID 577, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:45 INFO TaskSetManager: Starting task 1.0 in stage 178.0 (TID 578, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:45 INFO Executor: Running task 1.0 in stage 178.0 (TID 578)
18/04/01 20:16:45 INFO Executor: Running task 0.0 in stage 178.0 (TID 577)
18/04/01 20:16:45 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:45 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:45 INFO Executor: Finished task 0.0 in stage 178.0 (TID 577). 938 bytes result sent to driver
18/04/01 20:16:45 INFO Executor: Finished task 1.0 in stage 178.0 (TID 578). 938 bytes result sent to driver
18/04/01 20:16:45 INFO TaskSetManager: Starting task 2.0 in stage 178.0 (TID 579, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:45 INFO TaskSetManager: Starting task 3.0 in stage 178.0 (TID 580, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:45 INFO TaskSetManager: Finished task 0.0 in stage 178.0 (TID 577) in 7 ms on localhost (executor driver) (1/5)
18/04/01 20:16:45 INFO Executor: Running task 2.0 in stage 178.0 (TID 579)
18/04/01 20:16:45 INFO TaskSetManager: Finished task 1.0 in stage 178.0 (TID 578) in 6 ms on localhost (executor driver) (2/5)
18/04/01 20:16:45 INFO Executor: Running task 3.0 in stage 178.0 (TID 580)
18/04/01 20:16:45 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:45 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:45 INFO Executor: Finished task 3.0 in stage 178.0 (TID 580). 938 bytes result sent to driver
18/04/01 20:16:45 INFO Executor: Finished task 2.0 in stage 178.0 (TID 579). 938 bytes result sent to driver
18/04/01 20:16:45 INFO TaskSetManager: Starting task 4.0 in stage 178.0 (TID 581, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:45 INFO TaskSetManager: Finished task 3.0 in stage 178.0 (TID 580) in 5 ms on localhost (executor driver) (3/5)
18/04/01 20:16:45 INFO TaskSetManager: Finished task 2.0 in stage 178.0 (TID 579) in 7 ms on localhost (executor driver) (4/5)
18/04/01 20:16:45 INFO Executor: Running task 4.0 in stage 178.0 (TID 581)
18/04/01 20:16:45 INFO KafkaRDD: Beginning offset 732 is the same as ending offset skipping clients-purchases-src-xxx 0
18/04/01 20:16:45 INFO Executor: Finished task 4.0 in stage 178.0 (TID 581). 938 bytes result sent to driver
18/04/01 20:16:45 INFO TaskSetManager: Finished task 4.0 in stage 178.0 (TID 581) in 6 ms on localhost (executor driver) (5/5)
18/04/01 20:16:45 INFO TaskSchedulerImpl: Removed TaskSet 178.0, whose tasks have all completed, from pool 
18/04/01 20:16:45 INFO DAGScheduler: ShuffleMapStage 178 (map at RefereeStats.scala:53) finished in 0.025 s
18/04/01 20:16:45 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:16:45 INFO DAGScheduler: running: Set()
18/04/01 20:16:45 INFO DAGScheduler: waiting: Set(ResultStage 179)
18/04/01 20:16:45 INFO DAGScheduler: failed: Set()
18/04/01 20:16:45 INFO DAGScheduler: Submitting ResultStage 179 (ShuffledRDD[156] at reduceByKey at RefereeStats.scala:60), which has no missing parents
18/04/01 20:16:45 INFO MemoryStore: Block broadcast_180 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:16:45 INFO MemoryStore: Block broadcast_180_piece0 stored as bytes in memory (estimated size 1706.0 B, free 477.2 MB)
18/04/01 20:16:45 INFO BlockManagerInfo: Added broadcast_180_piece0 in memory on 192.168.1.3:35449 (size: 1706.0 B, free: 477.2 MB)
18/04/01 20:16:45 INFO SparkContext: Created broadcast 180 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 179 (ShuffledRDD[156] at reduceByKey at RefereeStats.scala:60) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:16:45 INFO TaskSchedulerImpl: Adding task set 179.0 with 2 tasks
18/04/01 20:16:45 INFO TaskSetManager: Starting task 0.0 in stage 179.0 (TID 582, localhost, executor driver, partition 0, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:45 INFO TaskSetManager: Starting task 1.0 in stage 179.0 (TID 583, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:45 INFO Executor: Running task 1.0 in stage 179.0 (TID 583)
18/04/01 20:16:45 INFO Executor: Running task 0.0 in stage 179.0 (TID 582)
18/04/01 20:16:45 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:45 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:45 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:45 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:45 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:45 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:45 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:45 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:45 INFO KafkaProducer: [Producer clientId=producer-134] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:45 INFO KafkaProducer: [Producer clientId=producer-133] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:45 INFO Executor: Finished task 1.0 in stage 179.0 (TID 583). 1138 bytes result sent to driver
18/04/01 20:16:45 INFO Executor: Finished task 0.0 in stage 179.0 (TID 582). 1138 bytes result sent to driver
18/04/01 20:16:45 INFO TaskSetManager: Finished task 1.0 in stage 179.0 (TID 583) in 13 ms on localhost (executor driver) (1/2)
18/04/01 20:16:45 INFO TaskSetManager: Finished task 0.0 in stage 179.0 (TID 582) in 14 ms on localhost (executor driver) (2/2)
18/04/01 20:16:45 INFO TaskSchedulerImpl: Removed TaskSet 179.0, whose tasks have all completed, from pool 
18/04/01 20:16:45 INFO DAGScheduler: ResultStage 179 (foreachPartition at RefereeStats.scala:71) finished in 0.021 s
18/04/01 20:16:45 INFO DAGScheduler: Job 112 finished: foreachPartition at RefereeStats.scala:71, took 0.053209 s
18/04/01 20:16:45 INFO JobScheduler: Finished job streaming job 1522603005000 ms.1 from job set of time 1522603005000 ms
18/04/01 20:16:45 INFO JobScheduler: Starting job streaming job 1522603005000 ms.2 from job set of time 1522603005000 ms
18/04/01 20:16:45 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:89
18/04/01 20:16:45 INFO DAGScheduler: Registering RDD 157 (map at RefereeStats.scala:46)
18/04/01 20:16:45 INFO DAGScheduler: Got job 113 (foreachPartition at RefereeStats.scala:89) with 2 output partitions
18/04/01 20:16:45 INFO DAGScheduler: Final stage: ResultStage 181 (foreachPartition at RefereeStats.scala:89)
18/04/01 20:16:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 180)
18/04/01 20:16:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 180)
18/04/01 20:16:45 INFO DAGScheduler: Submitting ShuffleMapStage 180 (MapPartitionsRDD[157] at map at RefereeStats.scala:46), which has no missing parents
18/04/01 20:16:45 INFO MemoryStore: Block broadcast_181 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:16:45 INFO MemoryStore: Block broadcast_181_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:16:45 INFO BlockManagerInfo: Added broadcast_181_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.2 MB)
18/04/01 20:16:45 INFO SparkContext: Created broadcast 181 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:45 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 180 (MapPartitionsRDD[157] at map at RefereeStats.scala:46) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:16:45 INFO TaskSchedulerImpl: Adding task set 180.0 with 5 tasks
18/04/01 20:16:45 INFO TaskSetManager: Starting task 0.0 in stage 180.0 (TID 584, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:45 INFO TaskSetManager: Starting task 1.0 in stage 180.0 (TID 585, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:45 INFO Executor: Running task 0.0 in stage 180.0 (TID 584)
18/04/01 20:16:45 INFO Executor: Running task 1.0 in stage 180.0 (TID 585)
18/04/01 20:16:45 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:45 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:45 INFO Executor: Finished task 0.0 in stage 180.0 (TID 584). 938 bytes result sent to driver
18/04/01 20:16:45 INFO Executor: Finished task 1.0 in stage 180.0 (TID 585). 938 bytes result sent to driver
18/04/01 20:16:45 INFO TaskSetManager: Starting task 2.0 in stage 180.0 (TID 586, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:45 INFO TaskSetManager: Starting task 3.0 in stage 180.0 (TID 587, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:45 INFO Executor: Running task 2.0 in stage 180.0 (TID 586)
18/04/01 20:16:45 INFO Executor: Running task 3.0 in stage 180.0 (TID 587)
18/04/01 20:16:45 INFO TaskSetManager: Finished task 1.0 in stage 180.0 (TID 585) in 6 ms on localhost (executor driver) (1/5)
18/04/01 20:16:45 INFO TaskSetManager: Finished task 0.0 in stage 180.0 (TID 584) in 7 ms on localhost (executor driver) (2/5)
18/04/01 20:16:45 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:45 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:45 INFO Executor: Finished task 3.0 in stage 180.0 (TID 587). 938 bytes result sent to driver
18/04/01 20:16:45 INFO Executor: Finished task 2.0 in stage 180.0 (TID 586). 938 bytes result sent to driver
18/04/01 20:16:45 INFO TaskSetManager: Starting task 4.0 in stage 180.0 (TID 588, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:45 INFO Executor: Running task 4.0 in stage 180.0 (TID 588)
18/04/01 20:16:45 INFO TaskSetManager: Finished task 3.0 in stage 180.0 (TID 587) in 6 ms on localhost (executor driver) (3/5)
18/04/01 20:16:45 INFO TaskSetManager: Finished task 2.0 in stage 180.0 (TID 586) in 8 ms on localhost (executor driver) (4/5)
18/04/01 20:16:45 INFO KafkaRDD: Beginning offset 732 is the same as ending offset skipping clients-purchases-src-xxx 0
18/04/01 20:16:45 INFO Executor: Finished task 4.0 in stage 180.0 (TID 588). 938 bytes result sent to driver
18/04/01 20:16:45 INFO TaskSetManager: Finished task 4.0 in stage 180.0 (TID 588) in 7 ms on localhost (executor driver) (5/5)
18/04/01 20:16:45 INFO TaskSchedulerImpl: Removed TaskSet 180.0, whose tasks have all completed, from pool 
18/04/01 20:16:45 INFO DAGScheduler: ShuffleMapStage 180 (map at RefereeStats.scala:46) finished in 0.027 s
18/04/01 20:16:45 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:16:45 INFO DAGScheduler: running: Set()
18/04/01 20:16:45 INFO DAGScheduler: waiting: Set(ResultStage 181)
18/04/01 20:16:45 INFO DAGScheduler: failed: Set()
18/04/01 20:16:45 INFO DAGScheduler: Submitting ResultStage 181 (ShuffledRDD[158] at reduceByKey at RefereeStats.scala:51), which has no missing parents
18/04/01 20:16:45 INFO MemoryStore: Block broadcast_182 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:16:45 INFO MemoryStore: Block broadcast_182_piece0 stored as bytes in memory (estimated size 1709.0 B, free 477.2 MB)
18/04/01 20:16:45 INFO BlockManagerInfo: Added broadcast_182_piece0 in memory on 192.168.1.3:35449 (size: 1709.0 B, free: 477.2 MB)
18/04/01 20:16:45 INFO SparkContext: Created broadcast 182 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 181 (ShuffledRDD[158] at reduceByKey at RefereeStats.scala:51) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:16:45 INFO TaskSchedulerImpl: Adding task set 181.0 with 2 tasks
18/04/01 20:16:45 INFO TaskSetManager: Starting task 0.0 in stage 181.0 (TID 589, localhost, executor driver, partition 0, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:45 INFO TaskSetManager: Starting task 1.0 in stage 181.0 (TID 590, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:45 INFO Executor: Running task 1.0 in stage 181.0 (TID 590)
18/04/01 20:16:45 INFO Executor: Running task 0.0 in stage 181.0 (TID 589)
18/04/01 20:16:45 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:45 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/04/01 20:16:45 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:45 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:45 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:45 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:45 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:45 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:45 INFO KafkaProducer: [Producer clientId=producer-136] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:45 INFO KafkaProducer: [Producer clientId=producer-135] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:45 INFO Executor: Finished task 1.0 in stage 181.0 (TID 590). 1138 bytes result sent to driver
18/04/01 20:16:45 INFO TaskSetManager: Finished task 1.0 in stage 181.0 (TID 590) in 16 ms on localhost (executor driver) (1/2)
18/04/01 20:16:45 INFO Executor: Finished task 0.0 in stage 181.0 (TID 589). 1138 bytes result sent to driver
18/04/01 20:16:45 INFO TaskSetManager: Finished task 0.0 in stage 181.0 (TID 589) in 18 ms on localhost (executor driver) (2/2)
18/04/01 20:16:45 INFO TaskSchedulerImpl: Removed TaskSet 181.0, whose tasks have all completed, from pool 
18/04/01 20:16:45 INFO DAGScheduler: ResultStage 181 (foreachPartition at RefereeStats.scala:89) finished in 0.027 s
18/04/01 20:16:45 INFO DAGScheduler: Job 113 finished: foreachPartition at RefereeStats.scala:89, took 0.064867 s
18/04/01 20:16:45 INFO JobScheduler: Finished job streaming job 1522603005000 ms.2 from job set of time 1522603005000 ms
18/04/01 20:16:45 INFO JobScheduler: Starting job streaming job 1522603005000 ms.3 from job set of time 1522603005000 ms
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4023
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4162
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4198
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4406
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4171
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3957
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4193
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4239
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4060
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4252
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4493
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4186
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3956
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4348
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4234
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4313
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4475
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4516
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4350
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4358
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4030
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4106
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4130
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4391
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4268
18/04/01 20:16:45 INFO BlockManagerInfo: Removed broadcast_182_piece0 on 192.168.1.3:35449 in memory (size: 1709.0 B, free: 477.2 MB)
18/04/01 20:16:45 INFO SparkContext: Starting job: foreachPartition at RefereeStats.scala:106
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4128
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3995
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3964
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4222
18/04/01 20:16:45 INFO DAGScheduler: Registering RDD 159 (map at RefereeStats.scala:39)
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4044
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4107
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4250
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4174
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4240
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4345
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4492
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4527
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4508
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4289
18/04/01 20:16:45 INFO DAGScheduler: Got job 114 (foreachPartition at RefereeStats.scala:106) with 2 output partitions
18/04/01 20:16:45 INFO DAGScheduler: Final stage: ResultStage 183 (foreachPartition at RefereeStats.scala:106)
18/04/01 20:16:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 182)
18/04/01 20:16:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 182)
18/04/01 20:16:45 INFO DAGScheduler: Submitting ShuffleMapStage 182 (MapPartitionsRDD[159] at map at RefereeStats.scala:39), which has no missing parents
18/04/01 20:16:45 INFO BlockManagerInfo: Removed broadcast_159_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.2 MB)
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4184
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4024
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4460
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4467
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4110
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4415
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4435
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4416
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4536
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4379
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3998
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4238
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4165
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4424
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3990
18/04/01 20:16:45 INFO BlockManagerInfo: Removed broadcast_167_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4054
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4546
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4521
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4454
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4283
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4337
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4372
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4248
18/04/01 20:16:45 INFO BlockManagerInfo: Removed broadcast_179_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4502
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4520
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4150
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4230
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4263
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4201
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4126
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4073
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4382
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4216
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4483
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4013
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4173
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4203
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4095
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4488
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3984
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4278
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4243
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4255
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3987
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4365
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4115
18/04/01 20:16:45 INFO MemoryStore: Block broadcast_183 stored as values in memory (estimated size 3.9 KB, free 477.2 MB)
18/04/01 20:16:45 INFO ContextCleaner: Cleaned shuffle 60
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4414
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4437
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4528
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4096
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4352
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4369
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4438
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4498
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3954
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4333
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4122
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4105
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4149
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4513
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4205
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4046
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4479
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4360
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4048
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4449
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4050
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4155
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4160
18/04/01 20:16:45 INFO MemoryStore: Block broadcast_183_piece0 stored as bytes in memory (estimated size 2.4 KB, free 477.2 MB)
18/04/01 20:16:45 INFO BlockManagerInfo: Added broadcast_183_piece0 in memory on 192.168.1.3:35449 (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:45 INFO SparkContext: Created broadcast 183 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:45 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 182 (MapPartitionsRDD[159] at map at RefereeStats.scala:39) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/04/01 20:16:45 INFO TaskSchedulerImpl: Adding task set 182.0 with 5 tasks
18/04/01 20:16:45 INFO TaskSetManager: Starting task 0.0 in stage 182.0 (TID 591, localhost, executor driver, partition 0, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:45 INFO TaskSetManager: Starting task 1.0 in stage 182.0 (TID 592, localhost, executor driver, partition 1, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:45 INFO BlockManagerInfo: Removed broadcast_180_piece0 on 192.168.1.3:35449 in memory (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:16:45 INFO Executor: Running task 0.0 in stage 182.0 (TID 591)
18/04/01 20:16:45 INFO Executor: Running task 1.0 in stage 182.0 (TID 592)
18/04/01 20:16:45 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 2
18/04/01 20:16:45 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 1
18/04/01 20:16:45 INFO Executor: Finished task 0.0 in stage 182.0 (TID 591). 938 bytes result sent to driver
18/04/01 20:16:45 INFO Executor: Finished task 1.0 in stage 182.0 (TID 592). 938 bytes result sent to driver
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3979
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4427
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4142
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4265
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3962
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4067
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4247
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4057
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4510
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4081
18/04/01 20:16:45 INFO TaskSetManager: Starting task 2.0 in stage 182.0 (TID 593, localhost, executor driver, partition 2, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:45 INFO TaskSetManager: Finished task 0.0 in stage 182.0 (TID 591) in 6 ms on localhost (executor driver) (1/5)
18/04/01 20:16:45 INFO Executor: Running task 2.0 in stage 182.0 (TID 593)
18/04/01 20:16:45 INFO ContextCleaner: Cleaned shuffle 61
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3997
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4221
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4505
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4040
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4549
18/04/01 20:16:45 INFO TaskSetManager: Starting task 3.0 in stage 182.0 (TID 594, localhost, executor driver, partition 3, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4354
18/04/01 20:16:45 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 4
18/04/01 20:16:45 INFO TaskSetManager: Finished task 1.0 in stage 182.0 (TID 592) in 8 ms on localhost (executor driver) (2/5)
18/04/01 20:16:45 INFO Executor: Running task 3.0 in stage 182.0 (TID 594)
18/04/01 20:16:45 INFO BlockManagerInfo: Removed broadcast_161_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4290
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4374
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4532
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4389
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3970
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4083
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3981
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4232
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4291
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4251
18/04/01 20:16:45 INFO Executor: Finished task 2.0 in stage 182.0 (TID 593). 938 bytes result sent to driver
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4091
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4411
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4430
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4332
18/04/01 20:16:45 INFO TaskSetManager: Starting task 4.0 in stage 182.0 (TID 595, localhost, executor driver, partition 4, PROCESS_LOCAL, 7740 bytes)
18/04/01 20:16:45 INFO Executor: Running task 4.0 in stage 182.0 (TID 595)
18/04/01 20:16:45 INFO TaskSetManager: Finished task 2.0 in stage 182.0 (TID 593) in 5 ms on localhost (executor driver) (3/5)
18/04/01 20:16:45 INFO KafkaRDD: Beginning offset 0 is the same as ending offset skipping clients-purchases-src-xxx 3
18/04/01 20:16:45 INFO BlockManagerInfo: Removed broadcast_164_piece0 on 192.168.1.3:35449 in memory (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4284
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4397
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4531
18/04/01 20:16:45 INFO KafkaRDD: Beginning offset 732 is the same as ending offset skipping clients-purchases-src-xxx 0
18/04/01 20:16:45 INFO Executor: Finished task 3.0 in stage 182.0 (TID 594). 938 bytes result sent to driver
18/04/01 20:16:45 INFO Executor: Finished task 4.0 in stage 182.0 (TID 595). 938 bytes result sent to driver
18/04/01 20:16:45 INFO TaskSetManager: Finished task 3.0 in stage 182.0 (TID 594) in 9 ms on localhost (executor driver) (4/5)
18/04/01 20:16:45 INFO TaskSetManager: Finished task 4.0 in stage 182.0 (TID 595) in 5 ms on localhost (executor driver) (5/5)
18/04/01 20:16:45 INFO TaskSchedulerImpl: Removed TaskSet 182.0, whose tasks have all completed, from pool 
18/04/01 20:16:45 INFO BlockManagerInfo: Removed broadcast_177_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:45 INFO DAGScheduler: ShuffleMapStage 182 (map at RefereeStats.scala:39) finished in 0.025 s
18/04/01 20:16:45 INFO DAGScheduler: looking for newly runnable stages
18/04/01 20:16:45 INFO DAGScheduler: running: Set()
18/04/01 20:16:45 INFO DAGScheduler: waiting: Set(ResultStage 183)
18/04/01 20:16:45 INFO DAGScheduler: failed: Set()
18/04/01 20:16:45 INFO DAGScheduler: Submitting ResultStage 183 (ShuffledRDD[160] at reduceByKey at RefereeStats.scala:43), which has no missing parents
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4267
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4200
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4210
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4481
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4133
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4262
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4396
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4463
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4425
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4329
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4524
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4140
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4187
18/04/01 20:16:45 INFO MemoryStore: Block broadcast_184 stored as values in memory (estimated size 2.8 KB, free 477.2 MB)
18/04/01 20:16:45 INFO BlockManagerInfo: Removed broadcast_178_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4288
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4061
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4132
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3993
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3988
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3996
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4002
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4509
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4218
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4294
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4506
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4033
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4459
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4478
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4190
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4470
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3973
18/04/01 20:16:45 INFO MemoryStore: Block broadcast_184_piece0 stored as bytes in memory (estimated size 1704.0 B, free 477.2 MB)
18/04/01 20:16:45 INFO BlockManagerInfo: Removed broadcast_163_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:45 INFO BlockManagerInfo: Added broadcast_184_piece0 in memory on 192.168.1.3:35449 (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4314
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4364
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4019
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4325
18/04/01 20:16:45 INFO SparkContext: Created broadcast 184 from broadcast at DAGScheduler.scala:1039
18/04/01 20:16:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 183 (ShuffledRDD[160] at reduceByKey at RefereeStats.scala:43) (first 15 tasks are for partitions Vector(0, 1))
18/04/01 20:16:45 INFO BlockManagerInfo: Removed broadcast_160_piece0 on 192.168.1.3:35449 in memory (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:16:45 INFO TaskSchedulerImpl: Adding task set 183.0 with 2 tasks
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4259
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4043
18/04/01 20:16:45 INFO TaskSetManager: Starting task 0.0 in stage 183.0 (TID 596, localhost, executor driver, partition 0, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:45 INFO BlockManagerInfo: Removed broadcast_181_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:45 INFO TaskSetManager: Starting task 1.0 in stage 183.0 (TID 597, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4120
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3982
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4011
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4293
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4008
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4166
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4507
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4387
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4485
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4269
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4473
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3967
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4229
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4257
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4443
18/04/01 20:16:45 INFO Executor: Running task 0.0 in stage 183.0 (TID 596)
18/04/01 20:16:45 INFO BlockManagerInfo: Removed broadcast_171_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4308
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4045
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4356
18/04/01 20:16:45 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:16:45 INFO BlockManagerInfo: Removed broadcast_170_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:45 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4370
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4476
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4359
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4063
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4177
18/04/01 20:16:45 INFO BlockManagerInfo: Removed broadcast_162_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4276
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4302
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4336
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4544
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4403
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4432
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4223
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4080
18/04/01 20:16:45 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:45 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:45 INFO KafkaProducer: [Producer clientId=producer-137] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:45 INFO BlockManagerInfo: Removed broadcast_169_piece0 on 192.168.1.3:35449 in memory (size: 1987.0 B, free: 477.3 MB)
18/04/01 20:16:45 INFO Executor: Running task 1.0 in stage 183.0 (TID 597)
18/04/01 20:16:45 INFO Executor: Finished task 0.0 in stage 183.0 (TID 596). 1138 bytes result sent to driver
18/04/01 20:16:45 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
18/04/01 20:16:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/04/01 20:16:45 INFO TaskSetManager: Finished task 0.0 in stage 183.0 (TID 596) in 14 ms on localhost (executor driver) (1/2)
18/04/01 20:16:45 INFO ProducerConfig: ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4245
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4188
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4196
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4231
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4477
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4169
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4227
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4323
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4535
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4324
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4480
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4131
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4104
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4342
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4408
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4487
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4068
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4433
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4517
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4094
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3961
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4179
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4504
18/04/01 20:16:45 INFO AppInfoParser: Kafka version : 1.1.0
18/04/01 20:16:45 INFO AppInfoParser: Kafka commitId : fdcf75ea326b8e07
18/04/01 20:16:45 INFO KafkaProducer: [Producer clientId=producer-138] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
18/04/01 20:16:45 INFO Executor: Finished task 1.0 in stage 183.0 (TID 597). 1138 bytes result sent to driver
18/04/01 20:16:45 INFO BlockManagerInfo: Removed broadcast_172_piece0 on 192.168.1.3:35449 in memory (size: 1706.0 B, free: 477.3 MB)
18/04/01 20:16:45 INFO TaskSetManager: Finished task 1.0 in stage 183.0 (TID 597) in 27 ms on localhost (executor driver) (2/2)
18/04/01 20:16:45 INFO TaskSchedulerImpl: Removed TaskSet 183.0, whose tasks have all completed, from pool 
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4404
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4088
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4446
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4003
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4533
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4388
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4000
18/04/01 20:16:45 INFO DAGScheduler: ResultStage 183 (foreachPartition at RefereeStats.scala:106) finished in 0.036 s
18/04/01 20:16:45 INFO DAGScheduler: Job 114 finished: foreachPartition at RefereeStats.scala:106, took 0.073812 s
18/04/01 20:16:45 INFO JobScheduler: Finished job streaming job 1522603005000 ms.3 from job set of time 1522603005000 ms
18/04/01 20:16:45 INFO JobScheduler: Total delay: 0.323 s for time 1522603005000 ms (execution: 0.298 s)
18/04/01 20:16:45 INFO MapPartitionsRDD: Removing RDD 148 from persistence list
18/04/01 20:16:45 INFO BlockManagerInfo: Removed broadcast_176_piece0 on 192.168.1.3:35449 in memory (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:16:45 INFO BlockManager: Removing RDD 148
18/04/01 20:16:45 INFO KafkaRDD: Removing RDD 147 from persistence list
18/04/01 20:16:45 INFO ShuffledRDD: Removing RDD 149 from persistence list
18/04/01 20:16:45 INFO BlockManager: Removing RDD 147
18/04/01 20:16:45 INFO BlockManager: Removing RDD 149
18/04/01 20:16:45 INFO ShuffledRDD: Removing RDD 151 from persistence list
18/04/01 20:16:45 INFO BlockManager: Removing RDD 151
18/04/01 20:16:45 INFO MapPartitionsRDD: Removing RDD 150 from persistence list
18/04/01 20:16:45 INFO BlockManager: Removing RDD 150
18/04/01 20:16:45 INFO ShuffledRDD: Removing RDD 153 from persistence list
18/04/01 20:16:45 INFO BlockManager: Removing RDD 153
18/04/01 20:16:45 INFO MapPartitionsRDD: Removing RDD 152 from persistence list
18/04/01 20:16:45 INFO BlockManager: Removing RDD 152
18/04/01 20:16:45 INFO JobGenerator: Checkpointing graph for time 1522603005000 ms
18/04/01 20:16:45 INFO DStreamGraph: Updating checkpoint data for time 1522603005000 ms
18/04/01 20:16:45 INFO DStreamGraph: Updated checkpoint data for time 1522603005000 ms
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4034
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4393
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4244
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4208
18/04/01 20:16:45 INFO CheckpointWriter: Submitted checkpoint of time 1522603005000 ms to writer queue
18/04/01 20:16:45 INFO CheckpointWriter: Saving checkpoint for time 1522603005000 ms to file 'file:/tmp/refs-xyzabb/checkpoint-1522603005000'
18/04/01 20:16:45 INFO BlockManagerInfo: Removed broadcast_166_piece0 on 192.168.1.3:35449 in memory (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4322
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4178
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4514
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3999
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4029
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4256
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4420
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4065
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4137
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3965
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4445
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4429
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4053
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4346
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4363
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4417
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4439
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4383
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4466
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4491
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4099
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3978
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4355
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4285
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4497
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4181
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4309
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4390
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3986
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4277
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4548
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4351
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4541
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4017
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4170
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3992
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3976
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4084
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4287
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4009
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4195
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4455
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4282
18/04/01 20:16:45 INFO BlockManagerInfo: Removed broadcast_175_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4066
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4296
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4212
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4164
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4206
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4407
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4108
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4242
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4472
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4209
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3966
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4300
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4151
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4035
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4114
18/04/01 20:16:45 INFO BlockManagerInfo: Removed broadcast_168_piece0 on 192.168.1.3:35449 in memory (size: 1704.0 B, free: 477.3 MB)
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4194
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4375
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4530
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4361
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4123
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4235
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4078
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4523
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4026
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4189
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4157
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4070
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4086
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4320
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4058
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4335
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4192
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4380
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4434
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4496
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4368
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4338
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4402
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4254
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4501
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4444
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4079
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4515
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4272
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4237
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3991
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4156
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4241
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4412
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3972
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4202
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4394
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4097
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4102
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4071
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4299
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4319
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3963
18/04/01 20:16:45 INFO CheckpointWriter: Deleting file:/tmp/refs-xyzabb/checkpoint-1522602980000
18/04/01 20:16:45 INFO BlockManagerInfo: Removed broadcast_173_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4334
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4450
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4217
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4144
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4093
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4486
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4220
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4215
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4182
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4377
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4176
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3977
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4214
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4199
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4052
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4273
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4138
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4306
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4064
18/04/01 20:16:45 INFO CheckpointWriter: Checkpoint for time 1522603005000 ms saved to file 'file:/tmp/refs-xyzabb/checkpoint-1522603005000', took 5535 bytes and 21 ms
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4482
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3955
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4191
18/04/01 20:16:45 INFO DStreamGraph: Clearing checkpoint data for time 1522603005000 ms
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4326
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3975
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4236
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4317
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4543
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4400
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4076
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4286
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4028
18/04/01 20:16:45 INFO DStreamGraph: Cleared checkpoint data for time 1522603005000 ms
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4161
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4167
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4055
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4012
18/04/01 20:16:45 INFO ReceivedBlockTracker: Deleting batches: 
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3951
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4010
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4032
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4125
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4301
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4134
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4347
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4310
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4015
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4101
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4447
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4005
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3971
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4249
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4020
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4371
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4197
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4007
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4266
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4075
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4074
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4025
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4398
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4261
18/04/01 20:16:45 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/tmp/refs-xyzabb/receivedBlockMetadata older than 1522603000000: 
18/04/01 20:16:45 INFO ContextCleaner: Cleaned shuffle 56
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4185
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4292
18/04/01 20:16:45 INFO InputInfoTracker: remove old batch metadata: 1522602995000 ms
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4331
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4274
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4330
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4129
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4021
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4124
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4489
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3968
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4458
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4056
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4405
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4113
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4462
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4211
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4441
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4421
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4315
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4442
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4431
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4385
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4014
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4499
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4474
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4456
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3960
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4271
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4540
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4366
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3974
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4001
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4047
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4152
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4016
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4518
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4049
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4448
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4526
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4148
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4112
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4511
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4006
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4042
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4503
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3980
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4512
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4539
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4147
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4109
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4270
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4357
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4119
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4373
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4141
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4376
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4077
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4452
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4258
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4327
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3950
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4275
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4038
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4522
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4022
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4175
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4418
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4428
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4031
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4018
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4121
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4180
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3983
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4163
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4260
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4484
18/04/01 20:16:45 INFO ContextCleaner: Cleaned shuffle 62
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4145
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4423
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4419
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4233
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4072
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4172
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4471
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3959
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4051
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4004
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4534
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4279
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4316
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4069
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4340
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4143
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4085
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4399
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4062
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4451
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4089
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4305
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4098
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4039
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4547
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4307
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4281
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4343
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4410
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4422
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4264
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4159
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4381
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3989
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4158
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4116
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4413
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4207
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4092
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4349
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4153
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4183
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4225
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4111
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4457
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4146
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4328
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4103
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3958
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4367
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4246
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4525
18/04/01 20:16:45 INFO BlockManagerInfo: Removed broadcast_174_piece0 on 192.168.1.3:35449 in memory (size: 1709.0 B, free: 477.3 MB)
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4297
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4339
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4495
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4384
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4453
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4219
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4469
18/04/01 20:16:45 INFO BlockManagerInfo: Removed broadcast_165_piece0 on 192.168.1.3:35449 in memory (size: 2.4 KB, free: 477.3 MB)
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4362
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4538
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3994
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4041
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4117
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4344
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4409
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4519
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4542
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4295
18/04/01 20:16:45 INFO ContextCleaner: Cleaned shuffle 59
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4500
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4304
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4353
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4401
18/04/01 20:16:45 INFO ContextCleaner: Cleaned shuffle 58
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4082
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4228
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4537
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4224
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4378
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4341
18/04/01 20:16:45 INFO ContextCleaner: Cleaned shuffle 57
18/04/01 20:16:45 INFO ContextCleaner: Cleaned shuffle 54
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3953
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4545
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4280
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4226
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3952
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4213
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4321
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4100
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4440
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4036
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4392
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4298
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4436
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4087
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4303
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4468
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4059
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4386
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4318
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4312
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4168
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4090
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4395
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4139
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4529
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4426
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4253
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4490
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4461
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4135
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4136
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3969
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4154
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4464
18/04/01 20:16:45 INFO ContextCleaner: Cleaned shuffle 55
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4118
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4311
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4204
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4037
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4027
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4127
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4494
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 4465
18/04/01 20:16:45 INFO ContextCleaner: Cleaned accumulator 3985
